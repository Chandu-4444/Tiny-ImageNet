{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3GDHKn1NXdH",
        "outputId": "2559c1a5-583f-45cc-b877-91dc23899609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-12-03 05:55:33--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  6.21MB/s    in 40s     \n",
            "\n",
            "2021-12-03 05:56:14 (5.86 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM2OFhWSLTCa"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtaoTVi54fLd",
        "outputId": "c3411fad-676f-480a-a2fb-369e687d7111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# if not os.path.exists(\"tiny-imagenet-200/\"):\n",
        "#     !wget http: // cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "#     !unzip - q tiny-imagenet-200.zip\n",
        "#     print(\"Data downloaded!\")\n",
        "# else:\n",
        "#     print(\"Data downloaded!\")\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "# from utils import helper_plot\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    # you can continue going on here, like cuda:1 cuda:2....etc.\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")\n",
        "\n",
        "# Constants\n",
        "DATA_DIR = \"tiny-imagenet-200\"\n",
        "VAL_DIR = \"tiny-imagenet-200/val\"\n",
        "VAL_IMG_DIR = \"tiny-imagenet-200/val/images\"\n",
        "\n",
        "train_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomRotation(30),\n",
        "    torchvision.transforms.Resize(255),\n",
        "    torchvision.transforms.RandomResizedCrop(224),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.RandomVerticalFlip(),\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(255),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(\n",
        "    \"tiny-imagenet-200/train\", transform=train_transforms)\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "# helper_plot.plot_grid(dataloader=train_dataloader)\n",
        "\n",
        "# Place corresponding images into respective folders\n",
        "val_info = pd.read_csv(\"tiny-imagenet-200/val/val_annotations.txt\",\n",
        "                       sep='\\t', header=None, names=[\"File\", \"Class\", \"X\", \"Y\", \"H\", \"W\"])\n",
        "val_info.drop([\"X\", \"Y\", \"H\", \"W\"], axis=1, inplace=True)\n",
        "for img, folder_name in zip(val_info[\"File\"], val_info[\"Class\"]):\n",
        "    newpath = os.path.join(VAL_IMG_DIR, folder_name)\n",
        "    if not os.path.exists(newpath):\n",
        "        os.makedirs(newpath)\n",
        "    if os.path.exists(os.path.join(VAL_IMG_DIR, img)):\n",
        "        os.rename(os.path.join(VAL_IMG_DIR, img), os.path.join(newpath, img))\n",
        "\n",
        "val_dataset = torchvision.datasets.ImageFolder(\n",
        "    \"tiny-imagenet-200/val/images\", transform=test_transforms)\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
        "# helper_plot.plot_grid(dataloader=val_dataloader)\n",
        "\n",
        "\n",
        "# class AlexNet(nn.Module):\n",
        "#     def __init__(self, num_classes: int = 200, dropout: float = 0.5) -> None:\n",
        "#         super().__init__()\n",
        "#         self.features = nn.Sequential(\n",
        "#             nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(kernel_size=2),\n",
        "#             nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "#             nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "#         )\n",
        "#         self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.Dropout(p=dropout),\n",
        "#             nn.Linear(256 * 6 * 6, 4096),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Dropout(p=dropout),\n",
        "#             nn.Linear(4096, 4096),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Linear(4096, num_classes),\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "#         x = self.features(x)\n",
        "#         x = self.avgpool(x)\n",
        "#         x = torch.flatten(x, 1)\n",
        "#         x = self.classifier(x)\n",
        "#         return x\n",
        "\n",
        "\n",
        "# model = AlexNet(num_classes=200).to(device)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimiser = torch.optim.SGD(model.parameters(), lr=0.5)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "#     optimizer=optimiser, step_size=5, gamma=0.99)\n",
        "\n",
        "# # from utils import misc\n",
        "\n",
        "# # for idx, (image, label) in enumerate(train_dataloader):\n",
        "# #     print(idx, image.shape, label.shape)\n",
        "# #     break\n",
        "\n",
        "# epochs = 2\n",
        "# train_loss = 0\n",
        "# train_correct = 0\n",
        "# total = 0\n",
        "\n",
        "\n",
        "# for i in range(epochs):\n",
        "#     for index, (images, labels) in enumerate(train_dataloader):\n",
        "#         images, labels = images.to(device), labels.to(device)\n",
        "#         outputs = model.forward(images)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimiser.step()\n",
        "\n",
        "#         train_loss += loss.item()\n",
        "\n",
        "#         print(torch.sum(torch.argmax(outputs, 1) == labels))\n",
        "\n",
        "        \n",
        "\n",
        "#         total += labels.size(0)\n",
        "\n",
        "#         # misc.progress_bar(index, len(train_dataloader), 'Loss: %.4f | Acc: %.3f%% (%d/%d)'\n",
        "#         #                  % (train_loss / (index + 1), 100. * train_correct / total, train_correct, total))\n",
        "\n",
        "#         optimiser.zero_grad()\n",
        "#         scheduler.step()\n",
        "#         curr_lr = scheduler.get_last_lr()\n",
        "\n",
        "#         print(\n",
        "#             f'Epoch: [{i+1} / {epochs}], Step [{index + 1} / {len(train_dataloader)}], Loss: {loss.item()}, lr: {curr_lr[0]}')\n",
        "\n",
        "\n",
        "# print(train_loss, train_correct / total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuS5JxmLW2VM"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), \"model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tus44rm4-VSQ"
      },
      "outputs": [],
      "source": [
        "# model.features[0].weight.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvVcv8WD-2kk"
      },
      "outputs": [],
      "source": [
        "def plot_filters_single_channel_big(t):\n",
        "    \n",
        "    #setting the rows and columns\n",
        "    nrows = t.shape[0]*t.shape[2]\n",
        "    ncols = t.shape[1]*t.shape[3]\n",
        "    \n",
        "    \n",
        "    npimg = np.array(t.numpy(), np.float32)\n",
        "    npimg = npimg.transpose((0, 2, 1, 3))\n",
        "    npimg = npimg.ravel().reshape(nrows, ncols)\n",
        "    \n",
        "    npimg = npimg.T\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(ncols/10, nrows/200))    \n",
        "    imgplot = sns.heatmap(npimg, xticklabels=False, yticklabels=False, cmap='gray', ax=ax, cbar=False)\n",
        "\n",
        "def plot_filters_multi_channel(t):\n",
        "    \n",
        "    #get the number of kernals\n",
        "    num_kernels = t.shape[0]    \n",
        "    \n",
        "    #define number of columns for subplots\n",
        "    num_cols = 12\n",
        "    #rows = num of kernels\n",
        "    num_rows = num_kernels\n",
        "    \n",
        "    #set the figure size\n",
        "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
        "    \n",
        "    #looping through all the kernels\n",
        "    for i in range(t.shape[0]):\n",
        "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
        "        \n",
        "        #for each kernel, we convert the tensor to numpy \n",
        "        npimg = np.array(t[i].numpy(), np.float32)\n",
        "        #standardize the numpy image\n",
        "        npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
        "        npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
        "        npimg = npimg.transpose((1, 2, 0))\n",
        "        ax1.imshow(npimg)\n",
        "        ax1.axis('off')\n",
        "        ax1.set_title(str(i))\n",
        "        ax1.set_xticklabels([])\n",
        "        ax1.set_yticklabels([])\n",
        "        \n",
        "    plt.savefig('myimage.png', dpi=100)    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_filters_single_channel(t):\n",
        "    \n",
        "    #kernels depth * number of kernels\n",
        "    nplots = t.shape[0]*t.shape[1]\n",
        "    ncols = 12\n",
        "    \n",
        "    nrows = 1 + nplots//ncols\n",
        "    #convert tensor to numpy image\n",
        "    npimg = np.array(t.numpy(), np.float32)\n",
        "    \n",
        "    count = 0\n",
        "    fig = plt.figure(figsize=(ncols, nrows))\n",
        "    \n",
        "    #looping through all the kernels in each channel\n",
        "    for i in range(t.shape[0]):\n",
        "        for j in range(t.shape[1]):\n",
        "            count += 1\n",
        "            ax1 = fig.add_subplot(nrows, ncols, count)\n",
        "            npimg = np.array(t[i, j].numpy(), np.float32)\n",
        "            npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
        "            npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
        "            ax1.imshow(npimg)\n",
        "            ax1.set_title(str(i) + ',' + str(j))\n",
        "            ax1.axis('off')\n",
        "            ax1.set_xticklabels([])\n",
        "            ax1.set_yticklabels([])\n",
        "   \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_weights(model, layer_num, single_channel = True, collated = False):\n",
        "  \n",
        "  #extracting the model features at the particular layer number\n",
        "  layer = model.features[layer_num]\n",
        "  \n",
        "  #checking whether the layer is convolution layer or not \n",
        "  if isinstance(layer, nn.Conv2d):\n",
        "    #getting the weight tensor data\n",
        "    weight_tensor = model.features[layer_num].weight.data\n",
        "    \n",
        "    if single_channel:\n",
        "      if collated:\n",
        "        plot_filters_single_channel_big(weight_tensor)\n",
        "      else:\n",
        "        plot_filters_single_channel(weight_tensor)\n",
        "        \n",
        "    else:\n",
        "      if weight_tensor.shape[1] == 3:\n",
        "        plot_filters_multi_channel(weight_tensor)\n",
        "      else:\n",
        "        print(\"Can only plot weights with three channels with single channel = False\")\n",
        "        \n",
        "  else:\n",
        "    print(\"Can only visualize layers which are convolutional\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQhPLTbm-6-C"
      },
      "outputs": [],
      "source": [
        "# plot_weights(alexnet.cpu(), 0, single_channel=False)\n",
        "# print(\"Plot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGAw--iaMAAl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx4wSakWAmHa"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for index, (inputs, labels) in enumerate(dataloader[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                print(f\"[{index} / {len(train_dataloader)}], Loss: {loss}\")\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader[phase])\n",
        "            epoch_acc = running_corrects.double() / len(dataloader[phase])\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz4srvE9FHJC"
      },
      "outputs": [],
      "source": [
        "dataloader = {}\n",
        "dataloader['train'] = train_dataloader\n",
        "dataloader['val'] = val_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSggkdvDK4IN"
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52Yz5kBDK66Q"
      },
      "outputs": [],
      "source": [
        "model_ft = torchvision.models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 200)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QAk-QO1K8_u",
        "outputId": "d01f5d4d-3f66-4690-cddc-943e3baf0421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/2\n",
            "----------\n",
            "[0 / 781], Loss: 5.548508644104004\n",
            "[1 / 781], Loss: 5.511419296264648\n",
            "[2 / 781], Loss: 5.561408519744873\n",
            "[3 / 781], Loss: 5.436439037322998\n",
            "[4 / 781], Loss: 5.4931182861328125\n",
            "[5 / 781], Loss: 5.518818378448486\n",
            "[6 / 781], Loss: 5.521348476409912\n",
            "[7 / 781], Loss: 5.558944225311279\n",
            "[8 / 781], Loss: 5.531897068023682\n",
            "[9 / 781], Loss: 5.460701942443848\n",
            "[10 / 781], Loss: 5.471998691558838\n",
            "[11 / 781], Loss: 5.569391250610352\n",
            "[12 / 781], Loss: 5.5899763107299805\n",
            "[13 / 781], Loss: 5.554075717926025\n",
            "[14 / 781], Loss: 5.370026588439941\n",
            "[15 / 781], Loss: 5.495981693267822\n",
            "[16 / 781], Loss: 5.389349937438965\n",
            "[17 / 781], Loss: 5.458691120147705\n",
            "[18 / 781], Loss: 5.324427127838135\n",
            "[19 / 781], Loss: 5.476112365722656\n",
            "[20 / 781], Loss: 5.418116569519043\n",
            "[21 / 781], Loss: 5.446244239807129\n",
            "[22 / 781], Loss: 5.491970062255859\n",
            "[23 / 781], Loss: 5.353592872619629\n",
            "[24 / 781], Loss: 5.465343475341797\n",
            "[25 / 781], Loss: 5.444760799407959\n",
            "[26 / 781], Loss: 5.376533031463623\n",
            "[27 / 781], Loss: 5.406579494476318\n",
            "[28 / 781], Loss: 5.459523677825928\n",
            "[29 / 781], Loss: 5.410316467285156\n",
            "[30 / 781], Loss: 5.389593124389648\n",
            "[31 / 781], Loss: 5.390436172485352\n",
            "[32 / 781], Loss: 5.420528411865234\n",
            "[33 / 781], Loss: 5.45237922668457\n",
            "[34 / 781], Loss: 5.352672100067139\n",
            "[35 / 781], Loss: 5.48048734664917\n",
            "[36 / 781], Loss: 5.298573970794678\n",
            "[37 / 781], Loss: 5.364785194396973\n",
            "[38 / 781], Loss: 5.376560688018799\n",
            "[39 / 781], Loss: 5.413379192352295\n",
            "[40 / 781], Loss: 5.343940734863281\n",
            "[41 / 781], Loss: 5.284771919250488\n",
            "[42 / 781], Loss: 5.310283660888672\n",
            "[43 / 781], Loss: 5.345157146453857\n",
            "[44 / 781], Loss: 5.329624176025391\n",
            "[45 / 781], Loss: 5.313891887664795\n",
            "[46 / 781], Loss: 5.2822346687316895\n",
            "[47 / 781], Loss: 5.329405784606934\n",
            "[48 / 781], Loss: 5.340503692626953\n",
            "[49 / 781], Loss: 5.29641056060791\n",
            "[50 / 781], Loss: 5.348837852478027\n",
            "[51 / 781], Loss: 5.3916850090026855\n",
            "[52 / 781], Loss: 5.3979973793029785\n",
            "[53 / 781], Loss: 5.392968654632568\n",
            "[54 / 781], Loss: 5.377293109893799\n",
            "[55 / 781], Loss: 5.24600887298584\n",
            "[56 / 781], Loss: 5.3492631912231445\n",
            "[57 / 781], Loss: 5.337144374847412\n",
            "[58 / 781], Loss: 5.288848876953125\n",
            "[59 / 781], Loss: 5.3320465087890625\n",
            "[60 / 781], Loss: 5.277109622955322\n",
            "[61 / 781], Loss: 5.356329441070557\n",
            "[62 / 781], Loss: 5.3086419105529785\n",
            "[63 / 781], Loss: 5.365999221801758\n",
            "[64 / 781], Loss: 5.257543563842773\n",
            "[65 / 781], Loss: 5.304272174835205\n",
            "[66 / 781], Loss: 5.330276012420654\n",
            "[67 / 781], Loss: 5.2625412940979\n",
            "[68 / 781], Loss: 5.297447204589844\n",
            "[69 / 781], Loss: 5.308769702911377\n",
            "[70 / 781], Loss: 5.287665367126465\n",
            "[71 / 781], Loss: 5.3173112869262695\n",
            "[72 / 781], Loss: 5.355146884918213\n",
            "[73 / 781], Loss: 5.259541034698486\n",
            "[74 / 781], Loss: 5.309007167816162\n",
            "[75 / 781], Loss: 5.235762119293213\n",
            "[76 / 781], Loss: 5.296558380126953\n",
            "[77 / 781], Loss: 5.261051654815674\n",
            "[78 / 781], Loss: 5.2439775466918945\n",
            "[79 / 781], Loss: 5.2743730545043945\n",
            "[80 / 781], Loss: 5.224555969238281\n",
            "[81 / 781], Loss: 5.240634441375732\n",
            "[82 / 781], Loss: 5.34500789642334\n",
            "[83 / 781], Loss: 5.261708736419678\n",
            "[84 / 781], Loss: 5.21915864944458\n",
            "[85 / 781], Loss: 5.255209445953369\n",
            "[86 / 781], Loss: 5.228794574737549\n",
            "[87 / 781], Loss: 5.297908782958984\n",
            "[88 / 781], Loss: 5.259415149688721\n",
            "[89 / 781], Loss: 5.193655014038086\n",
            "[90 / 781], Loss: 5.293825626373291\n",
            "[91 / 781], Loss: 5.181726455688477\n",
            "[92 / 781], Loss: 5.292356967926025\n",
            "[93 / 781], Loss: 5.1754841804504395\n",
            "[94 / 781], Loss: 5.293420791625977\n",
            "[95 / 781], Loss: 5.229232311248779\n",
            "[96 / 781], Loss: 5.248899459838867\n",
            "[97 / 781], Loss: 5.261877536773682\n",
            "[98 / 781], Loss: 5.209516525268555\n",
            "[99 / 781], Loss: 5.29865837097168\n",
            "[100 / 781], Loss: 5.220099449157715\n",
            "[101 / 781], Loss: 5.258256435394287\n",
            "[102 / 781], Loss: 5.301100254058838\n",
            "[103 / 781], Loss: 5.269688606262207\n",
            "[104 / 781], Loss: 5.196382999420166\n",
            "[105 / 781], Loss: 5.246798515319824\n",
            "[106 / 781], Loss: 5.27158260345459\n",
            "[107 / 781], Loss: 5.296099662780762\n",
            "[108 / 781], Loss: 5.21976900100708\n",
            "[109 / 781], Loss: 5.275724411010742\n",
            "[110 / 781], Loss: 5.261739253997803\n",
            "[111 / 781], Loss: 5.274139404296875\n",
            "[112 / 781], Loss: 5.283321857452393\n",
            "[113 / 781], Loss: 5.181480884552002\n",
            "[114 / 781], Loss: 5.248970031738281\n",
            "[115 / 781], Loss: 5.22359037399292\n",
            "[116 / 781], Loss: 5.266870021820068\n",
            "[117 / 781], Loss: 5.158849716186523\n",
            "[118 / 781], Loss: 5.2445173263549805\n",
            "[119 / 781], Loss: 5.200797080993652\n",
            "[120 / 781], Loss: 5.2414326667785645\n",
            "[121 / 781], Loss: 5.207592487335205\n",
            "[122 / 781], Loss: 5.245034694671631\n",
            "[123 / 781], Loss: 5.203461170196533\n",
            "[124 / 781], Loss: 5.239702224731445\n",
            "[125 / 781], Loss: 5.1825714111328125\n",
            "[126 / 781], Loss: 5.2314043045043945\n",
            "[127 / 781], Loss: 5.194498062133789\n",
            "[128 / 781], Loss: 5.160433769226074\n",
            "[129 / 781], Loss: 5.195650577545166\n",
            "[130 / 781], Loss: 5.1561479568481445\n",
            "[131 / 781], Loss: 5.201596260070801\n",
            "[132 / 781], Loss: 5.244681358337402\n",
            "[133 / 781], Loss: 5.207121849060059\n",
            "[134 / 781], Loss: 5.203800201416016\n",
            "[135 / 781], Loss: 5.130715847015381\n",
            "[136 / 781], Loss: 5.1458892822265625\n",
            "[137 / 781], Loss: 5.187994956970215\n",
            "[138 / 781], Loss: 5.150926113128662\n",
            "[139 / 781], Loss: 5.149648666381836\n",
            "[140 / 781], Loss: 5.170670986175537\n",
            "[141 / 781], Loss: 5.230825901031494\n",
            "[142 / 781], Loss: 5.222827434539795\n",
            "[143 / 781], Loss: 5.124996662139893\n",
            "[144 / 781], Loss: 5.170895099639893\n",
            "[145 / 781], Loss: 5.195389747619629\n",
            "[146 / 781], Loss: 5.163711071014404\n",
            "[147 / 781], Loss: 5.14427375793457\n",
            "[148 / 781], Loss: 5.166637420654297\n",
            "[149 / 781], Loss: 5.188397407531738\n",
            "[150 / 781], Loss: 5.152927398681641\n",
            "[151 / 781], Loss: 5.1304144859313965\n",
            "[152 / 781], Loss: 5.143529891967773\n",
            "[153 / 781], Loss: 5.146701812744141\n",
            "[154 / 781], Loss: 5.067530155181885\n",
            "[155 / 781], Loss: 5.168247222900391\n",
            "[156 / 781], Loss: 5.168687343597412\n",
            "[157 / 781], Loss: 5.180140972137451\n",
            "[158 / 781], Loss: 5.141400337219238\n",
            "[159 / 781], Loss: 5.110552787780762\n",
            "[160 / 781], Loss: 5.126501560211182\n",
            "[161 / 781], Loss: 5.170427322387695\n",
            "[162 / 781], Loss: 5.166277885437012\n",
            "[163 / 781], Loss: 5.174257755279541\n",
            "[164 / 781], Loss: 5.062901496887207\n",
            "[165 / 781], Loss: 5.134740829467773\n",
            "[166 / 781], Loss: 5.025459289550781\n",
            "[167 / 781], Loss: 5.160659313201904\n",
            "[168 / 781], Loss: 5.131338119506836\n",
            "[169 / 781], Loss: 5.153630256652832\n",
            "[170 / 781], Loss: 5.152081489562988\n",
            "[171 / 781], Loss: 5.08982515335083\n",
            "[172 / 781], Loss: 5.06838321685791\n",
            "[173 / 781], Loss: 5.080521583557129\n",
            "[174 / 781], Loss: 5.123597621917725\n",
            "[175 / 781], Loss: 5.072567939758301\n",
            "[176 / 781], Loss: 5.146111488342285\n",
            "[177 / 781], Loss: 5.031668663024902\n",
            "[178 / 781], Loss: 5.125216960906982\n",
            "[179 / 781], Loss: 5.033210277557373\n",
            "[180 / 781], Loss: 5.047532081604004\n",
            "[181 / 781], Loss: 5.164035797119141\n",
            "[182 / 781], Loss: 5.093018531799316\n",
            "[183 / 781], Loss: 5.033665657043457\n",
            "[184 / 781], Loss: 5.031288146972656\n",
            "[185 / 781], Loss: 5.009480953216553\n",
            "[186 / 781], Loss: 4.981521129608154\n",
            "[187 / 781], Loss: 4.95838737487793\n",
            "[188 / 781], Loss: 5.152943134307861\n",
            "[189 / 781], Loss: 5.0542311668396\n",
            "[190 / 781], Loss: 5.075704097747803\n",
            "[191 / 781], Loss: 5.083165168762207\n",
            "[192 / 781], Loss: 5.0229716300964355\n",
            "[193 / 781], Loss: 5.1224045753479\n",
            "[194 / 781], Loss: 5.084579944610596\n",
            "[195 / 781], Loss: 5.0422210693359375\n",
            "[196 / 781], Loss: 4.963379859924316\n",
            "[197 / 781], Loss: 5.075328826904297\n",
            "[198 / 781], Loss: 5.060083866119385\n",
            "[199 / 781], Loss: 5.0924811363220215\n",
            "[200 / 781], Loss: 5.049442291259766\n",
            "[201 / 781], Loss: 5.05183744430542\n",
            "[202 / 781], Loss: 4.982471942901611\n",
            "[203 / 781], Loss: 5.004194259643555\n",
            "[204 / 781], Loss: 5.052055358886719\n",
            "[205 / 781], Loss: 5.036653995513916\n",
            "[206 / 781], Loss: 5.056368827819824\n",
            "[207 / 781], Loss: 4.9716644287109375\n",
            "[208 / 781], Loss: 5.014695167541504\n",
            "[209 / 781], Loss: 5.120178699493408\n",
            "[210 / 781], Loss: 5.051383972167969\n",
            "[211 / 781], Loss: 5.05605936050415\n",
            "[212 / 781], Loss: 5.095219612121582\n",
            "[213 / 781], Loss: 5.122385501861572\n",
            "[214 / 781], Loss: 5.042390823364258\n",
            "[215 / 781], Loss: 5.09247350692749\n",
            "[216 / 781], Loss: 4.978419303894043\n",
            "[217 / 781], Loss: 4.98792839050293\n",
            "[218 / 781], Loss: 4.927152156829834\n",
            "[219 / 781], Loss: 4.979699611663818\n",
            "[220 / 781], Loss: 5.012649059295654\n",
            "[221 / 781], Loss: 4.93105936050415\n",
            "[222 / 781], Loss: 4.905597686767578\n",
            "[223 / 781], Loss: 5.06141996383667\n",
            "[224 / 781], Loss: 4.983109951019287\n",
            "[225 / 781], Loss: 4.989330768585205\n",
            "[226 / 781], Loss: 5.063383102416992\n",
            "[227 / 781], Loss: 5.046627998352051\n",
            "[228 / 781], Loss: 4.972696781158447\n",
            "[229 / 781], Loss: 5.058890342712402\n",
            "[230 / 781], Loss: 5.055436611175537\n",
            "[231 / 781], Loss: 5.062270641326904\n",
            "[232 / 781], Loss: 4.915677547454834\n",
            "[233 / 781], Loss: 4.883145809173584\n",
            "[234 / 781], Loss: 5.006951808929443\n",
            "[235 / 781], Loss: 4.928399085998535\n",
            "[236 / 781], Loss: 4.965260028839111\n",
            "[237 / 781], Loss: 4.999723434448242\n",
            "[238 / 781], Loss: 4.968592643737793\n",
            "[239 / 781], Loss: 5.040059566497803\n",
            "[240 / 781], Loss: 4.933413982391357\n",
            "[241 / 781], Loss: 4.927233695983887\n",
            "[242 / 781], Loss: 4.964081287384033\n",
            "[243 / 781], Loss: 4.991086006164551\n",
            "[244 / 781], Loss: 4.935898303985596\n",
            "[245 / 781], Loss: 4.893087387084961\n",
            "[246 / 781], Loss: 4.891471862792969\n",
            "[247 / 781], Loss: 4.950644016265869\n",
            "[248 / 781], Loss: 5.031373500823975\n",
            "[249 / 781], Loss: 4.943914413452148\n",
            "[250 / 781], Loss: 4.903794288635254\n",
            "[251 / 781], Loss: 4.965703964233398\n",
            "[252 / 781], Loss: 4.894543647766113\n",
            "[253 / 781], Loss: 4.882259368896484\n",
            "[254 / 781], Loss: 4.969461917877197\n",
            "[255 / 781], Loss: 4.889405727386475\n",
            "[256 / 781], Loss: 4.938544750213623\n",
            "[257 / 781], Loss: 4.992021560668945\n",
            "[258 / 781], Loss: 4.9186692237854\n",
            "[259 / 781], Loss: 4.949524402618408\n",
            "[260 / 781], Loss: 4.873443603515625\n",
            "[261 / 781], Loss: 4.840463161468506\n",
            "[262 / 781], Loss: 5.01807165145874\n",
            "[263 / 781], Loss: 4.873103141784668\n",
            "[264 / 781], Loss: 4.940280437469482\n",
            "[265 / 781], Loss: 4.869266033172607\n",
            "[266 / 781], Loss: 4.876028537750244\n",
            "[267 / 781], Loss: 4.9076151847839355\n",
            "[268 / 781], Loss: 4.868650913238525\n",
            "[269 / 781], Loss: 4.884576797485352\n",
            "[270 / 781], Loss: 5.035816192626953\n",
            "[271 / 781], Loss: 4.75548791885376\n",
            "[272 / 781], Loss: 4.968604564666748\n",
            "[273 / 781], Loss: 4.745389461517334\n",
            "[274 / 781], Loss: 4.847232341766357\n",
            "[275 / 781], Loss: 4.8852338790893555\n",
            "[276 / 781], Loss: 4.853321075439453\n",
            "[277 / 781], Loss: 4.9528961181640625\n",
            "[278 / 781], Loss: 4.819402694702148\n",
            "[279 / 781], Loss: 4.927646160125732\n",
            "[280 / 781], Loss: 4.851659774780273\n",
            "[281 / 781], Loss: 4.925015449523926\n",
            "[282 / 781], Loss: 4.9276227951049805\n",
            "[283 / 781], Loss: 4.93760347366333\n",
            "[284 / 781], Loss: 4.955323219299316\n",
            "[285 / 781], Loss: 4.995730400085449\n",
            "[286 / 781], Loss: 4.866129398345947\n",
            "[287 / 781], Loss: 4.80299186706543\n",
            "[288 / 781], Loss: 4.755328178405762\n",
            "[289 / 781], Loss: 4.857565879821777\n",
            "[290 / 781], Loss: 4.851715564727783\n",
            "[291 / 781], Loss: 5.021018981933594\n",
            "[292 / 781], Loss: 4.6955060958862305\n",
            "[293 / 781], Loss: 4.8415679931640625\n",
            "[294 / 781], Loss: 4.914371490478516\n",
            "[295 / 781], Loss: 4.865699768066406\n",
            "[296 / 781], Loss: 4.808343410491943\n",
            "[297 / 781], Loss: 4.753899097442627\n",
            "[298 / 781], Loss: 4.9525675773620605\n",
            "[299 / 781], Loss: 4.8634843826293945\n",
            "[300 / 781], Loss: 4.80013370513916\n",
            "[301 / 781], Loss: 4.881799221038818\n",
            "[302 / 781], Loss: 4.764441967010498\n",
            "[303 / 781], Loss: 4.795909881591797\n",
            "[304 / 781], Loss: 4.827240467071533\n",
            "[305 / 781], Loss: 4.747527122497559\n",
            "[306 / 781], Loss: 4.854531288146973\n",
            "[307 / 781], Loss: 4.822254657745361\n",
            "[308 / 781], Loss: 4.819544792175293\n",
            "[309 / 781], Loss: 4.877049922943115\n",
            "[310 / 781], Loss: 4.786425590515137\n",
            "[311 / 781], Loss: 4.947582244873047\n",
            "[312 / 781], Loss: 4.854638576507568\n",
            "[313 / 781], Loss: 4.769050598144531\n",
            "[314 / 781], Loss: 4.865513324737549\n",
            "[315 / 781], Loss: 4.799283027648926\n",
            "[316 / 781], Loss: 4.790142059326172\n",
            "[317 / 781], Loss: 4.781424522399902\n",
            "[318 / 781], Loss: 4.885786056518555\n",
            "[319 / 781], Loss: 4.7714972496032715\n",
            "[320 / 781], Loss: 4.748868942260742\n",
            "[321 / 781], Loss: 4.82930850982666\n",
            "[322 / 781], Loss: 4.791359901428223\n",
            "[323 / 781], Loss: 4.8372931480407715\n",
            "[324 / 781], Loss: 4.869561672210693\n",
            "[325 / 781], Loss: 4.745725631713867\n",
            "[326 / 781], Loss: 4.726604461669922\n",
            "[327 / 781], Loss: 4.748619556427002\n",
            "[328 / 781], Loss: 4.89583683013916\n",
            "[329 / 781], Loss: 4.6427693367004395\n",
            "[330 / 781], Loss: 4.843504428863525\n",
            "[331 / 781], Loss: 4.756217956542969\n",
            "[332 / 781], Loss: 4.762298583984375\n",
            "[333 / 781], Loss: 4.76875638961792\n",
            "[334 / 781], Loss: 4.737520694732666\n",
            "[335 / 781], Loss: 4.931580543518066\n",
            "[336 / 781], Loss: 4.836638450622559\n",
            "[337 / 781], Loss: 4.8202900886535645\n",
            "[338 / 781], Loss: 4.6816911697387695\n",
            "[339 / 781], Loss: 4.748031139373779\n",
            "[340 / 781], Loss: 4.652884483337402\n",
            "[341 / 781], Loss: 4.822226047515869\n",
            "[342 / 781], Loss: 4.839308261871338\n",
            "[343 / 781], Loss: 4.649298667907715\n",
            "[344 / 781], Loss: 4.747222423553467\n",
            "[345 / 781], Loss: 4.710697174072266\n",
            "[346 / 781], Loss: 4.695712089538574\n",
            "[347 / 781], Loss: 4.8176960945129395\n",
            "[348 / 781], Loss: 4.766891956329346\n",
            "[349 / 781], Loss: 4.844222068786621\n",
            "[350 / 781], Loss: 4.740002155303955\n",
            "[351 / 781], Loss: 4.6997175216674805\n",
            "[352 / 781], Loss: 4.733386993408203\n",
            "[353 / 781], Loss: 4.6447248458862305\n",
            "[354 / 781], Loss: 4.701684474945068\n",
            "[355 / 781], Loss: 4.745567798614502\n",
            "[356 / 781], Loss: 4.785616874694824\n",
            "[357 / 781], Loss: 4.651126861572266\n",
            "[358 / 781], Loss: 4.786088943481445\n",
            "[359 / 781], Loss: 4.642001628875732\n",
            "[360 / 781], Loss: 4.80063009262085\n",
            "[361 / 781], Loss: 4.649684429168701\n",
            "[362 / 781], Loss: 4.570710182189941\n",
            "[363 / 781], Loss: 4.744626998901367\n",
            "[364 / 781], Loss: 4.721978664398193\n",
            "[365 / 781], Loss: 4.768016815185547\n",
            "[366 / 781], Loss: 4.6815714836120605\n",
            "[367 / 781], Loss: 4.809770107269287\n",
            "[368 / 781], Loss: 4.659095287322998\n",
            "[369 / 781], Loss: 4.740261554718018\n",
            "[370 / 781], Loss: 4.645762920379639\n",
            "[371 / 781], Loss: 4.7455525398254395\n",
            "[372 / 781], Loss: 4.717957973480225\n",
            "[373 / 781], Loss: 4.674387454986572\n",
            "[374 / 781], Loss: 4.704957008361816\n",
            "[375 / 781], Loss: 4.645158767700195\n",
            "[376 / 781], Loss: 4.704225063323975\n",
            "[377 / 781], Loss: 4.661693096160889\n",
            "[378 / 781], Loss: 4.635369777679443\n",
            "[379 / 781], Loss: 4.734392166137695\n",
            "[380 / 781], Loss: 4.621472358703613\n",
            "[381 / 781], Loss: 4.760565757751465\n",
            "[382 / 781], Loss: 4.63285493850708\n",
            "[383 / 781], Loss: 4.726557731628418\n",
            "[384 / 781], Loss: 4.714317321777344\n",
            "[385 / 781], Loss: 4.719849586486816\n",
            "[386 / 781], Loss: 4.639339923858643\n",
            "[387 / 781], Loss: 4.736278057098389\n",
            "[388 / 781], Loss: 4.5378217697143555\n",
            "[389 / 781], Loss: 4.550384521484375\n",
            "[390 / 781], Loss: 4.687245845794678\n",
            "[391 / 781], Loss: 4.726604461669922\n",
            "[392 / 781], Loss: 4.676653861999512\n",
            "[393 / 781], Loss: 4.666069507598877\n",
            "[394 / 781], Loss: 4.611799240112305\n",
            "[395 / 781], Loss: 4.745976448059082\n",
            "[396 / 781], Loss: 4.622339248657227\n",
            "[397 / 781], Loss: 4.648751735687256\n",
            "[398 / 781], Loss: 4.576643466949463\n",
            "[399 / 781], Loss: 4.62204647064209\n",
            "[400 / 781], Loss: 4.734799385070801\n",
            "[401 / 781], Loss: 4.654597759246826\n",
            "[402 / 781], Loss: 4.612558364868164\n",
            "[403 / 781], Loss: 4.567564010620117\n",
            "[404 / 781], Loss: 4.65755033493042\n",
            "[405 / 781], Loss: 4.749819755554199\n",
            "[406 / 781], Loss: 4.793341636657715\n",
            "[407 / 781], Loss: 4.800887107849121\n",
            "[408 / 781], Loss: 4.601432800292969\n",
            "[409 / 781], Loss: 4.631714820861816\n",
            "[410 / 781], Loss: 4.607590675354004\n",
            "[411 / 781], Loss: 4.595463752746582\n",
            "[412 / 781], Loss: 4.538829326629639\n",
            "[413 / 781], Loss: 4.572803974151611\n",
            "[414 / 781], Loss: 4.717931270599365\n",
            "[415 / 781], Loss: 4.665374755859375\n",
            "[416 / 781], Loss: 4.521172523498535\n",
            "[417 / 781], Loss: 4.666260719299316\n",
            "[418 / 781], Loss: 4.618679046630859\n",
            "[419 / 781], Loss: 4.603470802307129\n",
            "[420 / 781], Loss: 4.688769340515137\n",
            "[421 / 781], Loss: 4.572790622711182\n",
            "[422 / 781], Loss: 4.629152297973633\n",
            "[423 / 781], Loss: 4.578850269317627\n",
            "[424 / 781], Loss: 4.630702018737793\n",
            "[425 / 781], Loss: 4.636334419250488\n",
            "[426 / 781], Loss: 4.685755729675293\n",
            "[427 / 781], Loss: 4.613908767700195\n",
            "[428 / 781], Loss: 4.626341342926025\n",
            "[429 / 781], Loss: 4.539857387542725\n",
            "[430 / 781], Loss: 4.59104061126709\n",
            "[431 / 781], Loss: 4.595630645751953\n",
            "[432 / 781], Loss: 4.688421249389648\n",
            "[433 / 781], Loss: 4.519179344177246\n",
            "[434 / 781], Loss: 4.684691429138184\n",
            "[435 / 781], Loss: 4.651861667633057\n",
            "[436 / 781], Loss: 4.612130641937256\n",
            "[437 / 781], Loss: 4.689993381500244\n",
            "[438 / 781], Loss: 4.538934230804443\n",
            "[439 / 781], Loss: 4.61545991897583\n",
            "[440 / 781], Loss: 4.598219871520996\n",
            "[441 / 781], Loss: 4.596689224243164\n",
            "[442 / 781], Loss: 4.512170791625977\n",
            "[443 / 781], Loss: 4.504494667053223\n",
            "[444 / 781], Loss: 4.53523588180542\n",
            "[445 / 781], Loss: 4.641138076782227\n",
            "[446 / 781], Loss: 4.516156196594238\n",
            "[447 / 781], Loss: 4.613358020782471\n",
            "[448 / 781], Loss: 4.476590633392334\n",
            "[449 / 781], Loss: 4.4942450523376465\n",
            "[450 / 781], Loss: 4.605599403381348\n",
            "[451 / 781], Loss: 4.639964580535889\n",
            "[452 / 781], Loss: 4.634218692779541\n",
            "[453 / 781], Loss: 4.621066093444824\n",
            "[454 / 781], Loss: 4.529937744140625\n",
            "[455 / 781], Loss: 4.453908920288086\n",
            "[456 / 781], Loss: 4.474341869354248\n",
            "[457 / 781], Loss: 4.5079169273376465\n",
            "[458 / 781], Loss: 4.592979431152344\n",
            "[459 / 781], Loss: 4.621054172515869\n",
            "[460 / 781], Loss: 4.603316783905029\n",
            "[461 / 781], Loss: 4.5803751945495605\n",
            "[462 / 781], Loss: 4.531899929046631\n",
            "[463 / 781], Loss: 4.430269241333008\n",
            "[464 / 781], Loss: 4.552470684051514\n",
            "[465 / 781], Loss: 4.4962286949157715\n",
            "[466 / 781], Loss: 4.462708950042725\n",
            "[467 / 781], Loss: 4.555989742279053\n",
            "[468 / 781], Loss: 4.575135707855225\n",
            "[469 / 781], Loss: 4.54534912109375\n",
            "[470 / 781], Loss: 4.420851707458496\n",
            "[471 / 781], Loss: 4.516841888427734\n",
            "[472 / 781], Loss: 4.593379497528076\n",
            "[473 / 781], Loss: 4.52131986618042\n",
            "[474 / 781], Loss: 4.4765167236328125\n",
            "[475 / 781], Loss: 4.56224250793457\n",
            "[476 / 781], Loss: 4.470474720001221\n",
            "[477 / 781], Loss: 4.444037437438965\n",
            "[478 / 781], Loss: 4.470183849334717\n",
            "[479 / 781], Loss: 4.400847911834717\n",
            "[480 / 781], Loss: 4.4875922203063965\n",
            "[481 / 781], Loss: 4.374544143676758\n",
            "[482 / 781], Loss: 4.415714740753174\n",
            "[483 / 781], Loss: 4.55430269241333\n",
            "[484 / 781], Loss: 4.609016418457031\n",
            "[485 / 781], Loss: 4.554809093475342\n",
            "[486 / 781], Loss: 4.473224639892578\n",
            "[487 / 781], Loss: 4.3183722496032715\n",
            "[488 / 781], Loss: 4.486468315124512\n",
            "[489 / 781], Loss: 4.337364196777344\n",
            "[490 / 781], Loss: 4.470058441162109\n",
            "[491 / 781], Loss: 4.4314985275268555\n",
            "[492 / 781], Loss: 4.490774154663086\n",
            "[493 / 781], Loss: 4.5704264640808105\n",
            "[494 / 781], Loss: 4.4025044441223145\n",
            "[495 / 781], Loss: 4.574163913726807\n",
            "[496 / 781], Loss: 4.55015754699707\n",
            "[497 / 781], Loss: 4.565222263336182\n",
            "[498 / 781], Loss: 4.545642375946045\n",
            "[499 / 781], Loss: 4.454739570617676\n",
            "[500 / 781], Loss: 4.310287952423096\n",
            "[501 / 781], Loss: 4.539346694946289\n",
            "[502 / 781], Loss: 4.46536111831665\n",
            "[503 / 781], Loss: 4.519270420074463\n",
            "[504 / 781], Loss: 4.51379919052124\n",
            "[505 / 781], Loss: 4.4321699142456055\n",
            "[506 / 781], Loss: 4.406182289123535\n",
            "[507 / 781], Loss: 4.545949935913086\n",
            "[508 / 781], Loss: 4.325506210327148\n",
            "[509 / 781], Loss: 4.386398792266846\n",
            "[510 / 781], Loss: 4.344882488250732\n",
            "[511 / 781], Loss: 4.379173755645752\n",
            "[512 / 781], Loss: 4.5553879737854\n",
            "[513 / 781], Loss: 4.436394214630127\n",
            "[514 / 781], Loss: 4.583330154418945\n",
            "[515 / 781], Loss: 4.391462326049805\n",
            "[516 / 781], Loss: 4.350412368774414\n",
            "[517 / 781], Loss: 4.4811506271362305\n",
            "[518 / 781], Loss: 4.42136287689209\n",
            "[519 / 781], Loss: 4.493373870849609\n",
            "[520 / 781], Loss: 4.431116104125977\n",
            "[521 / 781], Loss: 4.256082534790039\n",
            "[522 / 781], Loss: 4.4703240394592285\n",
            "[523 / 781], Loss: 4.33534574508667\n",
            "[524 / 781], Loss: 4.450314521789551\n",
            "[525 / 781], Loss: 4.328585624694824\n",
            "[526 / 781], Loss: 4.387490272521973\n",
            "[527 / 781], Loss: 4.395535469055176\n",
            "[528 / 781], Loss: 4.478366851806641\n",
            "[529 / 781], Loss: 4.336834907531738\n",
            "[530 / 781], Loss: 4.4476799964904785\n",
            "[531 / 781], Loss: 4.390554904937744\n",
            "[532 / 781], Loss: 4.476912975311279\n",
            "[533 / 781], Loss: 4.325311183929443\n",
            "[534 / 781], Loss: 4.389032363891602\n",
            "[535 / 781], Loss: 4.458850383758545\n",
            "[536 / 781], Loss: 4.337853908538818\n",
            "[537 / 781], Loss: 4.275392532348633\n",
            "[538 / 781], Loss: 4.3879618644714355\n",
            "[539 / 781], Loss: 4.28676700592041\n",
            "[540 / 781], Loss: 4.484082221984863\n",
            "[541 / 781], Loss: 4.317917823791504\n",
            "[542 / 781], Loss: 4.445637226104736\n",
            "[543 / 781], Loss: 4.291656970977783\n",
            "[544 / 781], Loss: 4.315455436706543\n",
            "[545 / 781], Loss: 4.446796894073486\n",
            "[546 / 781], Loss: 4.480218887329102\n",
            "[547 / 781], Loss: 4.3524980545043945\n",
            "[548 / 781], Loss: 4.298825740814209\n",
            "[549 / 781], Loss: 4.487813472747803\n",
            "[550 / 781], Loss: 4.384524345397949\n",
            "[551 / 781], Loss: 4.409013748168945\n",
            "[552 / 781], Loss: 4.222028732299805\n",
            "[553 / 781], Loss: 4.43875789642334\n",
            "[554 / 781], Loss: 4.395677089691162\n",
            "[555 / 781], Loss: 4.3358635902404785\n",
            "[556 / 781], Loss: 4.462735176086426\n",
            "[557 / 781], Loss: 4.1774749755859375\n",
            "[558 / 781], Loss: 4.363318920135498\n",
            "[559 / 781], Loss: 4.392476558685303\n",
            "[560 / 781], Loss: 4.14459753036499\n",
            "[561 / 781], Loss: 4.296442985534668\n",
            "[562 / 781], Loss: 4.581082344055176\n",
            "[563 / 781], Loss: 4.239545822143555\n",
            "[564 / 781], Loss: 4.486727237701416\n",
            "[565 / 781], Loss: 4.435718536376953\n",
            "[566 / 781], Loss: 4.224459648132324\n",
            "[567 / 781], Loss: 4.47088098526001\n",
            "[568 / 781], Loss: 4.29287576675415\n",
            "[569 / 781], Loss: 4.307185173034668\n",
            "[570 / 781], Loss: 4.4290361404418945\n",
            "[571 / 781], Loss: 4.252405166625977\n",
            "[572 / 781], Loss: 4.327673435211182\n",
            "[573 / 781], Loss: 4.303210258483887\n",
            "[574 / 781], Loss: 4.275458335876465\n",
            "[575 / 781], Loss: 4.1783013343811035\n",
            "[576 / 781], Loss: 4.334503173828125\n",
            "[577 / 781], Loss: 4.293631076812744\n",
            "[578 / 781], Loss: 4.340890884399414\n",
            "[579 / 781], Loss: 4.218906402587891\n",
            "[580 / 781], Loss: 4.359144687652588\n",
            "[581 / 781], Loss: 4.240286827087402\n",
            "[582 / 781], Loss: 4.461278438568115\n",
            "[583 / 781], Loss: 4.41045618057251\n",
            "[584 / 781], Loss: 4.301798343658447\n",
            "[585 / 781], Loss: 4.4775071144104\n",
            "[586 / 781], Loss: 4.207649230957031\n",
            "[587 / 781], Loss: 4.27833890914917\n",
            "[588 / 781], Loss: 4.376138687133789\n",
            "[589 / 781], Loss: 4.334922790527344\n",
            "[590 / 781], Loss: 4.308205604553223\n",
            "[591 / 781], Loss: 4.446533679962158\n",
            "[592 / 781], Loss: 4.1890130043029785\n",
            "[593 / 781], Loss: 4.217864036560059\n",
            "[594 / 781], Loss: 4.204564571380615\n",
            "[595 / 781], Loss: 4.356173992156982\n",
            "[596 / 781], Loss: 4.440699577331543\n",
            "[597 / 781], Loss: 4.438137531280518\n",
            "[598 / 781], Loss: 4.340446949005127\n",
            "[599 / 781], Loss: 4.273171424865723\n",
            "[600 / 781], Loss: 4.521053314208984\n",
            "[601 / 781], Loss: 4.462242603302002\n",
            "[602 / 781], Loss: 4.576062202453613\n",
            "[603 / 781], Loss: 4.193697452545166\n",
            "[604 / 781], Loss: 4.213086128234863\n",
            "[605 / 781], Loss: 4.230255603790283\n",
            "[606 / 781], Loss: 4.347204685211182\n",
            "[607 / 781], Loss: 4.185107707977295\n",
            "[608 / 781], Loss: 4.329960823059082\n",
            "[609 / 781], Loss: 4.1982598304748535\n",
            "[610 / 781], Loss: 4.3463664054870605\n",
            "[611 / 781], Loss: 4.289944648742676\n",
            "[612 / 781], Loss: 4.409861087799072\n",
            "[613 / 781], Loss: 4.220121383666992\n",
            "[614 / 781], Loss: 4.351373672485352\n",
            "[615 / 781], Loss: 4.382896900177002\n",
            "[616 / 781], Loss: 4.280365943908691\n",
            "[617 / 781], Loss: 4.271729946136475\n",
            "[618 / 781], Loss: 4.331773281097412\n",
            "[619 / 781], Loss: 4.326763153076172\n",
            "[620 / 781], Loss: 4.280764102935791\n",
            "[621 / 781], Loss: 4.238940238952637\n",
            "[622 / 781], Loss: 4.1646928787231445\n",
            "[623 / 781], Loss: 4.419064998626709\n",
            "[624 / 781], Loss: 4.2557220458984375\n",
            "[625 / 781], Loss: 4.250646114349365\n",
            "[626 / 781], Loss: 4.34810733795166\n",
            "[627 / 781], Loss: 4.2038140296936035\n",
            "[628 / 781], Loss: 4.286561012268066\n",
            "[629 / 781], Loss: 4.172946929931641\n",
            "[630 / 781], Loss: 4.265037536621094\n",
            "[631 / 781], Loss: 4.268252372741699\n",
            "[632 / 781], Loss: 4.370095252990723\n",
            "[633 / 781], Loss: 4.202371597290039\n",
            "[634 / 781], Loss: 4.063363075256348\n",
            "[635 / 781], Loss: 4.15473747253418\n",
            "[636 / 781], Loss: 4.299654006958008\n",
            "[637 / 781], Loss: 4.118863582611084\n",
            "[638 / 781], Loss: 4.318869113922119\n",
            "[639 / 781], Loss: 4.305854320526123\n",
            "[640 / 781], Loss: 4.17735481262207\n",
            "[641 / 781], Loss: 4.158145904541016\n",
            "[642 / 781], Loss: 4.235839366912842\n",
            "[643 / 781], Loss: 4.320204734802246\n",
            "[644 / 781], Loss: 4.23444128036499\n",
            "[645 / 781], Loss: 4.270580291748047\n",
            "[646 / 781], Loss: 4.171947479248047\n",
            "[647 / 781], Loss: 4.267159461975098\n",
            "[648 / 781], Loss: 4.124574184417725\n",
            "[649 / 781], Loss: 4.386401653289795\n",
            "[650 / 781], Loss: 4.289165019989014\n",
            "[651 / 781], Loss: 4.286136150360107\n",
            "[652 / 781], Loss: 4.327189922332764\n",
            "[653 / 781], Loss: 4.097197532653809\n",
            "[654 / 781], Loss: 4.25938081741333\n",
            "[655 / 781], Loss: 4.111855506896973\n",
            "[656 / 781], Loss: 4.225214958190918\n",
            "[657 / 781], Loss: 4.272116661071777\n",
            "[658 / 781], Loss: 4.214804649353027\n",
            "[659 / 781], Loss: 4.345582485198975\n",
            "[660 / 781], Loss: 4.106950759887695\n",
            "[661 / 781], Loss: 4.29947566986084\n",
            "[662 / 781], Loss: 4.274937629699707\n",
            "[663 / 781], Loss: 4.395885944366455\n",
            "[664 / 781], Loss: 4.217535018920898\n",
            "[665 / 781], Loss: 4.007364749908447\n",
            "[666 / 781], Loss: 4.177358150482178\n",
            "[667 / 781], Loss: 4.206207275390625\n",
            "[668 / 781], Loss: 4.232702255249023\n",
            "[669 / 781], Loss: 4.163403511047363\n",
            "[670 / 781], Loss: 4.054588794708252\n",
            "[671 / 781], Loss: 4.131627559661865\n",
            "[672 / 781], Loss: 4.231303691864014\n",
            "[673 / 781], Loss: 4.160223484039307\n",
            "[674 / 781], Loss: 4.2130608558654785\n",
            "[675 / 781], Loss: 4.281761646270752\n",
            "[676 / 781], Loss: 4.114926815032959\n",
            "[677 / 781], Loss: 4.10692024230957\n",
            "[678 / 781], Loss: 4.087240219116211\n",
            "[679 / 781], Loss: 4.297155857086182\n",
            "[680 / 781], Loss: 4.216985702514648\n",
            "[681 / 781], Loss: 4.06947135925293\n",
            "[682 / 781], Loss: 4.072311878204346\n",
            "[683 / 781], Loss: 4.278993606567383\n",
            "[684 / 781], Loss: 4.025503158569336\n",
            "[685 / 781], Loss: 4.161543846130371\n",
            "[686 / 781], Loss: 4.260244369506836\n",
            "[687 / 781], Loss: 4.111990451812744\n",
            "[688 / 781], Loss: 4.251036643981934\n",
            "[689 / 781], Loss: 4.087428092956543\n",
            "[690 / 781], Loss: 4.20024299621582\n",
            "[691 / 781], Loss: 4.2163472175598145\n",
            "[692 / 781], Loss: 4.238812446594238\n",
            "[693 / 781], Loss: 4.167387962341309\n",
            "[694 / 781], Loss: 4.267765522003174\n",
            "[695 / 781], Loss: 4.1474738121032715\n",
            "[696 / 781], Loss: 4.1383161544799805\n",
            "[697 / 781], Loss: 4.262670040130615\n",
            "[698 / 781], Loss: 4.0869598388671875\n",
            "[699 / 781], Loss: 4.209475040435791\n",
            "[700 / 781], Loss: 4.206911563873291\n",
            "[701 / 781], Loss: 4.14434289932251\n",
            "[702 / 781], Loss: 4.161471366882324\n",
            "[703 / 781], Loss: 4.158586025238037\n",
            "[704 / 781], Loss: 4.076394081115723\n",
            "[705 / 781], Loss: 3.975395441055298\n",
            "[706 / 781], Loss: 4.092221260070801\n",
            "[707 / 781], Loss: 4.113250255584717\n",
            "[708 / 781], Loss: 4.03068733215332\n",
            "[709 / 781], Loss: 3.9392683506011963\n",
            "[710 / 781], Loss: 4.02671480178833\n",
            "[711 / 781], Loss: 4.214870929718018\n",
            "[712 / 781], Loss: 4.226010799407959\n",
            "[713 / 781], Loss: 4.1296868324279785\n",
            "[714 / 781], Loss: 4.182143211364746\n",
            "[715 / 781], Loss: 4.254804611206055\n",
            "[716 / 781], Loss: 4.08653450012207\n",
            "[717 / 781], Loss: 4.1153740882873535\n",
            "[718 / 781], Loss: 4.081310749053955\n",
            "[719 / 781], Loss: 4.14969539642334\n",
            "[720 / 781], Loss: 4.247313499450684\n",
            "[721 / 781], Loss: 4.082398891448975\n",
            "[722 / 781], Loss: 3.906069278717041\n",
            "[723 / 781], Loss: 4.237250804901123\n",
            "[724 / 781], Loss: 4.246743202209473\n",
            "[725 / 781], Loss: 4.303508281707764\n",
            "[726 / 781], Loss: 4.280880451202393\n",
            "[727 / 781], Loss: 4.10904598236084\n",
            "[728 / 781], Loss: 3.9506092071533203\n",
            "[729 / 781], Loss: 4.055426597595215\n",
            "[730 / 781], Loss: 4.130669116973877\n",
            "[731 / 781], Loss: 4.013746738433838\n",
            "[732 / 781], Loss: 4.00043249130249\n",
            "[733 / 781], Loss: 4.109757900238037\n",
            "[734 / 781], Loss: 4.144216060638428\n",
            "[735 / 781], Loss: 4.0810627937316895\n",
            "[736 / 781], Loss: 3.930255889892578\n",
            "[737 / 781], Loss: 4.0368123054504395\n",
            "[738 / 781], Loss: 4.053211212158203\n",
            "[739 / 781], Loss: 4.112144470214844\n",
            "[740 / 781], Loss: 4.095798492431641\n",
            "[741 / 781], Loss: 4.084326267242432\n",
            "[742 / 781], Loss: 4.272583484649658\n",
            "[743 / 781], Loss: 4.072385311126709\n",
            "[744 / 781], Loss: 4.214193344116211\n",
            "[745 / 781], Loss: 4.224740028381348\n",
            "[746 / 781], Loss: 4.167596817016602\n",
            "[747 / 781], Loss: 4.233891010284424\n",
            "[748 / 781], Loss: 3.9344871044158936\n",
            "[749 / 781], Loss: 4.000763893127441\n",
            "[750 / 781], Loss: 4.180919647216797\n",
            "[751 / 781], Loss: 4.067633152008057\n",
            "[752 / 781], Loss: 4.307892799377441\n",
            "[753 / 781], Loss: 4.095503330230713\n",
            "[754 / 781], Loss: 3.984351873397827\n",
            "[755 / 781], Loss: 4.102136611938477\n",
            "[756 / 781], Loss: 4.015737533569336\n",
            "[757 / 781], Loss: 4.207604885101318\n",
            "[758 / 781], Loss: 4.0394415855407715\n",
            "[759 / 781], Loss: 4.038652420043945\n",
            "[760 / 781], Loss: 4.066071033477783\n",
            "[761 / 781], Loss: 3.8728742599487305\n",
            "[762 / 781], Loss: 4.122719764709473\n",
            "[763 / 781], Loss: 4.016456604003906\n",
            "[764 / 781], Loss: 4.016298770904541\n",
            "[765 / 781], Loss: 3.923180341720581\n",
            "[766 / 781], Loss: 3.914522647857666\n",
            "[767 / 781], Loss: 4.092167377471924\n",
            "[768 / 781], Loss: 3.840383768081665\n",
            "[769 / 781], Loss: 4.165761470794678\n",
            "[770 / 781], Loss: 4.123485088348389\n",
            "[771 / 781], Loss: 3.907714605331421\n",
            "[772 / 781], Loss: 3.9963929653167725\n",
            "[773 / 781], Loss: 3.9223685264587402\n",
            "[774 / 781], Loss: 4.148001670837402\n",
            "[775 / 781], Loss: 4.01086950302124\n",
            "[776 / 781], Loss: 3.9535577297210693\n",
            "[777 / 781], Loss: 3.976874589920044\n",
            "[778 / 781], Loss: 4.124520301818848\n",
            "[779 / 781], Loss: 4.182175159454346\n",
            "[780 / 781], Loss: 3.9987728595733643\n",
            "train Loss: 601.0863 Acc: 10.4725\n",
            "[0 / 781], Loss: 3.4385719299316406\n",
            "[1 / 781], Loss: 3.6897144317626953\n",
            "[2 / 781], Loss: 3.7003355026245117\n",
            "[3 / 781], Loss: 3.6409449577331543\n",
            "[4 / 781], Loss: 3.876779317855835\n",
            "[5 / 781], Loss: 3.608342170715332\n",
            "[6 / 781], Loss: 3.312922716140747\n",
            "[7 / 781], Loss: 3.6000561714172363\n",
            "[8 / 781], Loss: 3.676563262939453\n",
            "[9 / 781], Loss: 3.607311964035034\n",
            "[10 / 781], Loss: 3.854243040084839\n",
            "[11 / 781], Loss: 3.513442039489746\n",
            "[12 / 781], Loss: 3.884559154510498\n",
            "[13 / 781], Loss: 3.122802495956421\n",
            "[14 / 781], Loss: 3.523527145385742\n",
            "[15 / 781], Loss: 3.318432092666626\n",
            "[16 / 781], Loss: 3.773806571960449\n",
            "[17 / 781], Loss: 3.1997807025909424\n",
            "[18 / 781], Loss: 3.5831491947174072\n",
            "[19 / 781], Loss: 3.607722282409668\n",
            "[20 / 781], Loss: 3.7168095111846924\n",
            "[21 / 781], Loss: 3.597135066986084\n",
            "[22 / 781], Loss: 3.759371757507324\n",
            "[23 / 781], Loss: 3.607025623321533\n",
            "[24 / 781], Loss: 3.5782458782196045\n",
            "[25 / 781], Loss: 4.127684116363525\n",
            "[26 / 781], Loss: 3.7587831020355225\n",
            "[27 / 781], Loss: 3.783454656600952\n",
            "[28 / 781], Loss: 3.3020687103271484\n",
            "[29 / 781], Loss: 3.9495861530303955\n",
            "[30 / 781], Loss: 4.017465591430664\n",
            "[31 / 781], Loss: 3.7089216709136963\n",
            "[32 / 781], Loss: 3.6336803436279297\n",
            "[33 / 781], Loss: 3.515615940093994\n",
            "[34 / 781], Loss: 3.6607484817504883\n",
            "[35 / 781], Loss: 3.649312734603882\n",
            "[36 / 781], Loss: 3.958261251449585\n",
            "[37 / 781], Loss: 3.728381633758545\n",
            "[38 / 781], Loss: 3.9867634773254395\n",
            "[39 / 781], Loss: 3.5966739654541016\n",
            "[40 / 781], Loss: 3.3104844093322754\n",
            "[41 / 781], Loss: 3.5077171325683594\n",
            "[42 / 781], Loss: 3.212247371673584\n",
            "[43 / 781], Loss: 4.0440521240234375\n",
            "[44 / 781], Loss: 3.843560218811035\n",
            "[45 / 781], Loss: 3.7617759704589844\n",
            "[46 / 781], Loss: 3.5753660202026367\n",
            "[47 / 781], Loss: 3.633349895477295\n",
            "[48 / 781], Loss: 3.4471800327301025\n",
            "[49 / 781], Loss: 3.6276676654815674\n",
            "[50 / 781], Loss: 3.852236270904541\n",
            "[51 / 781], Loss: 3.9848759174346924\n",
            "[52 / 781], Loss: 3.7098188400268555\n",
            "[53 / 781], Loss: 3.915071964263916\n",
            "[54 / 781], Loss: 3.780261993408203\n",
            "[55 / 781], Loss: 3.9035403728485107\n",
            "[56 / 781], Loss: 3.8259332180023193\n",
            "[57 / 781], Loss: 3.696028232574463\n",
            "[58 / 781], Loss: 3.2942187786102295\n",
            "[59 / 781], Loss: 3.935622453689575\n",
            "[60 / 781], Loss: 3.873535633087158\n",
            "[61 / 781], Loss: 4.007992267608643\n",
            "[62 / 781], Loss: 3.7023258209228516\n",
            "[63 / 781], Loss: 3.6305994987487793\n",
            "[64 / 781], Loss: 3.474912405014038\n",
            "[65 / 781], Loss: 3.6398983001708984\n",
            "[66 / 781], Loss: 3.8815338611602783\n",
            "[67 / 781], Loss: 3.883106231689453\n",
            "[68 / 781], Loss: 3.45365047454834\n",
            "[69 / 781], Loss: 3.553523540496826\n",
            "[70 / 781], Loss: 3.7208540439605713\n",
            "[71 / 781], Loss: 3.1434898376464844\n",
            "[72 / 781], Loss: 3.5706787109375\n",
            "[73 / 781], Loss: 3.458667516708374\n",
            "[74 / 781], Loss: 3.4248900413513184\n",
            "[75 / 781], Loss: 3.8625664710998535\n",
            "[76 / 781], Loss: 3.530797243118286\n",
            "[77 / 781], Loss: 3.8732941150665283\n",
            "[78 / 781], Loss: 3.968116283416748\n",
            "[79 / 781], Loss: 3.5884220600128174\n",
            "[80 / 781], Loss: 3.6317553520202637\n",
            "[81 / 781], Loss: 3.717150926589966\n",
            "[82 / 781], Loss: 3.3479695320129395\n",
            "[83 / 781], Loss: 3.7890498638153076\n",
            "[84 / 781], Loss: 3.794645071029663\n",
            "[85 / 781], Loss: 3.9020814895629883\n",
            "[86 / 781], Loss: 3.526782751083374\n",
            "[87 / 781], Loss: 3.6498053073883057\n",
            "[88 / 781], Loss: 3.3731470108032227\n",
            "[89 / 781], Loss: 4.117410182952881\n",
            "[90 / 781], Loss: 3.4932801723480225\n",
            "[91 / 781], Loss: 3.413839817047119\n",
            "[92 / 781], Loss: 3.140085458755493\n",
            "[93 / 781], Loss: 3.742464065551758\n",
            "[94 / 781], Loss: 3.415449619293213\n",
            "[95 / 781], Loss: 3.5824637413024902\n",
            "[96 / 781], Loss: 3.5163347721099854\n",
            "[97 / 781], Loss: 3.4659857749938965\n",
            "[98 / 781], Loss: 3.997276544570923\n",
            "[99 / 781], Loss: 3.9837756156921387\n",
            "[100 / 781], Loss: 3.7269654273986816\n",
            "[101 / 781], Loss: 3.7029993534088135\n",
            "[102 / 781], Loss: 3.8904073238372803\n",
            "[103 / 781], Loss: 3.8169147968292236\n",
            "[104 / 781], Loss: 3.3949620723724365\n",
            "[105 / 781], Loss: 3.6455907821655273\n",
            "[106 / 781], Loss: 3.620513916015625\n",
            "[107 / 781], Loss: 3.5843615531921387\n",
            "[108 / 781], Loss: 3.5149576663970947\n",
            "[109 / 781], Loss: 3.5439467430114746\n",
            "[110 / 781], Loss: 3.7983922958374023\n",
            "[111 / 781], Loss: 3.800415277481079\n",
            "[112 / 781], Loss: 3.9668374061584473\n",
            "[113 / 781], Loss: 3.6534295082092285\n",
            "[114 / 781], Loss: 3.637768268585205\n",
            "[115 / 781], Loss: 3.5757577419281006\n",
            "[116 / 781], Loss: 3.8341214656829834\n",
            "[117 / 781], Loss: 3.188232421875\n",
            "[118 / 781], Loss: 3.945861577987671\n",
            "[119 / 781], Loss: 3.43076229095459\n",
            "[120 / 781], Loss: 3.7424240112304688\n",
            "[121 / 781], Loss: 3.8258609771728516\n",
            "[122 / 781], Loss: 3.5288426876068115\n",
            "[123 / 781], Loss: 3.4989969730377197\n",
            "[124 / 781], Loss: 4.0212578773498535\n",
            "[125 / 781], Loss: 3.6319005489349365\n",
            "[126 / 781], Loss: 3.386922836303711\n",
            "[127 / 781], Loss: 3.3127670288085938\n",
            "[128 / 781], Loss: 3.5436623096466064\n",
            "[129 / 781], Loss: 3.8398327827453613\n",
            "[130 / 781], Loss: 3.5578863620758057\n",
            "[131 / 781], Loss: 3.8267393112182617\n",
            "[132 / 781], Loss: 3.5843896865844727\n",
            "[133 / 781], Loss: 3.9400384426116943\n",
            "[134 / 781], Loss: 3.286240339279175\n",
            "[135 / 781], Loss: 3.123958110809326\n",
            "[136 / 781], Loss: 3.5071144104003906\n",
            "[137 / 781], Loss: 3.9008750915527344\n",
            "[138 / 781], Loss: 3.83247447013855\n",
            "[139 / 781], Loss: 3.635114908218384\n",
            "[140 / 781], Loss: 3.9277710914611816\n",
            "[141 / 781], Loss: 3.5270183086395264\n",
            "[142 / 781], Loss: 3.6339356899261475\n",
            "[143 / 781], Loss: 3.6745638847351074\n",
            "[144 / 781], Loss: 3.7033958435058594\n",
            "[145 / 781], Loss: 3.925708770751953\n",
            "[146 / 781], Loss: 3.4009766578674316\n",
            "[147 / 781], Loss: 3.6903834342956543\n",
            "[148 / 781], Loss: 3.7335126399993896\n",
            "[149 / 781], Loss: 3.7720532417297363\n",
            "[150 / 781], Loss: 3.412101984024048\n",
            "[151 / 781], Loss: 3.5411200523376465\n",
            "[152 / 781], Loss: 3.5463573932647705\n",
            "[153 / 781], Loss: 4.023753643035889\n",
            "[154 / 781], Loss: 3.894756555557251\n",
            "[155 / 781], Loss: 3.6204276084899902\n",
            "[156 / 781], Loss: 3.624018669128418\n",
            "[157 / 781], Loss: 3.726757287979126\n",
            "[158 / 781], Loss: 3.9350388050079346\n",
            "[159 / 781], Loss: 4.128198146820068\n",
            "[160 / 781], Loss: 3.547478199005127\n",
            "[161 / 781], Loss: 3.8787307739257812\n",
            "[162 / 781], Loss: 3.958134412765503\n",
            "[163 / 781], Loss: 3.8902957439422607\n",
            "[164 / 781], Loss: 3.1483194828033447\n",
            "[165 / 781], Loss: 3.590343475341797\n",
            "[166 / 781], Loss: 3.5582873821258545\n",
            "[167 / 781], Loss: 3.6822221279144287\n",
            "[168 / 781], Loss: 3.8398313522338867\n",
            "[169 / 781], Loss: 3.7672276496887207\n",
            "[170 / 781], Loss: 3.4576072692871094\n",
            "[171 / 781], Loss: 3.8538122177124023\n",
            "[172 / 781], Loss: 3.6691534519195557\n",
            "[173 / 781], Loss: 3.4657528400421143\n",
            "[174 / 781], Loss: 3.5345354080200195\n",
            "[175 / 781], Loss: 3.8249449729919434\n",
            "[176 / 781], Loss: 3.963454008102417\n",
            "[177 / 781], Loss: 3.8518238067626953\n",
            "[178 / 781], Loss: 3.7561423778533936\n",
            "[179 / 781], Loss: 3.564889430999756\n",
            "[180 / 781], Loss: 3.2269883155822754\n",
            "[181 / 781], Loss: 3.2221641540527344\n",
            "[182 / 781], Loss: 3.6801161766052246\n",
            "[183 / 781], Loss: 3.529191493988037\n",
            "[184 / 781], Loss: 3.6414260864257812\n",
            "[185 / 781], Loss: 3.4097373485565186\n",
            "[186 / 781], Loss: 3.3968801498413086\n",
            "[187 / 781], Loss: 4.077826499938965\n",
            "[188 / 781], Loss: 3.750561475753784\n",
            "[189 / 781], Loss: 3.8423500061035156\n",
            "[190 / 781], Loss: 3.597156286239624\n",
            "[191 / 781], Loss: 3.510164976119995\n",
            "[192 / 781], Loss: 3.50860595703125\n",
            "[193 / 781], Loss: 3.6976871490478516\n",
            "[194 / 781], Loss: 3.6767168045043945\n",
            "[195 / 781], Loss: 3.6154074668884277\n",
            "[196 / 781], Loss: 3.787839412689209\n",
            "[197 / 781], Loss: 3.81652569770813\n",
            "[198 / 781], Loss: 3.7383604049682617\n",
            "[199 / 781], Loss: 4.03029203414917\n",
            "[200 / 781], Loss: 3.646315336227417\n",
            "[201 / 781], Loss: 3.3320608139038086\n",
            "[202 / 781], Loss: 3.62090802192688\n",
            "[203 / 781], Loss: 3.691710948944092\n",
            "[204 / 781], Loss: 3.7396116256713867\n",
            "[205 / 781], Loss: 3.853668212890625\n",
            "[206 / 781], Loss: 3.4411675930023193\n",
            "[207 / 781], Loss: 3.6421990394592285\n",
            "[208 / 781], Loss: 3.5292720794677734\n",
            "[209 / 781], Loss: 3.6459450721740723\n",
            "[210 / 781], Loss: 3.7419304847717285\n",
            "[211 / 781], Loss: 3.852839946746826\n",
            "[212 / 781], Loss: 3.7326154708862305\n",
            "[213 / 781], Loss: 3.4270122051239014\n",
            "[214 / 781], Loss: 3.5106396675109863\n",
            "[215 / 781], Loss: 3.4499399662017822\n",
            "[216 / 781], Loss: 4.020660400390625\n",
            "[217 / 781], Loss: 3.275108814239502\n",
            "[218 / 781], Loss: 3.741245746612549\n",
            "[219 / 781], Loss: 3.938815116882324\n",
            "[220 / 781], Loss: 3.9459853172302246\n",
            "[221 / 781], Loss: 3.6144704818725586\n",
            "[222 / 781], Loss: 3.963170051574707\n",
            "[223 / 781], Loss: 3.8454060554504395\n",
            "[224 / 781], Loss: 3.4983253479003906\n",
            "[225 / 781], Loss: 3.6935935020446777\n",
            "[226 / 781], Loss: 3.7849364280700684\n",
            "[227 / 781], Loss: 3.935318946838379\n",
            "[228 / 781], Loss: 4.010516166687012\n",
            "[229 / 781], Loss: 3.9537737369537354\n",
            "[230 / 781], Loss: 3.643822193145752\n",
            "[231 / 781], Loss: 3.6494832038879395\n",
            "[232 / 781], Loss: 3.682804822921753\n",
            "[233 / 781], Loss: 3.686121940612793\n",
            "[234 / 781], Loss: 3.6428515911102295\n",
            "[235 / 781], Loss: 3.525578260421753\n",
            "[236 / 781], Loss: 3.51200270652771\n",
            "[237 / 781], Loss: 3.621309757232666\n",
            "[238 / 781], Loss: 3.5638816356658936\n",
            "[239 / 781], Loss: 3.5725088119506836\n",
            "[240 / 781], Loss: 3.611922025680542\n",
            "[241 / 781], Loss: 3.2937710285186768\n",
            "[242 / 781], Loss: 3.4273478984832764\n",
            "[243 / 781], Loss: 3.7107837200164795\n",
            "[244 / 781], Loss: 3.60693097114563\n",
            "[245 / 781], Loss: 3.6254043579101562\n",
            "[246 / 781], Loss: 3.6167893409729004\n",
            "[247 / 781], Loss: 3.396796464920044\n",
            "[248 / 781], Loss: 3.7841813564300537\n",
            "[249 / 781], Loss: 3.8801217079162598\n",
            "[250 / 781], Loss: 3.6376891136169434\n",
            "[251 / 781], Loss: 3.97316837310791\n",
            "[252 / 781], Loss: 4.035299777984619\n",
            "[253 / 781], Loss: 4.341094017028809\n",
            "[254 / 781], Loss: 3.8401877880096436\n",
            "[255 / 781], Loss: 3.462099075317383\n",
            "[256 / 781], Loss: 3.439147472381592\n",
            "[257 / 781], Loss: 3.75495982170105\n",
            "[258 / 781], Loss: 3.623826503753662\n",
            "[259 / 781], Loss: 3.554163932800293\n",
            "[260 / 781], Loss: 3.2546465396881104\n",
            "[261 / 781], Loss: 3.6516027450561523\n",
            "[262 / 781], Loss: 4.071518898010254\n",
            "[263 / 781], Loss: 3.9093263149261475\n",
            "[264 / 781], Loss: 3.637474536895752\n",
            "[265 / 781], Loss: 3.516982078552246\n",
            "[266 / 781], Loss: 4.1226372718811035\n",
            "[267 / 781], Loss: 3.456730604171753\n",
            "[268 / 781], Loss: 3.729421854019165\n",
            "[269 / 781], Loss: 4.001907825469971\n",
            "[270 / 781], Loss: 3.4123241901397705\n",
            "[271 / 781], Loss: 3.8200833797454834\n",
            "[272 / 781], Loss: 3.770918846130371\n",
            "[273 / 781], Loss: 3.7284352779388428\n",
            "[274 / 781], Loss: 3.3561930656433105\n",
            "[275 / 781], Loss: 3.827434539794922\n",
            "[276 / 781], Loss: 3.7537271976470947\n",
            "[277 / 781], Loss: 3.5029525756835938\n",
            "[278 / 781], Loss: 3.6671783924102783\n",
            "[279 / 781], Loss: 3.599259853363037\n",
            "[280 / 781], Loss: 3.8221213817596436\n",
            "[281 / 781], Loss: 3.717761516571045\n",
            "[282 / 781], Loss: 3.7872297763824463\n",
            "[283 / 781], Loss: 3.6395668983459473\n",
            "[284 / 781], Loss: 3.1705639362335205\n",
            "[285 / 781], Loss: 3.466287612915039\n",
            "[286 / 781], Loss: 3.662605047225952\n",
            "[287 / 781], Loss: 3.776587724685669\n",
            "[288 / 781], Loss: 3.7991323471069336\n",
            "[289 / 781], Loss: 3.8372726440429688\n",
            "[290 / 781], Loss: 3.7398734092712402\n",
            "[291 / 781], Loss: 3.5900368690490723\n",
            "[292 / 781], Loss: 3.9034526348114014\n",
            "[293 / 781], Loss: 3.623975992202759\n",
            "[294 / 781], Loss: 3.2861697673797607\n",
            "[295 / 781], Loss: 3.384139060974121\n",
            "[296 / 781], Loss: 3.9179728031158447\n",
            "[297 / 781], Loss: 4.061718463897705\n",
            "[298 / 781], Loss: 3.3587851524353027\n",
            "[299 / 781], Loss: 3.5551869869232178\n",
            "[300 / 781], Loss: 3.8215763568878174\n",
            "[301 / 781], Loss: 3.4030871391296387\n",
            "[302 / 781], Loss: 3.6008081436157227\n",
            "[303 / 781], Loss: 3.4306447505950928\n",
            "[304 / 781], Loss: 3.6403725147247314\n",
            "[305 / 781], Loss: 3.8083462715148926\n",
            "[306 / 781], Loss: 3.413464069366455\n",
            "[307 / 781], Loss: 3.5030174255371094\n",
            "[308 / 781], Loss: 3.4275150299072266\n",
            "[309 / 781], Loss: 3.194631338119507\n",
            "[310 / 781], Loss: 3.6061923503875732\n",
            "[311 / 781], Loss: 3.8474674224853516\n",
            "val Loss: 117.2368 Acc: 7.3173\n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "[0 / 781], Loss: 4.143777370452881\n",
            "[1 / 781], Loss: 3.9176456928253174\n",
            "[2 / 781], Loss: 4.024667263031006\n",
            "[3 / 781], Loss: 4.193770885467529\n",
            "[4 / 781], Loss: 3.96747088432312\n",
            "[5 / 781], Loss: 4.068123817443848\n",
            "[6 / 781], Loss: 3.9613640308380127\n",
            "[7 / 781], Loss: 4.189359664916992\n",
            "[8 / 781], Loss: 4.289628505706787\n",
            "[9 / 781], Loss: 3.9651787281036377\n",
            "[10 / 781], Loss: 3.9847145080566406\n",
            "[11 / 781], Loss: 4.147386074066162\n",
            "[12 / 781], Loss: 4.103975296020508\n",
            "[13 / 781], Loss: 3.9789180755615234\n",
            "[14 / 781], Loss: 4.06688117980957\n",
            "[15 / 781], Loss: 4.121121406555176\n",
            "[16 / 781], Loss: 4.2458600997924805\n",
            "[17 / 781], Loss: 3.89186954498291\n",
            "[18 / 781], Loss: 3.8342819213867188\n",
            "[19 / 781], Loss: 4.022067546844482\n",
            "[20 / 781], Loss: 3.9727678298950195\n",
            "[21 / 781], Loss: 4.033703327178955\n",
            "[22 / 781], Loss: 3.850419044494629\n",
            "[23 / 781], Loss: 4.078623294830322\n",
            "[24 / 781], Loss: 4.01403284072876\n",
            "[25 / 781], Loss: 3.958242893218994\n",
            "[26 / 781], Loss: 4.005989074707031\n",
            "[27 / 781], Loss: 3.981698751449585\n",
            "[28 / 781], Loss: 3.8436074256896973\n",
            "[29 / 781], Loss: 4.113102436065674\n",
            "[30 / 781], Loss: 4.116586208343506\n",
            "[31 / 781], Loss: 3.870567560195923\n",
            "[32 / 781], Loss: 4.0504889488220215\n",
            "[33 / 781], Loss: 4.023130893707275\n",
            "[34 / 781], Loss: 4.097285270690918\n",
            "[35 / 781], Loss: 4.02851676940918\n",
            "[36 / 781], Loss: 4.062878608703613\n",
            "[37 / 781], Loss: 4.005859375\n",
            "[38 / 781], Loss: 3.871264696121216\n",
            "[39 / 781], Loss: 3.900217294692993\n",
            "[40 / 781], Loss: 3.8578379154205322\n",
            "[41 / 781], Loss: 4.256662368774414\n",
            "[42 / 781], Loss: 4.144565582275391\n",
            "[43 / 781], Loss: 4.104262351989746\n",
            "[44 / 781], Loss: 4.1500067710876465\n",
            "[45 / 781], Loss: 3.985487222671509\n",
            "[46 / 781], Loss: 3.97664213180542\n",
            "[47 / 781], Loss: 3.9661905765533447\n",
            "[48 / 781], Loss: 4.067126750946045\n",
            "[49 / 781], Loss: 3.810680866241455\n",
            "[50 / 781], Loss: 4.031122207641602\n",
            "[51 / 781], Loss: 4.0247697830200195\n",
            "[52 / 781], Loss: 3.9968645572662354\n",
            "[53 / 781], Loss: 3.8683831691741943\n",
            "[54 / 781], Loss: 3.964599609375\n",
            "[55 / 781], Loss: 3.9834465980529785\n",
            "[56 / 781], Loss: 4.09706974029541\n",
            "[57 / 781], Loss: 3.979546546936035\n",
            "[58 / 781], Loss: 4.038363933563232\n",
            "[59 / 781], Loss: 4.185843467712402\n",
            "[60 / 781], Loss: 3.865596294403076\n",
            "[61 / 781], Loss: 4.207627773284912\n",
            "[62 / 781], Loss: 4.004599094390869\n",
            "[63 / 781], Loss: 3.9139511585235596\n",
            "[64 / 781], Loss: 4.19081449508667\n",
            "[65 / 781], Loss: 3.939971446990967\n",
            "[66 / 781], Loss: 4.095369338989258\n",
            "[67 / 781], Loss: 3.878868818283081\n",
            "[68 / 781], Loss: 3.8671069145202637\n",
            "[69 / 781], Loss: 4.135743141174316\n",
            "[70 / 781], Loss: 3.7613823413848877\n",
            "[71 / 781], Loss: 4.134470462799072\n",
            "[72 / 781], Loss: 3.7718260288238525\n",
            "[73 / 781], Loss: 4.031377792358398\n",
            "[74 / 781], Loss: 4.095418930053711\n",
            "[75 / 781], Loss: 4.03717565536499\n",
            "[76 / 781], Loss: 3.85550856590271\n",
            "[77 / 781], Loss: 3.925504684448242\n",
            "[78 / 781], Loss: 3.917799949645996\n",
            "[79 / 781], Loss: 3.677380084991455\n",
            "[80 / 781], Loss: 3.879844903945923\n",
            "[81 / 781], Loss: 4.030857086181641\n",
            "[82 / 781], Loss: 3.941465139389038\n",
            "[83 / 781], Loss: 3.9719066619873047\n",
            "[84 / 781], Loss: 4.006607532501221\n",
            "[85 / 781], Loss: 3.80877685546875\n",
            "[86 / 781], Loss: 4.0324578285217285\n",
            "[87 / 781], Loss: 3.8870530128479004\n",
            "[88 / 781], Loss: 4.076450347900391\n",
            "[89 / 781], Loss: 3.9422457218170166\n",
            "[90 / 781], Loss: 3.881554365158081\n",
            "[91 / 781], Loss: 3.923236846923828\n",
            "[92 / 781], Loss: 3.9428162574768066\n",
            "[93 / 781], Loss: 3.695361375808716\n",
            "[94 / 781], Loss: 4.0774993896484375\n",
            "[95 / 781], Loss: 4.0920023918151855\n",
            "[96 / 781], Loss: 3.8775389194488525\n",
            "[97 / 781], Loss: 3.930861234664917\n",
            "[98 / 781], Loss: 4.036102771759033\n",
            "[99 / 781], Loss: 3.829827070236206\n",
            "[100 / 781], Loss: 3.9098424911499023\n",
            "[101 / 781], Loss: 3.794398069381714\n",
            "[102 / 781], Loss: 3.933213949203491\n",
            "[103 / 781], Loss: 3.848736524581909\n",
            "[104 / 781], Loss: 3.8896169662475586\n",
            "[105 / 781], Loss: 3.913511037826538\n",
            "[106 / 781], Loss: 4.017406940460205\n",
            "[107 / 781], Loss: 3.905395984649658\n",
            "[108 / 781], Loss: 4.046356201171875\n",
            "[109 / 781], Loss: 3.9913039207458496\n",
            "[110 / 781], Loss: 3.9259514808654785\n",
            "[111 / 781], Loss: 3.8742594718933105\n",
            "[112 / 781], Loss: 3.6254193782806396\n",
            "[113 / 781], Loss: 3.910369634628296\n",
            "[114 / 781], Loss: 4.045177459716797\n",
            "[115 / 781], Loss: 3.9883949756622314\n",
            "[116 / 781], Loss: 3.600682020187378\n",
            "[117 / 781], Loss: 3.8579013347625732\n",
            "[118 / 781], Loss: 3.9788546562194824\n",
            "[119 / 781], Loss: 3.903968334197998\n",
            "[120 / 781], Loss: 4.348554611206055\n",
            "[121 / 781], Loss: 3.6921706199645996\n",
            "[122 / 781], Loss: 4.023311614990234\n",
            "[123 / 781], Loss: 3.9745917320251465\n",
            "[124 / 781], Loss: 3.971648931503296\n",
            "[125 / 781], Loss: 3.892354726791382\n",
            "[126 / 781], Loss: 3.816498041152954\n",
            "[127 / 781], Loss: 3.981384038925171\n",
            "[128 / 781], Loss: 4.109968662261963\n",
            "[129 / 781], Loss: 3.893080711364746\n",
            "[130 / 781], Loss: 3.7905070781707764\n",
            "[131 / 781], Loss: 3.634075164794922\n",
            "[132 / 781], Loss: 3.961646556854248\n",
            "[133 / 781], Loss: 3.8219528198242188\n",
            "[134 / 781], Loss: 3.980457305908203\n",
            "[135 / 781], Loss: 4.175222396850586\n",
            "[136 / 781], Loss: 3.893941879272461\n",
            "[137 / 781], Loss: 3.7280185222625732\n",
            "[138 / 781], Loss: 3.660477638244629\n",
            "[139 / 781], Loss: 4.0905046463012695\n",
            "[140 / 781], Loss: 4.074709415435791\n",
            "[141 / 781], Loss: 3.9384357929229736\n",
            "[142 / 781], Loss: 3.872673511505127\n",
            "[143 / 781], Loss: 4.008222579956055\n",
            "[144 / 781], Loss: 3.8875062465667725\n",
            "[145 / 781], Loss: 3.858365774154663\n",
            "[146 / 781], Loss: 3.785068988800049\n",
            "[147 / 781], Loss: 3.7488858699798584\n",
            "[148 / 781], Loss: 3.6775333881378174\n",
            "[149 / 781], Loss: 3.839876651763916\n",
            "[150 / 781], Loss: 4.010430812835693\n",
            "[151 / 781], Loss: 3.8837392330169678\n",
            "[152 / 781], Loss: 3.812081813812256\n",
            "[153 / 781], Loss: 3.979367733001709\n",
            "[154 / 781], Loss: 3.719589948654175\n",
            "[155 / 781], Loss: 3.8848016262054443\n",
            "[156 / 781], Loss: 3.9249930381774902\n",
            "[157 / 781], Loss: 3.8211584091186523\n",
            "[158 / 781], Loss: 3.818671703338623\n",
            "[159 / 781], Loss: 3.746814012527466\n",
            "[160 / 781], Loss: 3.8162875175476074\n",
            "[161 / 781], Loss: 3.9790782928466797\n",
            "[162 / 781], Loss: 3.8676650524139404\n",
            "[163 / 781], Loss: 3.9000444412231445\n",
            "[164 / 781], Loss: 4.027368068695068\n",
            "[165 / 781], Loss: 3.701038360595703\n",
            "[166 / 781], Loss: 3.623547077178955\n",
            "[167 / 781], Loss: 3.7631661891937256\n",
            "[168 / 781], Loss: 3.692425489425659\n",
            "[169 / 781], Loss: 3.974153995513916\n",
            "[170 / 781], Loss: 3.90964674949646\n",
            "[171 / 781], Loss: 3.826519250869751\n",
            "[172 / 781], Loss: 3.815260648727417\n",
            "[173 / 781], Loss: 3.7440714836120605\n",
            "[174 / 781], Loss: 4.003037452697754\n",
            "[175 / 781], Loss: 3.7210116386413574\n",
            "[176 / 781], Loss: 3.832637310028076\n",
            "[177 / 781], Loss: 3.762453556060791\n",
            "[178 / 781], Loss: 3.882190704345703\n",
            "[179 / 781], Loss: 3.905205011367798\n",
            "[180 / 781], Loss: 4.0133957862854\n",
            "[181 / 781], Loss: 3.8429949283599854\n",
            "[182 / 781], Loss: 3.82891845703125\n",
            "[183 / 781], Loss: 3.9795608520507812\n",
            "[184 / 781], Loss: 3.827507495880127\n",
            "[185 / 781], Loss: 3.8088574409484863\n",
            "[186 / 781], Loss: 3.9081952571868896\n",
            "[187 / 781], Loss: 3.919482946395874\n",
            "[188 / 781], Loss: 3.5836663246154785\n",
            "[189 / 781], Loss: 3.9683406352996826\n",
            "[190 / 781], Loss: 3.7828705310821533\n",
            "[191 / 781], Loss: 3.6426615715026855\n",
            "[192 / 781], Loss: 3.7508106231689453\n",
            "[193 / 781], Loss: 3.9044666290283203\n",
            "[194 / 781], Loss: 4.067146301269531\n",
            "[195 / 781], Loss: 3.787621259689331\n",
            "[196 / 781], Loss: 3.817640781402588\n",
            "[197 / 781], Loss: 3.7100605964660645\n",
            "[198 / 781], Loss: 3.820124626159668\n",
            "[199 / 781], Loss: 3.60581636428833\n",
            "[200 / 781], Loss: 3.817258834838867\n",
            "[201 / 781], Loss: 3.8444201946258545\n",
            "[202 / 781], Loss: 3.9874885082244873\n",
            "[203 / 781], Loss: 3.622154474258423\n",
            "[204 / 781], Loss: 3.8484115600585938\n",
            "[205 / 781], Loss: 3.6714234352111816\n",
            "[206 / 781], Loss: 3.7607383728027344\n",
            "[207 / 781], Loss: 3.7087526321411133\n",
            "[208 / 781], Loss: 3.721176862716675\n",
            "[209 / 781], Loss: 4.0585527420043945\n",
            "[210 / 781], Loss: 3.6456234455108643\n",
            "[211 / 781], Loss: 3.7909533977508545\n",
            "[212 / 781], Loss: 3.5640292167663574\n",
            "[213 / 781], Loss: 3.933483600616455\n",
            "[214 / 781], Loss: 3.8214144706726074\n",
            "[215 / 781], Loss: 3.4477267265319824\n",
            "[216 / 781], Loss: 3.932131052017212\n",
            "[217 / 781], Loss: 3.657838821411133\n",
            "[218 / 781], Loss: 3.6216847896575928\n",
            "[219 / 781], Loss: 3.9011478424072266\n",
            "[220 / 781], Loss: 3.6096105575561523\n",
            "[221 / 781], Loss: 3.6613922119140625\n",
            "[222 / 781], Loss: 3.7491700649261475\n",
            "[223 / 781], Loss: 3.8604040145874023\n",
            "[224 / 781], Loss: 3.7756190299987793\n",
            "[225 / 781], Loss: 3.5771450996398926\n",
            "[226 / 781], Loss: 3.8311386108398438\n",
            "[227 / 781], Loss: 3.7386093139648438\n",
            "[228 / 781], Loss: 3.819777727127075\n",
            "[229 / 781], Loss: 4.0438642501831055\n",
            "[230 / 781], Loss: 3.908209800720215\n",
            "[231 / 781], Loss: 3.9511725902557373\n",
            "[232 / 781], Loss: 3.815730333328247\n",
            "[233 / 781], Loss: 3.7892327308654785\n",
            "[234 / 781], Loss: 3.788092613220215\n",
            "[235 / 781], Loss: 4.047420501708984\n",
            "[236 / 781], Loss: 3.9118118286132812\n",
            "[237 / 781], Loss: 3.7856547832489014\n",
            "[238 / 781], Loss: 3.874476432800293\n",
            "[239 / 781], Loss: 3.6955032348632812\n",
            "[240 / 781], Loss: 3.7142889499664307\n",
            "[241 / 781], Loss: 3.8438098430633545\n",
            "[242 / 781], Loss: 3.90252423286438\n",
            "[243 / 781], Loss: 3.6465251445770264\n",
            "[244 / 781], Loss: 3.822890043258667\n",
            "[245 / 781], Loss: 3.6448774337768555\n",
            "[246 / 781], Loss: 3.944134473800659\n",
            "[247 / 781], Loss: 3.8738203048706055\n",
            "[248 / 781], Loss: 3.8393871784210205\n",
            "[249 / 781], Loss: 3.9222419261932373\n",
            "[250 / 781], Loss: 3.510730028152466\n",
            "[251 / 781], Loss: 3.6202778816223145\n",
            "[252 / 781], Loss: 3.7152934074401855\n",
            "[253 / 781], Loss: 3.9035964012145996\n",
            "[254 / 781], Loss: 3.7854080200195312\n",
            "[255 / 781], Loss: 3.956782102584839\n",
            "[256 / 781], Loss: 3.683075428009033\n",
            "[257 / 781], Loss: 4.02022123336792\n",
            "[258 / 781], Loss: 3.8196089267730713\n",
            "[259 / 781], Loss: 3.860506057739258\n",
            "[260 / 781], Loss: 3.847505569458008\n",
            "[261 / 781], Loss: 3.7487356662750244\n",
            "[262 / 781], Loss: 3.6588680744171143\n",
            "[263 / 781], Loss: 3.848527669906616\n",
            "[264 / 781], Loss: 3.9741404056549072\n",
            "[265 / 781], Loss: 3.5689685344696045\n",
            "[266 / 781], Loss: 3.6981124877929688\n",
            "[267 / 781], Loss: 3.865241289138794\n",
            "[268 / 781], Loss: 3.8319919109344482\n",
            "[269 / 781], Loss: 3.6367647647857666\n",
            "[270 / 781], Loss: 3.95188570022583\n",
            "[271 / 781], Loss: 3.518448829650879\n",
            "[272 / 781], Loss: 3.588857412338257\n",
            "[273 / 781], Loss: 3.7730846405029297\n",
            "[274 / 781], Loss: 3.7915890216827393\n",
            "[275 / 781], Loss: 3.711625814437866\n",
            "[276 / 781], Loss: 3.867166519165039\n",
            "[277 / 781], Loss: 3.8376657962799072\n",
            "[278 / 781], Loss: 3.9451301097869873\n",
            "[279 / 781], Loss: 3.789921283721924\n",
            "[280 / 781], Loss: 3.805065870285034\n",
            "[281 / 781], Loss: 3.7865428924560547\n",
            "[282 / 781], Loss: 3.605168342590332\n",
            "[283 / 781], Loss: 3.8027400970458984\n",
            "[284 / 781], Loss: 3.9003641605377197\n",
            "[285 / 781], Loss: 3.75671124458313\n",
            "[286 / 781], Loss: 3.620910167694092\n",
            "[287 / 781], Loss: 3.939293622970581\n",
            "[288 / 781], Loss: 3.805459976196289\n",
            "[289 / 781], Loss: 3.8511548042297363\n",
            "[290 / 781], Loss: 3.6220645904541016\n",
            "[291 / 781], Loss: 3.6269140243530273\n",
            "[292 / 781], Loss: 3.615522861480713\n",
            "[293 / 781], Loss: 3.853012800216675\n",
            "[294 / 781], Loss: 3.8792848587036133\n",
            "[295 / 781], Loss: 3.7260167598724365\n",
            "[296 / 781], Loss: 3.6975178718566895\n",
            "[297 / 781], Loss: 3.7117366790771484\n",
            "[298 / 781], Loss: 3.588754653930664\n",
            "[299 / 781], Loss: 3.6381778717041016\n",
            "[300 / 781], Loss: 3.4187090396881104\n",
            "[301 / 781], Loss: 3.7759509086608887\n",
            "[302 / 781], Loss: 3.752206563949585\n",
            "[303 / 781], Loss: 3.6527576446533203\n",
            "[304 / 781], Loss: 3.6441354751586914\n",
            "[305 / 781], Loss: 3.5862762928009033\n",
            "[306 / 781], Loss: 3.8254570960998535\n",
            "[307 / 781], Loss: 3.624990224838257\n",
            "[308 / 781], Loss: 3.734783887863159\n",
            "[309 / 781], Loss: 3.5645945072174072\n",
            "[310 / 781], Loss: 3.6617038249969482\n",
            "[311 / 781], Loss: 3.792418956756592\n",
            "[312 / 781], Loss: 3.8535001277923584\n",
            "[313 / 781], Loss: 3.5561251640319824\n",
            "[314 / 781], Loss: 3.6300694942474365\n",
            "[315 / 781], Loss: 3.820678234100342\n",
            "[316 / 781], Loss: 3.812366247177124\n",
            "[317 / 781], Loss: 3.792492151260376\n",
            "[318 / 781], Loss: 3.631527900695801\n",
            "[319 / 781], Loss: 3.5681350231170654\n",
            "[320 / 781], Loss: 3.7485687732696533\n",
            "[321 / 781], Loss: 3.760749340057373\n",
            "[322 / 781], Loss: 3.9481923580169678\n",
            "[323 / 781], Loss: 3.7014055252075195\n",
            "[324 / 781], Loss: 3.74491286277771\n",
            "[325 / 781], Loss: 3.6374683380126953\n",
            "[326 / 781], Loss: 3.7976715564727783\n",
            "[327 / 781], Loss: 3.8367087841033936\n",
            "[328 / 781], Loss: 3.782398223876953\n",
            "[329 / 781], Loss: 3.651000499725342\n",
            "[330 / 781], Loss: 3.693509817123413\n",
            "[331 / 781], Loss: 3.732689380645752\n",
            "[332 / 781], Loss: 3.5745792388916016\n",
            "[333 / 781], Loss: 4.114490032196045\n",
            "[334 / 781], Loss: 3.883683681488037\n",
            "[335 / 781], Loss: 3.744150161743164\n",
            "[336 / 781], Loss: 3.6770761013031006\n",
            "[337 / 781], Loss: 3.6514954566955566\n",
            "[338 / 781], Loss: 3.711522340774536\n",
            "[339 / 781], Loss: 3.6958167552948\n",
            "[340 / 781], Loss: 3.5139920711517334\n",
            "[341 / 781], Loss: 3.66044020652771\n",
            "[342 / 781], Loss: 3.583702325820923\n",
            "[343 / 781], Loss: 3.7041196823120117\n",
            "[344 / 781], Loss: 3.5830771923065186\n",
            "[345 / 781], Loss: 3.7691543102264404\n",
            "[346 / 781], Loss: 3.878593683242798\n",
            "[347 / 781], Loss: 3.653371572494507\n",
            "[348 / 781], Loss: 3.5835936069488525\n",
            "[349 / 781], Loss: 3.7386529445648193\n",
            "[350 / 781], Loss: 3.689896583557129\n",
            "[351 / 781], Loss: 3.6557741165161133\n",
            "[352 / 781], Loss: 3.775139570236206\n",
            "[353 / 781], Loss: 3.784238815307617\n",
            "[354 / 781], Loss: 3.580453872680664\n",
            "[355 / 781], Loss: 3.5428898334503174\n",
            "[356 / 781], Loss: 3.662519931793213\n",
            "[357 / 781], Loss: 3.940361261367798\n",
            "[358 / 781], Loss: 3.8576619625091553\n",
            "[359 / 781], Loss: 3.8105576038360596\n",
            "[360 / 781], Loss: 3.681295871734619\n",
            "[361 / 781], Loss: 3.830993890762329\n",
            "[362 / 781], Loss: 3.510800838470459\n",
            "[363 / 781], Loss: 3.775447130203247\n",
            "[364 / 781], Loss: 3.68203067779541\n",
            "[365 / 781], Loss: 3.877235174179077\n",
            "[366 / 781], Loss: 3.557084798812866\n",
            "[367 / 781], Loss: 3.707200288772583\n",
            "[368 / 781], Loss: 3.6710612773895264\n",
            "[369 / 781], Loss: 3.685767412185669\n",
            "[370 / 781], Loss: 3.454017400741577\n",
            "[371 / 781], Loss: 3.6837007999420166\n",
            "[372 / 781], Loss: 3.750699758529663\n",
            "[373 / 781], Loss: 3.8240296840667725\n",
            "[374 / 781], Loss: 3.9165544509887695\n",
            "[375 / 781], Loss: 3.539931535720825\n",
            "[376 / 781], Loss: 3.6064486503601074\n",
            "[377 / 781], Loss: 3.4950544834136963\n",
            "[378 / 781], Loss: 3.899766445159912\n",
            "[379 / 781], Loss: 3.5025811195373535\n",
            "[380 / 781], Loss: 3.830615997314453\n",
            "[381 / 781], Loss: 3.6350417137145996\n",
            "[382 / 781], Loss: 3.5316107273101807\n",
            "[383 / 781], Loss: 3.7346138954162598\n",
            "[384 / 781], Loss: 3.488502025604248\n",
            "[385 / 781], Loss: 3.66314697265625\n",
            "[386 / 781], Loss: 3.5813000202178955\n",
            "[387 / 781], Loss: 3.6774537563323975\n",
            "[388 / 781], Loss: 3.6665542125701904\n",
            "[389 / 781], Loss: 3.783460855484009\n",
            "[390 / 781], Loss: 3.673445224761963\n",
            "[391 / 781], Loss: 3.5149762630462646\n",
            "[392 / 781], Loss: 3.7260613441467285\n",
            "[393 / 781], Loss: 3.6510190963745117\n",
            "[394 / 781], Loss: 3.6174919605255127\n",
            "[395 / 781], Loss: 3.7078588008880615\n",
            "[396 / 781], Loss: 3.783505916595459\n",
            "[397 / 781], Loss: 3.8079421520233154\n",
            "[398 / 781], Loss: 3.7923543453216553\n",
            "[399 / 781], Loss: 3.5261640548706055\n",
            "[400 / 781], Loss: 3.7040956020355225\n",
            "[401 / 781], Loss: 3.6871633529663086\n",
            "[402 / 781], Loss: 3.774724006652832\n",
            "[403 / 781], Loss: 3.579777479171753\n",
            "[404 / 781], Loss: 3.729675531387329\n",
            "[405 / 781], Loss: 3.5274195671081543\n",
            "[406 / 781], Loss: 3.560084819793701\n",
            "[407 / 781], Loss: 3.877197265625\n",
            "[408 / 781], Loss: 3.6657161712646484\n",
            "[409 / 781], Loss: 3.6614468097686768\n",
            "[410 / 781], Loss: 3.6097073554992676\n",
            "[411 / 781], Loss: 3.581386089324951\n",
            "[412 / 781], Loss: 3.5677011013031006\n",
            "[413 / 781], Loss: 3.624587059020996\n",
            "[414 / 781], Loss: 3.6146721839904785\n",
            "[415 / 781], Loss: 3.7201881408691406\n",
            "[416 / 781], Loss: 3.9222710132598877\n",
            "[417 / 781], Loss: 3.565979480743408\n",
            "[418 / 781], Loss: 3.6419191360473633\n",
            "[419 / 781], Loss: 3.836540937423706\n",
            "[420 / 781], Loss: 3.8321056365966797\n",
            "[421 / 781], Loss: 3.6151366233825684\n",
            "[422 / 781], Loss: 3.746378183364868\n",
            "[423 / 781], Loss: 3.5676097869873047\n",
            "[424 / 781], Loss: 3.6263842582702637\n",
            "[425 / 781], Loss: 3.6400320529937744\n",
            "[426 / 781], Loss: 3.4185967445373535\n",
            "[427 / 781], Loss: 3.6738638877868652\n",
            "[428 / 781], Loss: 3.964061737060547\n",
            "[429 / 781], Loss: 3.6565537452697754\n",
            "[430 / 781], Loss: 3.4820189476013184\n",
            "[431 / 781], Loss: 3.831113815307617\n",
            "[432 / 781], Loss: 3.6035237312316895\n",
            "[433 / 781], Loss: 3.705772638320923\n",
            "[434 / 781], Loss: 3.51464581489563\n",
            "[435 / 781], Loss: 3.68233585357666\n",
            "[436 / 781], Loss: 3.8838999271392822\n",
            "[437 / 781], Loss: 3.680358648300171\n",
            "[438 / 781], Loss: 3.6243951320648193\n",
            "[439 / 781], Loss: 3.6847074031829834\n",
            "[440 / 781], Loss: 3.6718952655792236\n",
            "[441 / 781], Loss: 3.5210423469543457\n",
            "[442 / 781], Loss: 3.6894612312316895\n",
            "[443 / 781], Loss: 3.862610101699829\n",
            "[444 / 781], Loss: 3.5700604915618896\n",
            "[445 / 781], Loss: 3.508201837539673\n",
            "[446 / 781], Loss: 3.4891774654388428\n",
            "[447 / 781], Loss: 3.5985732078552246\n",
            "[448 / 781], Loss: 3.3472535610198975\n",
            "[449 / 781], Loss: 3.712872266769409\n",
            "[450 / 781], Loss: 3.7647786140441895\n",
            "[451 / 781], Loss: 3.494879961013794\n",
            "[452 / 781], Loss: 3.4798662662506104\n",
            "[453 / 781], Loss: 3.7078330516815186\n",
            "[454 / 781], Loss: 3.6254689693450928\n",
            "[455 / 781], Loss: 3.802466630935669\n",
            "[456 / 781], Loss: 3.5176656246185303\n",
            "[457 / 781], Loss: 3.6315908432006836\n",
            "[458 / 781], Loss: 3.6934139728546143\n",
            "[459 / 781], Loss: 3.5839202404022217\n",
            "[460 / 781], Loss: 3.628326654434204\n",
            "[461 / 781], Loss: 3.5672104358673096\n",
            "[462 / 781], Loss: 3.5280468463897705\n",
            "[463 / 781], Loss: 3.9710631370544434\n",
            "[464 / 781], Loss: 3.725583076477051\n",
            "[465 / 781], Loss: 3.5915703773498535\n",
            "[466 / 781], Loss: 3.7395882606506348\n",
            "[467 / 781], Loss: 3.5051729679107666\n",
            "[468 / 781], Loss: 3.742248058319092\n",
            "[469 / 781], Loss: 3.5110299587249756\n",
            "[470 / 781], Loss: 3.6463019847869873\n",
            "[471 / 781], Loss: 3.6219708919525146\n",
            "[472 / 781], Loss: 3.5200963020324707\n",
            "[473 / 781], Loss: 3.5029869079589844\n",
            "[474 / 781], Loss: 3.523972511291504\n",
            "[475 / 781], Loss: 3.756354331970215\n",
            "[476 / 781], Loss: 3.305715560913086\n",
            "[477 / 781], Loss: 3.506349563598633\n",
            "[478 / 781], Loss: 3.5839624404907227\n",
            "[479 / 781], Loss: 3.761709451675415\n",
            "[480 / 781], Loss: 3.591480016708374\n",
            "[481 / 781], Loss: 3.6686770915985107\n",
            "[482 / 781], Loss: 3.585395574569702\n",
            "[483 / 781], Loss: 3.4289276599884033\n",
            "[484 / 781], Loss: 3.6919238567352295\n",
            "[485 / 781], Loss: 3.677830696105957\n",
            "[486 / 781], Loss: 3.677489757537842\n",
            "[487 / 781], Loss: 3.6218385696411133\n",
            "[488 / 781], Loss: 3.7625036239624023\n",
            "[489 / 781], Loss: 3.7113707065582275\n",
            "[490 / 781], Loss: 3.5913143157958984\n",
            "[491 / 781], Loss: 3.7011942863464355\n",
            "[492 / 781], Loss: 3.478011131286621\n",
            "[493 / 781], Loss: 3.519507884979248\n",
            "[494 / 781], Loss: 3.5637636184692383\n",
            "[495 / 781], Loss: 3.5998377799987793\n",
            "[496 / 781], Loss: 3.648801565170288\n",
            "[497 / 781], Loss: 3.5010406970977783\n",
            "[498 / 781], Loss: 3.693876266479492\n",
            "[499 / 781], Loss: 3.638697862625122\n",
            "[500 / 781], Loss: 3.576883554458618\n",
            "[501 / 781], Loss: 3.776407241821289\n",
            "[502 / 781], Loss: 3.4877495765686035\n",
            "[503 / 781], Loss: 3.6288318634033203\n",
            "[504 / 781], Loss: 3.462599515914917\n",
            "[505 / 781], Loss: 3.337616443634033\n",
            "[506 / 781], Loss: 3.629370927810669\n",
            "[507 / 781], Loss: 3.546283483505249\n",
            "[508 / 781], Loss: 3.770655870437622\n",
            "[509 / 781], Loss: 3.5632216930389404\n",
            "[510 / 781], Loss: 3.602081775665283\n",
            "[511 / 781], Loss: 3.4731547832489014\n",
            "[512 / 781], Loss: 3.57914662361145\n",
            "[513 / 781], Loss: 3.6957457065582275\n",
            "[514 / 781], Loss: 3.5462517738342285\n",
            "[515 / 781], Loss: 3.4928486347198486\n",
            "[516 / 781], Loss: 3.4277267456054688\n",
            "[517 / 781], Loss: 3.636676549911499\n",
            "[518 / 781], Loss: 3.3593649864196777\n",
            "[519 / 781], Loss: 3.7449862957000732\n",
            "[520 / 781], Loss: 3.444451093673706\n",
            "[521 / 781], Loss: 3.6024937629699707\n",
            "[522 / 781], Loss: 3.664151906967163\n",
            "[523 / 781], Loss: 3.812448263168335\n",
            "[524 / 781], Loss: 3.371764659881592\n",
            "[525 / 781], Loss: 3.4167320728302\n",
            "[526 / 781], Loss: 3.4629974365234375\n",
            "[527 / 781], Loss: 3.4050703048706055\n",
            "[528 / 781], Loss: 3.687518358230591\n",
            "[529 / 781], Loss: 3.7647340297698975\n",
            "[530 / 781], Loss: 3.5107665061950684\n",
            "[531 / 781], Loss: 3.4203274250030518\n",
            "[532 / 781], Loss: 3.689512252807617\n",
            "[533 / 781], Loss: 3.4171931743621826\n",
            "[534 / 781], Loss: 3.6139533519744873\n",
            "[535 / 781], Loss: 3.511451005935669\n",
            "[536 / 781], Loss: 3.373948335647583\n",
            "[537 / 781], Loss: 3.6168160438537598\n",
            "[538 / 781], Loss: 3.4715733528137207\n",
            "[539 / 781], Loss: 3.4549269676208496\n",
            "[540 / 781], Loss: 3.834538459777832\n",
            "[541 / 781], Loss: 3.4776158332824707\n",
            "[542 / 781], Loss: 3.653564214706421\n",
            "[543 / 781], Loss: 3.6471357345581055\n",
            "[544 / 781], Loss: 3.5498971939086914\n",
            "[545 / 781], Loss: 3.5114376544952393\n",
            "[546 / 781], Loss: 3.7564480304718018\n",
            "[547 / 781], Loss: 3.3743722438812256\n",
            "[548 / 781], Loss: 3.668638229370117\n",
            "[549 / 781], Loss: 3.5420398712158203\n",
            "[550 / 781], Loss: 3.436114549636841\n",
            "[551 / 781], Loss: 3.471499443054199\n",
            "[552 / 781], Loss: 3.5400381088256836\n",
            "[553 / 781], Loss: 3.587120294570923\n",
            "[554 / 781], Loss: 3.6889312267303467\n",
            "[555 / 781], Loss: 3.616323947906494\n",
            "[556 / 781], Loss: 3.666125774383545\n",
            "[557 / 781], Loss: 3.517359495162964\n",
            "[558 / 781], Loss: 3.5540668964385986\n",
            "[559 / 781], Loss: 3.393862724304199\n",
            "[560 / 781], Loss: 3.66251802444458\n",
            "[561 / 781], Loss: 3.5546250343322754\n",
            "[562 / 781], Loss: 3.6186296939849854\n",
            "[563 / 781], Loss: 3.721883773803711\n",
            "[564 / 781], Loss: 3.405566453933716\n",
            "[565 / 781], Loss: 3.688277006149292\n",
            "[566 / 781], Loss: 3.591789722442627\n",
            "[567 / 781], Loss: 3.406541347503662\n",
            "[568 / 781], Loss: 3.6086792945861816\n",
            "[569 / 781], Loss: 3.4409260749816895\n",
            "[570 / 781], Loss: 3.5065252780914307\n",
            "[571 / 781], Loss: 3.520730972290039\n",
            "[572 / 781], Loss: 3.4962246417999268\n",
            "[573 / 781], Loss: 3.4562289714813232\n",
            "[574 / 781], Loss: 3.3999500274658203\n",
            "[575 / 781], Loss: 3.663853406906128\n",
            "[576 / 781], Loss: 3.919917106628418\n",
            "[577 / 781], Loss: 3.4725637435913086\n",
            "[578 / 781], Loss: 3.5265960693359375\n",
            "[579 / 781], Loss: 3.2889866828918457\n",
            "[580 / 781], Loss: 3.464876174926758\n",
            "[581 / 781], Loss: 3.7156765460968018\n",
            "[582 / 781], Loss: 3.4327139854431152\n",
            "[583 / 781], Loss: 3.79732608795166\n",
            "[584 / 781], Loss: 3.4072983264923096\n",
            "[585 / 781], Loss: 3.4033048152923584\n",
            "[586 / 781], Loss: 3.4550931453704834\n",
            "[587 / 781], Loss: 3.483947277069092\n",
            "[588 / 781], Loss: 3.2638955116271973\n",
            "[589 / 781], Loss: 3.695967197418213\n",
            "[590 / 781], Loss: 3.7235047817230225\n",
            "[591 / 781], Loss: 3.570964813232422\n",
            "[592 / 781], Loss: 3.3797640800476074\n",
            "[593 / 781], Loss: 3.4165291786193848\n",
            "[594 / 781], Loss: 3.6839499473571777\n",
            "[595 / 781], Loss: 3.4668078422546387\n",
            "[596 / 781], Loss: 3.5759458541870117\n",
            "[597 / 781], Loss: 3.545421838760376\n",
            "[598 / 781], Loss: 3.4897937774658203\n",
            "[599 / 781], Loss: 3.338224411010742\n",
            "[600 / 781], Loss: 3.4579384326934814\n",
            "[601 / 781], Loss: 3.531036138534546\n",
            "[602 / 781], Loss: 3.4351413249969482\n",
            "[603 / 781], Loss: 3.562940835952759\n",
            "[604 / 781], Loss: 3.5061206817626953\n",
            "[605 / 781], Loss: 3.3468449115753174\n",
            "[606 / 781], Loss: 3.5110912322998047\n",
            "[607 / 781], Loss: 3.4723286628723145\n",
            "[608 / 781], Loss: 3.4796338081359863\n",
            "[609 / 781], Loss: 3.404269218444824\n",
            "[610 / 781], Loss: 3.5417799949645996\n",
            "[611 / 781], Loss: 3.667487859725952\n",
            "[612 / 781], Loss: 3.3963916301727295\n",
            "[613 / 781], Loss: 3.455988645553589\n",
            "[614 / 781], Loss: 3.44498610496521\n",
            "[615 / 781], Loss: 3.3098456859588623\n",
            "[616 / 781], Loss: 3.6026089191436768\n",
            "[617 / 781], Loss: 3.484534740447998\n",
            "[618 / 781], Loss: 3.5455029010772705\n",
            "[619 / 781], Loss: 3.5060648918151855\n",
            "[620 / 781], Loss: 3.689995288848877\n",
            "[621 / 781], Loss: 3.7612030506134033\n",
            "[622 / 781], Loss: 3.5646820068359375\n",
            "[623 / 781], Loss: 3.7725796699523926\n",
            "[624 / 781], Loss: 3.6006622314453125\n",
            "[625 / 781], Loss: 3.504802703857422\n",
            "[626 / 781], Loss: 3.4567208290100098\n",
            "[627 / 781], Loss: 3.6434032917022705\n",
            "[628 / 781], Loss: 3.481349229812622\n",
            "[629 / 781], Loss: 3.4699387550354004\n",
            "[630 / 781], Loss: 3.4649603366851807\n",
            "[631 / 781], Loss: 3.5898115634918213\n",
            "[632 / 781], Loss: 3.7852983474731445\n",
            "[633 / 781], Loss: 3.5903258323669434\n",
            "[634 / 781], Loss: 3.4829628467559814\n",
            "[635 / 781], Loss: 3.687052011489868\n",
            "[636 / 781], Loss: 3.5262155532836914\n",
            "[637 / 781], Loss: 3.6845080852508545\n",
            "[638 / 781], Loss: 3.49123215675354\n",
            "[639 / 781], Loss: 3.36042857170105\n",
            "[640 / 781], Loss: 3.367398977279663\n",
            "[641 / 781], Loss: 3.395311117172241\n",
            "[642 / 781], Loss: 3.5944314002990723\n",
            "[643 / 781], Loss: 3.3353943824768066\n",
            "[644 / 781], Loss: 3.5471415519714355\n",
            "[645 / 781], Loss: 3.396131992340088\n",
            "[646 / 781], Loss: 3.322906255722046\n",
            "[647 / 781], Loss: 3.6782522201538086\n",
            "[648 / 781], Loss: 3.460777759552002\n",
            "[649 / 781], Loss: 3.636571168899536\n",
            "[650 / 781], Loss: 3.6341426372528076\n",
            "[651 / 781], Loss: 3.4842989444732666\n",
            "[652 / 781], Loss: 3.481480598449707\n",
            "[653 / 781], Loss: 3.3932363986968994\n",
            "[654 / 781], Loss: 3.259695529937744\n",
            "[655 / 781], Loss: 3.4936509132385254\n",
            "[656 / 781], Loss: 3.48164963722229\n",
            "[657 / 781], Loss: 3.5283803939819336\n",
            "[658 / 781], Loss: 3.3909664154052734\n",
            "[659 / 781], Loss: 3.643993377685547\n",
            "[660 / 781], Loss: 3.6532392501831055\n",
            "[661 / 781], Loss: 3.4198906421661377\n",
            "[662 / 781], Loss: 3.5269744396209717\n",
            "[663 / 781], Loss: 3.390340805053711\n",
            "[664 / 781], Loss: 3.5002002716064453\n",
            "[665 / 781], Loss: 3.5595180988311768\n",
            "[666 / 781], Loss: 3.3813064098358154\n",
            "[667 / 781], Loss: 3.4493556022644043\n",
            "[668 / 781], Loss: 3.4854564666748047\n",
            "[669 / 781], Loss: 3.3689582347869873\n",
            "[670 / 781], Loss: 3.66648268699646\n",
            "[671 / 781], Loss: 3.510093927383423\n",
            "[672 / 781], Loss: 3.4506587982177734\n",
            "[673 / 781], Loss: 3.2146575450897217\n",
            "[674 / 781], Loss: 3.330948829650879\n",
            "[675 / 781], Loss: 3.411184787750244\n",
            "[676 / 781], Loss: 3.452087879180908\n",
            "[677 / 781], Loss: 3.3742926120758057\n",
            "[678 / 781], Loss: 3.343768835067749\n",
            "[679 / 781], Loss: 3.6449217796325684\n",
            "[680 / 781], Loss: 3.423100709915161\n",
            "[681 / 781], Loss: 3.5401358604431152\n",
            "[682 / 781], Loss: 3.2830405235290527\n",
            "[683 / 781], Loss: 3.3714940547943115\n",
            "[684 / 781], Loss: 3.250499725341797\n",
            "[685 / 781], Loss: 3.364907741546631\n",
            "[686 / 781], Loss: 3.553556442260742\n",
            "[687 / 781], Loss: 3.4714858531951904\n",
            "[688 / 781], Loss: 3.544253349304199\n",
            "[689 / 781], Loss: 3.637549877166748\n",
            "[690 / 781], Loss: 3.233511447906494\n",
            "[691 / 781], Loss: 3.542327404022217\n",
            "[692 / 781], Loss: 3.4382619857788086\n",
            "[693 / 781], Loss: 3.3757781982421875\n",
            "[694 / 781], Loss: 3.1785788536071777\n",
            "[695 / 781], Loss: 3.371220588684082\n",
            "[696 / 781], Loss: 3.470453977584839\n",
            "[697 / 781], Loss: 3.36185359954834\n",
            "[698 / 781], Loss: 3.2578063011169434\n",
            "[699 / 781], Loss: 3.3107967376708984\n",
            "[700 / 781], Loss: 3.4440767765045166\n",
            "[701 / 781], Loss: 3.5982046127319336\n",
            "[702 / 781], Loss: 3.7125725746154785\n",
            "[703 / 781], Loss: 3.668886184692383\n",
            "[704 / 781], Loss: 3.6703994274139404\n",
            "[705 / 781], Loss: 3.386258125305176\n",
            "[706 / 781], Loss: 3.5128934383392334\n",
            "[707 / 781], Loss: 3.2834720611572266\n",
            "[708 / 781], Loss: 3.457808494567871\n",
            "[709 / 781], Loss: 3.527122735977173\n",
            "[710 / 781], Loss: 3.5138778686523438\n",
            "[711 / 781], Loss: 3.6189889907836914\n",
            "[712 / 781], Loss: 3.609123706817627\n",
            "[713 / 781], Loss: 3.477369785308838\n",
            "[714 / 781], Loss: 3.322605848312378\n",
            "[715 / 781], Loss: 3.2950797080993652\n",
            "[716 / 781], Loss: 3.5310375690460205\n",
            "[717 / 781], Loss: 3.525017738342285\n",
            "[718 / 781], Loss: 3.4900288581848145\n",
            "[719 / 781], Loss: 3.6023287773132324\n",
            "[720 / 781], Loss: 3.375926971435547\n",
            "[721 / 781], Loss: 3.2953298091888428\n",
            "[722 / 781], Loss: 3.4590282440185547\n",
            "[723 / 781], Loss: 3.6586782932281494\n",
            "[724 / 781], Loss: 3.2379024028778076\n",
            "[725 / 781], Loss: 3.270524740219116\n",
            "[726 / 781], Loss: 3.201002359390259\n",
            "[727 / 781], Loss: 3.5975000858306885\n",
            "[728 / 781], Loss: 3.4243757724761963\n",
            "[729 / 781], Loss: 3.6145617961883545\n",
            "[730 / 781], Loss: 3.556089162826538\n",
            "[731 / 781], Loss: 3.6782243251800537\n",
            "[732 / 781], Loss: 3.6604325771331787\n",
            "[733 / 781], Loss: 3.290527105331421\n",
            "[734 / 781], Loss: 3.401536703109741\n",
            "[735 / 781], Loss: 3.5466744899749756\n",
            "[736 / 781], Loss: 3.6614887714385986\n",
            "[737 / 781], Loss: 3.7068817615509033\n",
            "[738 / 781], Loss: 3.3241844177246094\n",
            "[739 / 781], Loss: 3.504607677459717\n",
            "[740 / 781], Loss: 3.1441330909729004\n",
            "[741 / 781], Loss: 3.4247777462005615\n",
            "[742 / 781], Loss: 3.562133550643921\n",
            "[743 / 781], Loss: 3.3106892108917236\n",
            "[744 / 781], Loss: 3.5906639099121094\n",
            "[745 / 781], Loss: 3.337819814682007\n",
            "[746 / 781], Loss: 3.447084426879883\n",
            "[747 / 781], Loss: 3.616926431655884\n",
            "[748 / 781], Loss: 3.5599558353424072\n",
            "[749 / 781], Loss: 3.3931593894958496\n",
            "[750 / 781], Loss: 3.2000892162323\n",
            "[751 / 781], Loss: 3.718280792236328\n",
            "[752 / 781], Loss: 3.4582786560058594\n",
            "[753 / 781], Loss: 3.410175323486328\n",
            "[754 / 781], Loss: 3.1808364391326904\n",
            "[755 / 781], Loss: 3.515958309173584\n",
            "[756 / 781], Loss: 3.239995241165161\n",
            "[757 / 781], Loss: 3.3750791549682617\n",
            "[758 / 781], Loss: 3.646519422531128\n",
            "[759 / 781], Loss: 3.8163771629333496\n",
            "[760 / 781], Loss: 3.480128765106201\n",
            "[761 / 781], Loss: 3.505636692047119\n",
            "[762 / 781], Loss: 3.64882230758667\n",
            "[763 / 781], Loss: 3.46201491355896\n",
            "[764 / 781], Loss: 3.3472704887390137\n",
            "[765 / 781], Loss: 3.46063494682312\n",
            "[766 / 781], Loss: 3.505829095840454\n",
            "[767 / 781], Loss: 3.346839189529419\n",
            "[768 / 781], Loss: 3.429325819015503\n",
            "[769 / 781], Loss: 3.300004482269287\n",
            "[770 / 781], Loss: 3.062598705291748\n",
            "[771 / 781], Loss: 3.5251967906951904\n",
            "[772 / 781], Loss: 3.4058313369750977\n",
            "[773 / 781], Loss: 3.2648766040802\n",
            "[774 / 781], Loss: 3.264261484146118\n",
            "[775 / 781], Loss: 3.413451910018921\n",
            "[776 / 781], Loss: 3.5033843517303467\n",
            "[777 / 781], Loss: 3.6091532707214355\n",
            "[778 / 781], Loss: 3.580373764038086\n",
            "[779 / 781], Loss: 3.3225669860839844\n",
            "[780 / 781], Loss: 3.468846082687378\n",
            "train Loss: 472.2410 Acc: 27.2074\n",
            "[0 / 781], Loss: 3.2943320274353027\n",
            "[1 / 781], Loss: 2.976041793823242\n",
            "[2 / 781], Loss: 2.6816864013671875\n",
            "[3 / 781], Loss: 2.913287878036499\n",
            "[4 / 781], Loss: 3.1036689281463623\n",
            "[5 / 781], Loss: 2.7108042240142822\n",
            "[6 / 781], Loss: 3.107377529144287\n",
            "[7 / 781], Loss: 3.485769510269165\n",
            "[8 / 781], Loss: 3.3697144985198975\n",
            "[9 / 781], Loss: 2.346928358078003\n",
            "[10 / 781], Loss: 2.501605272293091\n",
            "[11 / 781], Loss: 3.095560312271118\n",
            "[12 / 781], Loss: 3.1894328594207764\n",
            "[13 / 781], Loss: 2.951488733291626\n",
            "[14 / 781], Loss: 2.490292549133301\n",
            "[15 / 781], Loss: 2.6302578449249268\n",
            "[16 / 781], Loss: 2.864255666732788\n",
            "[17 / 781], Loss: 2.6829543113708496\n",
            "[18 / 781], Loss: 2.7660770416259766\n",
            "[19 / 781], Loss: 2.9389841556549072\n",
            "[20 / 781], Loss: 2.431457042694092\n",
            "[21 / 781], Loss: 2.7875616550445557\n",
            "[22 / 781], Loss: 2.4385740756988525\n",
            "[23 / 781], Loss: 2.525073528289795\n",
            "[24 / 781], Loss: 2.6448864936828613\n",
            "[25 / 781], Loss: 2.196960210800171\n",
            "[26 / 781], Loss: 2.923632860183716\n",
            "[27 / 781], Loss: 2.6602673530578613\n",
            "[28 / 781], Loss: 2.4684557914733887\n",
            "[29 / 781], Loss: 2.9209611415863037\n",
            "[30 / 781], Loss: 2.7697975635528564\n",
            "[31 / 781], Loss: 2.905916452407837\n",
            "[32 / 781], Loss: 3.031183958053589\n",
            "[33 / 781], Loss: 2.3391220569610596\n",
            "[34 / 781], Loss: 2.624650716781616\n",
            "[35 / 781], Loss: 3.0531344413757324\n",
            "[36 / 781], Loss: 2.572335958480835\n",
            "[37 / 781], Loss: 2.8944544792175293\n",
            "[38 / 781], Loss: 3.1036384105682373\n",
            "[39 / 781], Loss: 2.7911484241485596\n",
            "[40 / 781], Loss: 3.01625394821167\n",
            "[41 / 781], Loss: 2.761190891265869\n",
            "[42 / 781], Loss: 2.8038060665130615\n",
            "[43 / 781], Loss: 2.579030990600586\n",
            "[44 / 781], Loss: 2.84651255607605\n",
            "[45 / 781], Loss: 2.679069757461548\n",
            "[46 / 781], Loss: 2.7279717922210693\n",
            "[47 / 781], Loss: 2.8801345825195312\n",
            "[48 / 781], Loss: 2.711134910583496\n",
            "[49 / 781], Loss: 2.8976364135742188\n",
            "[50 / 781], Loss: 2.7697737216949463\n",
            "[51 / 781], Loss: 2.5566158294677734\n",
            "[52 / 781], Loss: 2.7122087478637695\n",
            "[53 / 781], Loss: 2.174290657043457\n",
            "[54 / 781], Loss: 2.834691286087036\n",
            "[55 / 781], Loss: 3.0509350299835205\n",
            "[56 / 781], Loss: 2.6897597312927246\n",
            "[57 / 781], Loss: 2.2721049785614014\n",
            "[58 / 781], Loss: 2.4845473766326904\n",
            "[59 / 781], Loss: 2.5957047939300537\n",
            "[60 / 781], Loss: 2.8679182529449463\n",
            "[61 / 781], Loss: 2.394819736480713\n",
            "[62 / 781], Loss: 2.847273826599121\n",
            "[63 / 781], Loss: 3.117959976196289\n",
            "[64 / 781], Loss: 2.5727157592773438\n",
            "[65 / 781], Loss: 2.8709869384765625\n",
            "[66 / 781], Loss: 2.751929998397827\n",
            "[67 / 781], Loss: 2.8903396129608154\n",
            "[68 / 781], Loss: 2.475065231323242\n",
            "[69 / 781], Loss: 3.011475086212158\n",
            "[70 / 781], Loss: 2.969827651977539\n",
            "[71 / 781], Loss: 2.3903515338897705\n",
            "[72 / 781], Loss: 3.3562510013580322\n",
            "[73 / 781], Loss: 2.713811159133911\n",
            "[74 / 781], Loss: 2.4021289348602295\n",
            "[75 / 781], Loss: 2.6812984943389893\n",
            "[76 / 781], Loss: 3.0310230255126953\n",
            "[77 / 781], Loss: 2.837125301361084\n",
            "[78 / 781], Loss: 2.405583143234253\n",
            "[79 / 781], Loss: 2.891641139984131\n",
            "[80 / 781], Loss: 2.9852678775787354\n",
            "[81 / 781], Loss: 2.675445556640625\n",
            "[82 / 781], Loss: 2.737752914428711\n",
            "[83 / 781], Loss: 2.7829222679138184\n",
            "[84 / 781], Loss: 3.2270138263702393\n",
            "[85 / 781], Loss: 2.739259958267212\n",
            "[86 / 781], Loss: 3.2295374870300293\n",
            "[87 / 781], Loss: 2.554169178009033\n",
            "[88 / 781], Loss: 2.91996693611145\n",
            "[89 / 781], Loss: 3.0751595497131348\n",
            "[90 / 781], Loss: 2.9683609008789062\n",
            "[91 / 781], Loss: 2.84649658203125\n",
            "[92 / 781], Loss: 2.606173276901245\n",
            "[93 / 781], Loss: 3.046273946762085\n",
            "[94 / 781], Loss: 3.1672821044921875\n",
            "[95 / 781], Loss: 2.9745101928710938\n",
            "[96 / 781], Loss: 2.9320836067199707\n",
            "[97 / 781], Loss: 2.997213125228882\n",
            "[98 / 781], Loss: 2.7278683185577393\n",
            "[99 / 781], Loss: 3.0629470348358154\n",
            "[100 / 781], Loss: 2.563382387161255\n",
            "[101 / 781], Loss: 2.608384609222412\n",
            "[102 / 781], Loss: 2.308983564376831\n",
            "[103 / 781], Loss: 3.0480618476867676\n",
            "[104 / 781], Loss: 3.0114920139312744\n",
            "[105 / 781], Loss: 2.7938895225524902\n",
            "[106 / 781], Loss: 2.747950792312622\n",
            "[107 / 781], Loss: 2.815418243408203\n",
            "[108 / 781], Loss: 3.139127492904663\n",
            "[109 / 781], Loss: 2.2303466796875\n",
            "[110 / 781], Loss: 3.180173635482788\n",
            "[111 / 781], Loss: 2.7405929565429688\n",
            "[112 / 781], Loss: 2.805626392364502\n",
            "[113 / 781], Loss: 2.981126546859741\n",
            "[114 / 781], Loss: 2.5844054222106934\n",
            "[115 / 781], Loss: 2.916067361831665\n",
            "[116 / 781], Loss: 2.048543691635132\n",
            "[117 / 781], Loss: 3.110593318939209\n",
            "[118 / 781], Loss: 2.759567975997925\n",
            "[119 / 781], Loss: 2.558593988418579\n",
            "[120 / 781], Loss: 3.0324740409851074\n",
            "[121 / 781], Loss: 3.003918409347534\n",
            "[122 / 781], Loss: 2.782850503921509\n",
            "[123 / 781], Loss: 3.1733131408691406\n",
            "[124 / 781], Loss: 2.522024631500244\n",
            "[125 / 781], Loss: 2.389052391052246\n",
            "[126 / 781], Loss: 2.604208469390869\n",
            "[127 / 781], Loss: 2.833378314971924\n",
            "[128 / 781], Loss: 2.8596370220184326\n",
            "[129 / 781], Loss: 2.2346620559692383\n",
            "[130 / 781], Loss: 3.356189250946045\n",
            "[131 / 781], Loss: 3.0376381874084473\n",
            "[132 / 781], Loss: 2.9897828102111816\n",
            "[133 / 781], Loss: 2.7828314304351807\n",
            "[134 / 781], Loss: 2.6353583335876465\n",
            "[135 / 781], Loss: 2.8971798419952393\n",
            "[136 / 781], Loss: 2.710176944732666\n",
            "[137 / 781], Loss: 2.8550806045532227\n",
            "[138 / 781], Loss: 2.812269926071167\n",
            "[139 / 781], Loss: 3.235586166381836\n",
            "[140 / 781], Loss: 2.8079488277435303\n",
            "[141 / 781], Loss: 3.1164183616638184\n",
            "[142 / 781], Loss: 2.53225040435791\n",
            "[143 / 781], Loss: 2.553802728652954\n",
            "[144 / 781], Loss: 2.3527004718780518\n",
            "[145 / 781], Loss: 3.1425652503967285\n",
            "[146 / 781], Loss: 2.7934205532073975\n",
            "[147 / 781], Loss: 3.0797929763793945\n",
            "[148 / 781], Loss: 2.7552006244659424\n",
            "[149 / 781], Loss: 2.6938493251800537\n",
            "[150 / 781], Loss: 2.4687864780426025\n",
            "[151 / 781], Loss: 2.588447332382202\n",
            "[152 / 781], Loss: 2.7053611278533936\n",
            "[153 / 781], Loss: 2.601025104522705\n",
            "[154 / 781], Loss: 2.402850389480591\n",
            "[155 / 781], Loss: 3.2738101482391357\n",
            "[156 / 781], Loss: 2.592733860015869\n",
            "[157 / 781], Loss: 2.703585624694824\n",
            "[158 / 781], Loss: 2.799264430999756\n",
            "[159 / 781], Loss: 2.729766368865967\n",
            "[160 / 781], Loss: 3.1574952602386475\n",
            "[161 / 781], Loss: 3.0199427604675293\n",
            "[162 / 781], Loss: 3.0635318756103516\n",
            "[163 / 781], Loss: 2.6423652172088623\n",
            "[164 / 781], Loss: 3.1211390495300293\n",
            "[165 / 781], Loss: 2.972419500350952\n",
            "[166 / 781], Loss: 2.465141534805298\n",
            "[167 / 781], Loss: 3.088560104370117\n",
            "[168 / 781], Loss: 3.1248390674591064\n",
            "[169 / 781], Loss: 2.6076395511627197\n",
            "[170 / 781], Loss: 2.832089424133301\n",
            "[171 / 781], Loss: 2.8400979042053223\n",
            "[172 / 781], Loss: 2.4071872234344482\n",
            "[173 / 781], Loss: 2.9495553970336914\n",
            "[174 / 781], Loss: 2.761382579803467\n",
            "[175 / 781], Loss: 2.8526687622070312\n",
            "[176 / 781], Loss: 2.6918721199035645\n",
            "[177 / 781], Loss: 2.5642056465148926\n",
            "[178 / 781], Loss: 2.45304799079895\n",
            "[179 / 781], Loss: 2.6720077991485596\n",
            "[180 / 781], Loss: 2.6363842487335205\n",
            "[181 / 781], Loss: 3.076594591140747\n",
            "[182 / 781], Loss: 2.7048308849334717\n",
            "[183 / 781], Loss: 2.474778890609741\n",
            "[184 / 781], Loss: 3.1046910285949707\n",
            "[185 / 781], Loss: 3.0220701694488525\n",
            "[186 / 781], Loss: 2.598567247390747\n",
            "[187 / 781], Loss: 2.850391149520874\n",
            "[188 / 781], Loss: 2.412473201751709\n",
            "[189 / 781], Loss: 3.1970016956329346\n",
            "[190 / 781], Loss: 2.9261093139648438\n",
            "[191 / 781], Loss: 2.821075916290283\n",
            "[192 / 781], Loss: 3.0881521701812744\n",
            "[193 / 781], Loss: 2.9986684322357178\n",
            "[194 / 781], Loss: 2.3850386142730713\n",
            "[195 / 781], Loss: 2.577725648880005\n",
            "[196 / 781], Loss: 3.0334315299987793\n",
            "[197 / 781], Loss: 2.920114517211914\n",
            "[198 / 781], Loss: 2.704890727996826\n",
            "[199 / 781], Loss: 2.482391357421875\n",
            "[200 / 781], Loss: 2.923485279083252\n",
            "[201 / 781], Loss: 2.4518609046936035\n",
            "[202 / 781], Loss: 2.3912572860717773\n",
            "[203 / 781], Loss: 2.7966785430908203\n",
            "[204 / 781], Loss: 2.4746460914611816\n",
            "[205 / 781], Loss: 2.5878119468688965\n",
            "[206 / 781], Loss: 2.427349090576172\n",
            "[207 / 781], Loss: 2.799025058746338\n",
            "[208 / 781], Loss: 3.2529265880584717\n",
            "[209 / 781], Loss: 3.0936386585235596\n",
            "[210 / 781], Loss: 2.72160267829895\n",
            "[211 / 781], Loss: 3.1478312015533447\n",
            "[212 / 781], Loss: 3.249343156814575\n",
            "[213 / 781], Loss: 2.23559832572937\n",
            "[214 / 781], Loss: 3.265329360961914\n",
            "[215 / 781], Loss: 3.1488795280456543\n",
            "[216 / 781], Loss: 3.351984739303589\n",
            "[217 / 781], Loss: 2.662799119949341\n",
            "[218 / 781], Loss: 2.856294631958008\n",
            "[219 / 781], Loss: 2.458329916000366\n",
            "[220 / 781], Loss: 3.271892547607422\n",
            "[221 / 781], Loss: 2.9546427726745605\n",
            "[222 / 781], Loss: 3.0392961502075195\n",
            "[223 / 781], Loss: 2.8512284755706787\n",
            "[224 / 781], Loss: 2.9691879749298096\n",
            "[225 / 781], Loss: 2.7690608501434326\n",
            "[226 / 781], Loss: 2.901503086090088\n",
            "[227 / 781], Loss: 2.9510903358459473\n",
            "[228 / 781], Loss: 2.857909917831421\n",
            "[229 / 781], Loss: 2.5026345252990723\n",
            "[230 / 781], Loss: 2.9318013191223145\n",
            "[231 / 781], Loss: 2.6409974098205566\n",
            "[232 / 781], Loss: 2.4840524196624756\n",
            "[233 / 781], Loss: 2.8707709312438965\n",
            "[234 / 781], Loss: 2.6024177074432373\n",
            "[235 / 781], Loss: 2.9387214183807373\n",
            "[236 / 781], Loss: 2.531435012817383\n",
            "[237 / 781], Loss: 3.21604585647583\n",
            "[238 / 781], Loss: 2.9766428470611572\n",
            "[239 / 781], Loss: 3.0906965732574463\n",
            "[240 / 781], Loss: 2.6072680950164795\n",
            "[241 / 781], Loss: 3.000920295715332\n",
            "[242 / 781], Loss: 2.836930990219116\n",
            "[243 / 781], Loss: 3.2041985988616943\n",
            "[244 / 781], Loss: 2.5674006938934326\n",
            "[245 / 781], Loss: 3.1909704208374023\n",
            "[246 / 781], Loss: 2.8556320667266846\n",
            "[247 / 781], Loss: 2.3835830688476562\n",
            "[248 / 781], Loss: 2.3096821308135986\n",
            "[249 / 781], Loss: 2.7264821529388428\n",
            "[250 / 781], Loss: 2.548129081726074\n",
            "[251 / 781], Loss: 2.9510910511016846\n",
            "[252 / 781], Loss: 2.6517910957336426\n",
            "[253 / 781], Loss: 2.5246639251708984\n",
            "[254 / 781], Loss: 2.829347848892212\n",
            "[255 / 781], Loss: 2.5485637187957764\n",
            "[256 / 781], Loss: 2.944924831390381\n",
            "[257 / 781], Loss: 3.043720245361328\n",
            "[258 / 781], Loss: 3.234844446182251\n",
            "[259 / 781], Loss: 2.511725664138794\n",
            "[260 / 781], Loss: 2.8817217350006104\n",
            "[261 / 781], Loss: 2.9927234649658203\n",
            "[262 / 781], Loss: 2.947702646255493\n",
            "[263 / 781], Loss: 2.243422031402588\n",
            "[264 / 781], Loss: 2.707777500152588\n",
            "[265 / 781], Loss: 2.4151883125305176\n",
            "[266 / 781], Loss: 2.5697364807128906\n",
            "[267 / 781], Loss: 2.5318527221679688\n",
            "[268 / 781], Loss: 2.276566505432129\n",
            "[269 / 781], Loss: 2.69734525680542\n",
            "[270 / 781], Loss: 2.699129819869995\n",
            "[271 / 781], Loss: 2.6218347549438477\n",
            "[272 / 781], Loss: 3.0029404163360596\n",
            "[273 / 781], Loss: 3.1061298847198486\n",
            "[274 / 781], Loss: 2.3337528705596924\n",
            "[275 / 781], Loss: 2.819946527481079\n",
            "[276 / 781], Loss: 2.471858501434326\n",
            "[277 / 781], Loss: 2.9219210147857666\n",
            "[278 / 781], Loss: 2.5207719802856445\n",
            "[279 / 781], Loss: 2.5873172283172607\n",
            "[280 / 781], Loss: 3.321367025375366\n",
            "[281 / 781], Loss: 2.7076199054718018\n",
            "[282 / 781], Loss: 2.8521671295166016\n",
            "[283 / 781], Loss: 2.5005102157592773\n",
            "[284 / 781], Loss: 2.457305908203125\n",
            "[285 / 781], Loss: 2.886678457260132\n",
            "[286 / 781], Loss: 2.556206226348877\n",
            "[287 / 781], Loss: 2.974229335784912\n",
            "[288 / 781], Loss: 2.821967601776123\n",
            "[289 / 781], Loss: 2.5861656665802\n",
            "[290 / 781], Loss: 2.6411588191986084\n",
            "[291 / 781], Loss: 2.7995471954345703\n",
            "[292 / 781], Loss: 2.6167104244232178\n",
            "[293 / 781], Loss: 2.690504312515259\n",
            "[294 / 781], Loss: 2.5701208114624023\n",
            "[295 / 781], Loss: 2.9418699741363525\n",
            "[296 / 781], Loss: 2.5718395709991455\n",
            "[297 / 781], Loss: 3.2728350162506104\n",
            "[298 / 781], Loss: 2.7874326705932617\n",
            "[299 / 781], Loss: 2.664919137954712\n",
            "[300 / 781], Loss: 2.327831506729126\n",
            "[301 / 781], Loss: 2.588460922241211\n",
            "[302 / 781], Loss: 2.6760823726654053\n",
            "[303 / 781], Loss: 2.2824020385742188\n",
            "[304 / 781], Loss: 2.53293776512146\n",
            "[305 / 781], Loss: 3.0851666927337646\n",
            "[306 / 781], Loss: 2.6827502250671387\n",
            "[307 / 781], Loss: 2.8945865631103516\n",
            "[308 / 781], Loss: 3.185380220413208\n",
            "[309 / 781], Loss: 2.5151684284210205\n",
            "[310 / 781], Loss: 2.5930252075195312\n",
            "[311 / 781], Loss: 2.4486167430877686\n",
            "val Loss: 89.0423 Acc: 11.9679\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "[0 / 781], Loss: 3.2984063625335693\n",
            "[1 / 781], Loss: 3.4048595428466797\n",
            "[2 / 781], Loss: 3.2704107761383057\n",
            "[3 / 781], Loss: 3.499570846557617\n",
            "[4 / 781], Loss: 3.4416885375976562\n",
            "[5 / 781], Loss: 3.2153329849243164\n",
            "[6 / 781], Loss: 3.548614263534546\n",
            "[7 / 781], Loss: 3.304072380065918\n",
            "[8 / 781], Loss: 3.5524139404296875\n",
            "[9 / 781], Loss: 3.3951714038848877\n",
            "[10 / 781], Loss: 3.2934298515319824\n",
            "[11 / 781], Loss: 3.2936437129974365\n",
            "[12 / 781], Loss: 3.505415916442871\n",
            "[13 / 781], Loss: 3.4196112155914307\n",
            "[14 / 781], Loss: 3.604764461517334\n",
            "[15 / 781], Loss: 3.3613040447235107\n",
            "[16 / 781], Loss: 3.4292361736297607\n",
            "[17 / 781], Loss: 3.4774913787841797\n",
            "[18 / 781], Loss: 3.314436197280884\n",
            "[19 / 781], Loss: 3.277679920196533\n",
            "[20 / 781], Loss: 3.4345431327819824\n",
            "[21 / 781], Loss: 3.3166306018829346\n",
            "[22 / 781], Loss: 3.4225871562957764\n",
            "[23 / 781], Loss: 3.335531711578369\n",
            "[24 / 781], Loss: 3.391406536102295\n",
            "[25 / 781], Loss: 3.3704164028167725\n",
            "[26 / 781], Loss: 3.3088767528533936\n",
            "[27 / 781], Loss: 3.496370315551758\n",
            "[28 / 781], Loss: 3.239567518234253\n",
            "[29 / 781], Loss: 3.431687831878662\n",
            "[30 / 781], Loss: 3.4672908782958984\n",
            "[31 / 781], Loss: 3.6738131046295166\n",
            "[32 / 781], Loss: 3.328902006149292\n",
            "[33 / 781], Loss: 3.2843103408813477\n",
            "[34 / 781], Loss: 3.4236104488372803\n",
            "[35 / 781], Loss: 3.3154635429382324\n",
            "[36 / 781], Loss: 3.6784424781799316\n",
            "[37 / 781], Loss: 3.38661527633667\n",
            "[38 / 781], Loss: 3.3712432384490967\n",
            "[39 / 781], Loss: 3.417236328125\n",
            "[40 / 781], Loss: 3.314619779586792\n",
            "[41 / 781], Loss: 3.49585223197937\n",
            "[42 / 781], Loss: 3.399141550064087\n",
            "[43 / 781], Loss: 3.288545846939087\n",
            "[44 / 781], Loss: 3.1018736362457275\n",
            "[45 / 781], Loss: 3.4738571643829346\n",
            "[46 / 781], Loss: 3.5173356533050537\n",
            "[47 / 781], Loss: 3.3477089405059814\n",
            "[48 / 781], Loss: 3.3529834747314453\n",
            "[49 / 781], Loss: 3.407860279083252\n",
            "[50 / 781], Loss: 3.28367280960083\n",
            "[51 / 781], Loss: 3.4711880683898926\n",
            "[52 / 781], Loss: 3.344411611557007\n",
            "[53 / 781], Loss: 3.179286241531372\n",
            "[54 / 781], Loss: 3.5950160026550293\n",
            "[55 / 781], Loss: 3.328270196914673\n",
            "[56 / 781], Loss: 3.369422674179077\n",
            "[57 / 781], Loss: 3.371858596801758\n",
            "[58 / 781], Loss: 3.4430243968963623\n",
            "[59 / 781], Loss: 3.425661325454712\n",
            "[60 / 781], Loss: 3.3463287353515625\n",
            "[61 / 781], Loss: 3.3814332485198975\n",
            "[62 / 781], Loss: 3.2307708263397217\n",
            "[63 / 781], Loss: 3.3241195678710938\n",
            "[64 / 781], Loss: 3.1958281993865967\n",
            "[65 / 781], Loss: 3.3274624347686768\n",
            "[66 / 781], Loss: 3.524064302444458\n",
            "[67 / 781], Loss: 3.365805149078369\n",
            "[68 / 781], Loss: 3.2990620136260986\n",
            "[69 / 781], Loss: 3.292185068130493\n",
            "[70 / 781], Loss: 3.2357423305511475\n",
            "[71 / 781], Loss: 3.6040520668029785\n",
            "[72 / 781], Loss: 3.597419261932373\n",
            "[73 / 781], Loss: 3.56770920753479\n",
            "[74 / 781], Loss: 3.383885145187378\n",
            "[75 / 781], Loss: 3.3918652534484863\n",
            "[76 / 781], Loss: 3.4143118858337402\n",
            "[77 / 781], Loss: 3.360607147216797\n",
            "[78 / 781], Loss: 3.289637565612793\n",
            "[79 / 781], Loss: 3.5603623390197754\n",
            "[80 / 781], Loss: 3.2410197257995605\n",
            "[81 / 781], Loss: 3.295036554336548\n",
            "[82 / 781], Loss: 3.2413227558135986\n",
            "[83 / 781], Loss: 3.4785218238830566\n",
            "[84 / 781], Loss: 3.262025833129883\n",
            "[85 / 781], Loss: 3.4334521293640137\n",
            "[86 / 781], Loss: 3.257920265197754\n",
            "[87 / 781], Loss: 3.4171102046966553\n",
            "[88 / 781], Loss: 3.33294939994812\n",
            "[89 / 781], Loss: 3.3369784355163574\n",
            "[90 / 781], Loss: 3.220191478729248\n",
            "[91 / 781], Loss: 3.2010409832000732\n",
            "[92 / 781], Loss: 3.376335620880127\n",
            "[93 / 781], Loss: 3.336705446243286\n",
            "[94 / 781], Loss: 3.3517184257507324\n",
            "[95 / 781], Loss: 3.4678993225097656\n",
            "[96 / 781], Loss: 3.3662140369415283\n",
            "[97 / 781], Loss: 3.2763869762420654\n",
            "[98 / 781], Loss: 3.1636788845062256\n",
            "[99 / 781], Loss: 3.360257625579834\n",
            "[100 / 781], Loss: 3.297682762145996\n",
            "[101 / 781], Loss: 3.35308837890625\n",
            "[102 / 781], Loss: 3.3179309368133545\n",
            "[103 / 781], Loss: 3.4455583095550537\n",
            "[104 / 781], Loss: 3.4380128383636475\n",
            "[105 / 781], Loss: 3.4513778686523438\n",
            "[106 / 781], Loss: 3.3064560890197754\n",
            "[107 / 781], Loss: 3.530747175216675\n",
            "[108 / 781], Loss: 3.27880859375\n",
            "[109 / 781], Loss: 3.1326115131378174\n",
            "[110 / 781], Loss: 3.4771652221679688\n",
            "[111 / 781], Loss: 3.3334453105926514\n",
            "[112 / 781], Loss: 3.274940252304077\n",
            "[113 / 781], Loss: 3.3722734451293945\n",
            "[114 / 781], Loss: 3.3002729415893555\n",
            "[115 / 781], Loss: 3.468437433242798\n",
            "[116 / 781], Loss: 3.144301414489746\n",
            "[117 / 781], Loss: 3.4624547958374023\n",
            "[118 / 781], Loss: 3.278883695602417\n",
            "[119 / 781], Loss: 3.350039005279541\n",
            "[120 / 781], Loss: 3.2098028659820557\n",
            "[121 / 781], Loss: 3.608090877532959\n",
            "[122 / 781], Loss: 3.501152515411377\n",
            "[123 / 781], Loss: 3.3662643432617188\n",
            "[124 / 781], Loss: 3.0207459926605225\n",
            "[125 / 781], Loss: 3.2214608192443848\n",
            "[126 / 781], Loss: 3.426856279373169\n",
            "[127 / 781], Loss: 3.5265164375305176\n",
            "[128 / 781], Loss: 3.178427219390869\n",
            "[129 / 781], Loss: 3.3169021606445312\n",
            "[130 / 781], Loss: 3.4761598110198975\n",
            "[131 / 781], Loss: 3.2210960388183594\n",
            "[132 / 781], Loss: 3.5125386714935303\n",
            "[133 / 781], Loss: 3.2073304653167725\n",
            "[134 / 781], Loss: 3.198371410369873\n",
            "[135 / 781], Loss: 3.2570605278015137\n",
            "[136 / 781], Loss: 3.3655271530151367\n",
            "[137 / 781], Loss: 3.1344797611236572\n",
            "[138 / 781], Loss: 3.3464386463165283\n",
            "[139 / 781], Loss: 3.313960313796997\n",
            "[140 / 781], Loss: 3.2040457725524902\n",
            "[141 / 781], Loss: 3.380875587463379\n",
            "[142 / 781], Loss: 3.2227962017059326\n",
            "[143 / 781], Loss: 3.226083755493164\n",
            "[144 / 781], Loss: 3.241569995880127\n",
            "[145 / 781], Loss: 3.318110466003418\n",
            "[146 / 781], Loss: 3.160435199737549\n",
            "[147 / 781], Loss: 3.1960744857788086\n",
            "[148 / 781], Loss: 3.1513946056365967\n",
            "[149 / 781], Loss: 3.5968809127807617\n",
            "[150 / 781], Loss: 3.299616575241089\n",
            "[151 / 781], Loss: 3.2659530639648438\n",
            "[152 / 781], Loss: 3.496180772781372\n",
            "[153 / 781], Loss: 3.319477081298828\n",
            "[154 / 781], Loss: 3.4601168632507324\n",
            "[155 / 781], Loss: 3.4478864669799805\n",
            "[156 / 781], Loss: 3.3843398094177246\n",
            "[157 / 781], Loss: 3.243640899658203\n",
            "[158 / 781], Loss: 3.280195474624634\n",
            "[159 / 781], Loss: 3.24756121635437\n",
            "[160 / 781], Loss: 3.335735559463501\n",
            "[161 / 781], Loss: 3.505436658859253\n",
            "[162 / 781], Loss: 3.251704692840576\n",
            "[163 / 781], Loss: 3.4086694717407227\n",
            "[164 / 781], Loss: 3.2685725688934326\n",
            "[165 / 781], Loss: 3.201414108276367\n",
            "[166 / 781], Loss: 3.267793893814087\n",
            "[167 / 781], Loss: 3.469519853591919\n",
            "[168 / 781], Loss: 3.282174587249756\n",
            "[169 / 781], Loss: 3.141148567199707\n",
            "[170 / 781], Loss: 3.328721523284912\n",
            "[171 / 781], Loss: 3.1353421211242676\n",
            "[172 / 781], Loss: 3.151484251022339\n",
            "[173 / 781], Loss: 3.419752597808838\n",
            "[174 / 781], Loss: 3.4263930320739746\n",
            "[175 / 781], Loss: 3.1391046047210693\n",
            "[176 / 781], Loss: 3.4858431816101074\n",
            "[177 / 781], Loss: 3.4386074542999268\n",
            "[178 / 781], Loss: 3.425689935684204\n",
            "[179 / 781], Loss: 3.38305401802063\n",
            "[180 / 781], Loss: 3.466313362121582\n",
            "[181 / 781], Loss: 3.3237743377685547\n",
            "[182 / 781], Loss: 3.13545823097229\n",
            "[183 / 781], Loss: 3.532074213027954\n",
            "[184 / 781], Loss: 3.3033764362335205\n",
            "[185 / 781], Loss: 3.263962745666504\n",
            "[186 / 781], Loss: 3.142198324203491\n",
            "[187 / 781], Loss: 3.293907403945923\n",
            "[188 / 781], Loss: 3.332089424133301\n",
            "[189 / 781], Loss: 3.4401326179504395\n",
            "[190 / 781], Loss: 3.552602529525757\n",
            "[191 / 781], Loss: 3.3661491870880127\n",
            "[192 / 781], Loss: 3.256838321685791\n",
            "[193 / 781], Loss: 3.502493381500244\n",
            "[194 / 781], Loss: 3.456467628479004\n",
            "[195 / 781], Loss: 3.319410800933838\n",
            "[196 / 781], Loss: 2.8686280250549316\n",
            "[197 / 781], Loss: 3.376473903656006\n",
            "[198 / 781], Loss: 3.334981679916382\n",
            "[199 / 781], Loss: 3.4622867107391357\n",
            "[200 / 781], Loss: 3.3734748363494873\n",
            "[201 / 781], Loss: 3.3990862369537354\n",
            "[202 / 781], Loss: 3.2732834815979004\n",
            "[203 / 781], Loss: 3.2289223670959473\n",
            "[204 / 781], Loss: 3.263152837753296\n",
            "[205 / 781], Loss: 3.228644609451294\n",
            "[206 / 781], Loss: 3.2748970985412598\n",
            "[207 / 781], Loss: 3.2259206771850586\n",
            "[208 / 781], Loss: 3.2374250888824463\n",
            "[209 / 781], Loss: 3.3742496967315674\n",
            "[210 / 781], Loss: 3.3267323970794678\n",
            "[211 / 781], Loss: 3.3146679401397705\n",
            "[212 / 781], Loss: 3.2337217330932617\n",
            "[213 / 781], Loss: 3.2333405017852783\n",
            "[214 / 781], Loss: 3.285822868347168\n",
            "[215 / 781], Loss: 3.1370632648468018\n",
            "[216 / 781], Loss: 3.4640891551971436\n",
            "[217 / 781], Loss: 3.4277589321136475\n",
            "[218 / 781], Loss: 3.208655834197998\n",
            "[219 / 781], Loss: 3.2996506690979004\n",
            "[220 / 781], Loss: 3.2276735305786133\n",
            "[221 / 781], Loss: 3.4624555110931396\n",
            "[222 / 781], Loss: 3.4450597763061523\n",
            "[223 / 781], Loss: 3.204134941101074\n",
            "[224 / 781], Loss: 3.323713541030884\n",
            "[225 / 781], Loss: 3.1608147621154785\n",
            "[226 / 781], Loss: 3.6437478065490723\n",
            "[227 / 781], Loss: 3.357485771179199\n",
            "[228 / 781], Loss: 3.2715353965759277\n",
            "[229 / 781], Loss: 3.152841091156006\n",
            "[230 / 781], Loss: 3.5829877853393555\n",
            "[231 / 781], Loss: 3.4884283542633057\n",
            "[232 / 781], Loss: 3.3369576930999756\n",
            "[233 / 781], Loss: 2.9282665252685547\n",
            "[234 / 781], Loss: 3.2254104614257812\n",
            "[235 / 781], Loss: 3.3215370178222656\n",
            "[236 / 781], Loss: 3.207300901412964\n",
            "[237 / 781], Loss: 3.203299045562744\n",
            "[238 / 781], Loss: 3.281320571899414\n",
            "[239 / 781], Loss: 3.320781707763672\n",
            "[240 / 781], Loss: 3.5621161460876465\n",
            "[241 / 781], Loss: 3.1623892784118652\n",
            "[242 / 781], Loss: 3.3624823093414307\n",
            "[243 / 781], Loss: 3.315732717514038\n",
            "[244 / 781], Loss: 3.383815288543701\n",
            "[245 / 781], Loss: 3.210434913635254\n",
            "[246 / 781], Loss: 3.3164889812469482\n",
            "[247 / 781], Loss: 3.2841455936431885\n",
            "[248 / 781], Loss: 3.3411550521850586\n",
            "[249 / 781], Loss: 3.237699270248413\n",
            "[250 / 781], Loss: 3.124199390411377\n",
            "[251 / 781], Loss: 3.1353230476379395\n",
            "[252 / 781], Loss: 3.093086004257202\n",
            "[253 / 781], Loss: 3.2440967559814453\n",
            "[254 / 781], Loss: 3.2673349380493164\n",
            "[255 / 781], Loss: 3.3622684478759766\n",
            "[256 / 781], Loss: 3.1172847747802734\n",
            "[257 / 781], Loss: 3.105003595352173\n",
            "[258 / 781], Loss: 3.385441780090332\n",
            "[259 / 781], Loss: 3.3220789432525635\n",
            "[260 / 781], Loss: 3.437089681625366\n",
            "[261 / 781], Loss: 3.284057140350342\n",
            "[262 / 781], Loss: 3.1919145584106445\n",
            "[263 / 781], Loss: 3.348222494125366\n",
            "[264 / 781], Loss: 3.30633807182312\n",
            "[265 / 781], Loss: 3.3973591327667236\n",
            "[266 / 781], Loss: 3.416935682296753\n",
            "[267 / 781], Loss: 3.31648588180542\n",
            "[268 / 781], Loss: 3.318967580795288\n",
            "[269 / 781], Loss: 3.209859848022461\n",
            "[270 / 781], Loss: 3.0270931720733643\n",
            "[271 / 781], Loss: 3.4409868717193604\n",
            "[272 / 781], Loss: 3.3155717849731445\n",
            "[273 / 781], Loss: 3.419523000717163\n",
            "[274 / 781], Loss: 3.5082037448883057\n",
            "[275 / 781], Loss: 3.2992467880249023\n",
            "[276 / 781], Loss: 3.344123601913452\n",
            "[277 / 781], Loss: 3.187436819076538\n",
            "[278 / 781], Loss: 3.3171439170837402\n",
            "[279 / 781], Loss: 3.107621431350708\n",
            "[280 / 781], Loss: 3.365518808364868\n",
            "[281 / 781], Loss: 3.3130342960357666\n",
            "[282 / 781], Loss: 3.4184226989746094\n",
            "[283 / 781], Loss: 3.287027359008789\n",
            "[284 / 781], Loss: 3.0585875511169434\n",
            "[285 / 781], Loss: 3.2309229373931885\n",
            "[286 / 781], Loss: 3.1454622745513916\n",
            "[287 / 781], Loss: 3.3152871131896973\n",
            "[288 / 781], Loss: 2.9960148334503174\n",
            "[289 / 781], Loss: 3.06052827835083\n",
            "[290 / 781], Loss: 3.1266262531280518\n",
            "[291 / 781], Loss: 3.2679338455200195\n",
            "[292 / 781], Loss: 3.348876476287842\n",
            "[293 / 781], Loss: 3.0312070846557617\n",
            "[294 / 781], Loss: 3.4093708992004395\n",
            "[295 / 781], Loss: 3.035057783126831\n",
            "[296 / 781], Loss: 3.282174587249756\n",
            "[297 / 781], Loss: 3.3678786754608154\n",
            "[298 / 781], Loss: 3.2271511554718018\n",
            "[299 / 781], Loss: 3.299051284790039\n",
            "[300 / 781], Loss: 3.229804515838623\n",
            "[301 / 781], Loss: 3.1580936908721924\n",
            "[302 / 781], Loss: 3.2983224391937256\n",
            "[303 / 781], Loss: 3.279000997543335\n",
            "[304 / 781], Loss: 3.2063937187194824\n",
            "[305 / 781], Loss: 3.2643895149230957\n",
            "[306 / 781], Loss: 3.303603172302246\n",
            "[307 / 781], Loss: 3.0658559799194336\n",
            "[308 / 781], Loss: 3.2266311645507812\n",
            "[309 / 781], Loss: 3.128469228744507\n",
            "[310 / 781], Loss: 3.3526289463043213\n",
            "[311 / 781], Loss: 3.235121965408325\n",
            "[312 / 781], Loss: 3.050719738006592\n",
            "[313 / 781], Loss: 3.2160701751708984\n",
            "[314 / 781], Loss: 3.226238489151001\n",
            "[315 / 781], Loss: 3.247638702392578\n",
            "[316 / 781], Loss: 3.2105629444122314\n",
            "[317 / 781], Loss: 3.152323007583618\n",
            "[318 / 781], Loss: 3.0666468143463135\n",
            "[319 / 781], Loss: 3.4591269493103027\n",
            "[320 / 781], Loss: 3.0818328857421875\n",
            "[321 / 781], Loss: 3.2395429611206055\n",
            "[322 / 781], Loss: 2.9711525440216064\n",
            "[323 / 781], Loss: 3.2104339599609375\n",
            "[324 / 781], Loss: 3.250312328338623\n",
            "[325 / 781], Loss: 3.2262332439422607\n",
            "[326 / 781], Loss: 3.173189401626587\n",
            "[327 / 781], Loss: 3.013702869415283\n",
            "[328 / 781], Loss: 3.118053436279297\n",
            "[329 / 781], Loss: 3.232530117034912\n",
            "[330 / 781], Loss: 3.3541665077209473\n",
            "[331 / 781], Loss: 3.1590311527252197\n",
            "[332 / 781], Loss: 3.2735836505889893\n",
            "[333 / 781], Loss: 3.133101224899292\n",
            "[334 / 781], Loss: 3.4973599910736084\n",
            "[335 / 781], Loss: 3.308894634246826\n",
            "[336 / 781], Loss: 3.1328911781311035\n",
            "[337 / 781], Loss: 3.196648597717285\n",
            "[338 / 781], Loss: 3.2153525352478027\n",
            "[339 / 781], Loss: 3.134777784347534\n",
            "[340 / 781], Loss: 3.1494460105895996\n",
            "[341 / 781], Loss: 3.011369228363037\n",
            "[342 / 781], Loss: 3.043431520462036\n",
            "[343 / 781], Loss: 3.0670039653778076\n",
            "[344 / 781], Loss: 3.2258284091949463\n",
            "[345 / 781], Loss: 3.0719830989837646\n",
            "[346 / 781], Loss: 3.1248154640197754\n",
            "[347 / 781], Loss: 3.363715410232544\n",
            "[348 / 781], Loss: 3.3868606090545654\n",
            "[349 / 781], Loss: 3.2049560546875\n",
            "[350 / 781], Loss: 3.080378293991089\n",
            "[351 / 781], Loss: 3.099846601486206\n",
            "[352 / 781], Loss: 3.1975886821746826\n",
            "[353 / 781], Loss: 3.1630699634552\n",
            "[354 / 781], Loss: 3.2800729274749756\n",
            "[355 / 781], Loss: 3.2324886322021484\n",
            "[356 / 781], Loss: 3.4317471981048584\n",
            "[357 / 781], Loss: 2.957476854324341\n",
            "[358 / 781], Loss: 2.881453514099121\n",
            "[359 / 781], Loss: 3.4218995571136475\n",
            "[360 / 781], Loss: 2.828831195831299\n",
            "[361 / 781], Loss: 3.253713846206665\n",
            "[362 / 781], Loss: 3.115511655807495\n",
            "[363 / 781], Loss: 3.195270538330078\n",
            "[364 / 781], Loss: 3.4074530601501465\n",
            "[365 / 781], Loss: 3.2995476722717285\n",
            "[366 / 781], Loss: 3.451702117919922\n",
            "[367 / 781], Loss: 3.4885711669921875\n",
            "[368 / 781], Loss: 3.1775214672088623\n",
            "[369 / 781], Loss: 3.17179536819458\n",
            "[370 / 781], Loss: 3.1556005477905273\n",
            "[371 / 781], Loss: 2.985063076019287\n",
            "[372 / 781], Loss: 3.443488359451294\n",
            "[373 / 781], Loss: 3.385558843612671\n",
            "[374 / 781], Loss: 3.099039316177368\n",
            "[375 / 781], Loss: 3.241954803466797\n",
            "[376 / 781], Loss: 3.2893800735473633\n",
            "[377 / 781], Loss: 3.4186441898345947\n",
            "[378 / 781], Loss: 3.1739425659179688\n",
            "[379 / 781], Loss: 3.243866205215454\n",
            "[380 / 781], Loss: 3.0154829025268555\n",
            "[381 / 781], Loss: 3.2410781383514404\n",
            "[382 / 781], Loss: 3.349971294403076\n",
            "[383 / 781], Loss: 3.517214059829712\n",
            "[384 / 781], Loss: 2.9589695930480957\n",
            "[385 / 781], Loss: 3.1033084392547607\n",
            "[386 / 781], Loss: 3.243725538253784\n",
            "[387 / 781], Loss: 3.423767566680908\n",
            "[388 / 781], Loss: 3.204110860824585\n",
            "[389 / 781], Loss: 3.120917558670044\n",
            "[390 / 781], Loss: 3.1765661239624023\n",
            "[391 / 781], Loss: 3.4001691341400146\n",
            "[392 / 781], Loss: 3.1275582313537598\n",
            "[393 / 781], Loss: 3.3542022705078125\n",
            "[394 / 781], Loss: 3.114037036895752\n",
            "[395 / 781], Loss: 2.948657274246216\n",
            "[396 / 781], Loss: 3.1503899097442627\n",
            "[397 / 781], Loss: 3.240994453430176\n",
            "[398 / 781], Loss: 3.2560153007507324\n",
            "[399 / 781], Loss: 3.2565150260925293\n",
            "[400 / 781], Loss: 3.0283074378967285\n",
            "[401 / 781], Loss: 2.9995930194854736\n",
            "[402 / 781], Loss: 3.3888940811157227\n",
            "[403 / 781], Loss: 3.3180017471313477\n",
            "[404 / 781], Loss: 3.3759756088256836\n",
            "[405 / 781], Loss: 3.1172282695770264\n",
            "[406 / 781], Loss: 3.2965188026428223\n",
            "[407 / 781], Loss: 3.150782346725464\n",
            "[408 / 781], Loss: 3.210669755935669\n",
            "[409 / 781], Loss: 3.20491623878479\n",
            "[410 / 781], Loss: 3.1604886054992676\n",
            "[411 / 781], Loss: 3.3699257373809814\n",
            "[412 / 781], Loss: 3.285789966583252\n",
            "[413 / 781], Loss: 3.287139654159546\n",
            "[414 / 781], Loss: 3.032088279724121\n",
            "[415 / 781], Loss: 3.165182113647461\n",
            "[416 / 781], Loss: 3.3385169506073\n",
            "[417 / 781], Loss: 3.327068328857422\n",
            "[418 / 781], Loss: 3.170079231262207\n",
            "[419 / 781], Loss: 3.308852195739746\n",
            "[420 / 781], Loss: 3.227715253829956\n",
            "[421 / 781], Loss: 3.2802655696868896\n",
            "[422 / 781], Loss: 3.298454761505127\n",
            "[423 / 781], Loss: 3.082782506942749\n",
            "[424 / 781], Loss: 3.228743076324463\n",
            "[425 / 781], Loss: 3.334571123123169\n",
            "[426 / 781], Loss: 3.261653184890747\n",
            "[427 / 781], Loss: 3.138070821762085\n",
            "[428 / 781], Loss: 2.9963831901550293\n",
            "[429 / 781], Loss: 3.3009750843048096\n",
            "[430 / 781], Loss: 3.354588747024536\n",
            "[431 / 781], Loss: 3.2827653884887695\n",
            "[432 / 781], Loss: 2.87068510055542\n",
            "[433 / 781], Loss: 3.054286479949951\n",
            "[434 / 781], Loss: 3.13677978515625\n",
            "[435 / 781], Loss: 3.2548828125\n",
            "[436 / 781], Loss: 3.2231531143188477\n",
            "[437 / 781], Loss: 3.2607359886169434\n",
            "[438 / 781], Loss: 3.1788768768310547\n",
            "[439 / 781], Loss: 2.9964842796325684\n",
            "[440 / 781], Loss: 3.0280489921569824\n",
            "[441 / 781], Loss: 3.1557066440582275\n",
            "[442 / 781], Loss: 3.25773549079895\n",
            "[443 / 781], Loss: 3.2632129192352295\n",
            "[444 / 781], Loss: 3.1517341136932373\n",
            "[445 / 781], Loss: 3.256474256515503\n",
            "[446 / 781], Loss: 3.3298330307006836\n",
            "[447 / 781], Loss: 2.8624868392944336\n",
            "[448 / 781], Loss: 3.162717580795288\n",
            "[449 / 781], Loss: 3.1995208263397217\n",
            "[450 / 781], Loss: 3.260336399078369\n",
            "[451 / 781], Loss: 3.4055891036987305\n",
            "[452 / 781], Loss: 3.162790060043335\n",
            "[453 / 781], Loss: 2.9824869632720947\n",
            "[454 / 781], Loss: 3.2441821098327637\n",
            "[455 / 781], Loss: 3.179136037826538\n",
            "[456 / 781], Loss: 3.302016258239746\n",
            "[457 / 781], Loss: 3.1476566791534424\n",
            "[458 / 781], Loss: 2.929767608642578\n",
            "[459 / 781], Loss: 3.2059810161590576\n",
            "[460 / 781], Loss: 3.1501591205596924\n",
            "[461 / 781], Loss: 3.053100824356079\n",
            "[462 / 781], Loss: 3.2883639335632324\n",
            "[463 / 781], Loss: 3.239320993423462\n",
            "[464 / 781], Loss: 3.42480731010437\n",
            "[465 / 781], Loss: 3.015594959259033\n",
            "[466 / 781], Loss: 3.0064234733581543\n",
            "[467 / 781], Loss: 3.374875068664551\n",
            "[468 / 781], Loss: 3.070340394973755\n",
            "[469 / 781], Loss: 3.2878806591033936\n",
            "[470 / 781], Loss: 3.065153121948242\n",
            "[471 / 781], Loss: 3.3378419876098633\n",
            "[472 / 781], Loss: 3.0719313621520996\n",
            "[473 / 781], Loss: 2.8738832473754883\n",
            "[474 / 781], Loss: 3.0308878421783447\n",
            "[475 / 781], Loss: 3.3446972370147705\n",
            "[476 / 781], Loss: 3.124514102935791\n",
            "[477 / 781], Loss: 3.5310537815093994\n",
            "[478 / 781], Loss: 3.239253044128418\n",
            "[479 / 781], Loss: 3.2804505825042725\n",
            "[480 / 781], Loss: 3.1518595218658447\n",
            "[481 / 781], Loss: 3.484243631362915\n",
            "[482 / 781], Loss: 2.959547281265259\n",
            "[483 / 781], Loss: 3.3244595527648926\n",
            "[484 / 781], Loss: 3.2199151515960693\n",
            "[485 / 781], Loss: 3.2607076168060303\n",
            "[486 / 781], Loss: 3.414264678955078\n",
            "[487 / 781], Loss: 3.142078161239624\n",
            "[488 / 781], Loss: 3.04518985748291\n",
            "[489 / 781], Loss: 3.0716254711151123\n",
            "[490 / 781], Loss: 3.0475621223449707\n",
            "[491 / 781], Loss: 3.014754295349121\n",
            "[492 / 781], Loss: 3.146930694580078\n",
            "[493 / 781], Loss: 3.4283480644226074\n",
            "[494 / 781], Loss: 3.0804362297058105\n",
            "[495 / 781], Loss: 3.2381668090820312\n",
            "[496 / 781], Loss: 3.2448692321777344\n",
            "[497 / 781], Loss: 3.4044413566589355\n",
            "[498 / 781], Loss: 3.168302297592163\n",
            "[499 / 781], Loss: 3.2018330097198486\n",
            "[500 / 781], Loss: 3.1813671588897705\n",
            "[501 / 781], Loss: 3.0633163452148438\n",
            "[502 / 781], Loss: 2.8568921089172363\n",
            "[503 / 781], Loss: 3.146449565887451\n",
            "[504 / 781], Loss: 3.014277458190918\n",
            "[505 / 781], Loss: 3.297163963317871\n",
            "[506 / 781], Loss: 2.951512098312378\n",
            "[507 / 781], Loss: 2.9790570735931396\n",
            "[508 / 781], Loss: 3.3462233543395996\n",
            "[509 / 781], Loss: 3.278465747833252\n",
            "[510 / 781], Loss: 3.274639844894409\n",
            "[511 / 781], Loss: 3.319768190383911\n",
            "[512 / 781], Loss: 3.333893060684204\n",
            "[513 / 781], Loss: 3.3521780967712402\n",
            "[514 / 781], Loss: 3.3514013290405273\n",
            "[515 / 781], Loss: 2.9171597957611084\n",
            "[516 / 781], Loss: 3.0882861614227295\n",
            "[517 / 781], Loss: 2.9841647148132324\n",
            "[518 / 781], Loss: 3.298442840576172\n",
            "[519 / 781], Loss: 3.1989243030548096\n",
            "[520 / 781], Loss: 3.1714718341827393\n",
            "[521 / 781], Loss: 3.569108724594116\n",
            "[522 / 781], Loss: 3.2825050354003906\n",
            "[523 / 781], Loss: 3.2770438194274902\n",
            "[524 / 781], Loss: 2.9456918239593506\n",
            "[525 / 781], Loss: 3.0466887950897217\n",
            "[526 / 781], Loss: 2.9870057106018066\n",
            "[527 / 781], Loss: 3.295193910598755\n",
            "[528 / 781], Loss: 3.1515121459960938\n",
            "[529 / 781], Loss: 3.100109338760376\n",
            "[530 / 781], Loss: 3.468806028366089\n",
            "[531 / 781], Loss: 3.3248777389526367\n",
            "[532 / 781], Loss: 3.129950761795044\n",
            "[533 / 781], Loss: 3.2459633350372314\n",
            "[534 / 781], Loss: 3.2237508296966553\n",
            "[535 / 781], Loss: 3.160951852798462\n",
            "[536 / 781], Loss: 3.256474494934082\n",
            "[537 / 781], Loss: 3.254019260406494\n",
            "[538 / 781], Loss: 3.281754493713379\n",
            "[539 / 781], Loss: 3.1460177898406982\n",
            "[540 / 781], Loss: 3.2190630435943604\n",
            "[541 / 781], Loss: 2.9373064041137695\n",
            "[542 / 781], Loss: 2.992321014404297\n",
            "[543 / 781], Loss: 2.9293577671051025\n",
            "[544 / 781], Loss: 3.161322832107544\n",
            "[545 / 781], Loss: 3.243941307067871\n",
            "[546 / 781], Loss: 3.100013256072998\n",
            "[547 / 781], Loss: 3.130258798599243\n",
            "[548 / 781], Loss: 3.1373696327209473\n",
            "[549 / 781], Loss: 2.8517072200775146\n",
            "[550 / 781], Loss: 3.063678026199341\n",
            "[551 / 781], Loss: 3.1680829524993896\n",
            "[552 / 781], Loss: 3.120096445083618\n",
            "[553 / 781], Loss: 3.283876895904541\n",
            "[554 / 781], Loss: 2.877962589263916\n",
            "[555 / 781], Loss: 3.1852304935455322\n",
            "[556 / 781], Loss: 3.1175601482391357\n",
            "[557 / 781], Loss: 3.3038406372070312\n",
            "[558 / 781], Loss: 3.2039084434509277\n",
            "[559 / 781], Loss: 3.2202956676483154\n",
            "[560 / 781], Loss: 3.1884825229644775\n",
            "[561 / 781], Loss: 3.381093740463257\n",
            "[562 / 781], Loss: 3.1524112224578857\n",
            "[563 / 781], Loss: 3.1234545707702637\n",
            "[564 / 781], Loss: 3.2170767784118652\n",
            "[565 / 781], Loss: 3.157628297805786\n",
            "[566 / 781], Loss: 2.995388984680176\n",
            "[567 / 781], Loss: 3.0146501064300537\n",
            "[568 / 781], Loss: 2.957897663116455\n",
            "[569 / 781], Loss: 3.1350083351135254\n",
            "[570 / 781], Loss: 3.205782890319824\n",
            "[571 / 781], Loss: 3.3082706928253174\n",
            "[572 / 781], Loss: 3.0889668464660645\n",
            "[573 / 781], Loss: 3.1379361152648926\n",
            "[574 / 781], Loss: 3.113124370574951\n",
            "[575 / 781], Loss: 3.0847740173339844\n",
            "[576 / 781], Loss: 3.1091794967651367\n",
            "[577 / 781], Loss: 3.223287343978882\n",
            "[578 / 781], Loss: 3.3265554904937744\n",
            "[579 / 781], Loss: 2.9856059551239014\n",
            "[580 / 781], Loss: 3.21563720703125\n",
            "[581 / 781], Loss: 3.3736629486083984\n",
            "[582 / 781], Loss: 3.225019693374634\n",
            "[583 / 781], Loss: 3.0737671852111816\n",
            "[584 / 781], Loss: 3.1644833087921143\n",
            "[585 / 781], Loss: 3.3020050525665283\n",
            "[586 / 781], Loss: 3.1018335819244385\n",
            "[587 / 781], Loss: 2.9581189155578613\n",
            "[588 / 781], Loss: 3.136571168899536\n",
            "[589 / 781], Loss: 3.1942148208618164\n",
            "[590 / 781], Loss: 3.0697989463806152\n",
            "[591 / 781], Loss: 2.985034465789795\n",
            "[592 / 781], Loss: 3.1189894676208496\n",
            "[593 / 781], Loss: 2.8960299491882324\n",
            "[594 / 781], Loss: 3.2511842250823975\n",
            "[595 / 781], Loss: 3.057034730911255\n",
            "[596 / 781], Loss: 3.3512887954711914\n",
            "[597 / 781], Loss: 3.1882307529449463\n",
            "[598 / 781], Loss: 3.1480517387390137\n",
            "[599 / 781], Loss: 3.065567970275879\n",
            "[600 / 781], Loss: 3.160383701324463\n",
            "[601 / 781], Loss: 2.9167187213897705\n",
            "[602 / 781], Loss: 3.010336399078369\n",
            "[603 / 781], Loss: 3.2557106018066406\n",
            "[604 / 781], Loss: 3.3469951152801514\n",
            "[605 / 781], Loss: 2.872267484664917\n",
            "[606 / 781], Loss: 3.0724987983703613\n",
            "[607 / 781], Loss: 3.137683391571045\n",
            "[608 / 781], Loss: 3.0147416591644287\n",
            "[609 / 781], Loss: 3.049835681915283\n",
            "[610 / 781], Loss: 3.080799102783203\n",
            "[611 / 781], Loss: 3.168187141418457\n",
            "[612 / 781], Loss: 3.200105667114258\n",
            "[613 / 781], Loss: 3.219252824783325\n",
            "[614 / 781], Loss: 3.181760787963867\n",
            "[615 / 781], Loss: 2.950455904006958\n",
            "[616 / 781], Loss: 3.21874737739563\n",
            "[617 / 781], Loss: 3.3585875034332275\n",
            "[618 / 781], Loss: 3.27810001373291\n",
            "[619 / 781], Loss: 3.2304015159606934\n",
            "[620 / 781], Loss: 3.4032177925109863\n",
            "[621 / 781], Loss: 2.985105514526367\n",
            "[622 / 781], Loss: 3.129178762435913\n",
            "[623 / 781], Loss: 3.0844578742980957\n",
            "[624 / 781], Loss: 2.8502840995788574\n",
            "[625 / 781], Loss: 3.0850672721862793\n",
            "[626 / 781], Loss: 3.120288372039795\n",
            "[627 / 781], Loss: 3.319268226623535\n",
            "[628 / 781], Loss: 3.2569336891174316\n",
            "[629 / 781], Loss: 3.1630918979644775\n",
            "[630 / 781], Loss: 2.986501693725586\n",
            "[631 / 781], Loss: 3.0378482341766357\n",
            "[632 / 781], Loss: 2.8899972438812256\n",
            "[633 / 781], Loss: 3.112199306488037\n",
            "[634 / 781], Loss: 2.8174822330474854\n",
            "[635 / 781], Loss: 2.9642813205718994\n",
            "[636 / 781], Loss: 3.081512928009033\n",
            "[637 / 781], Loss: 3.225715398788452\n",
            "[638 / 781], Loss: 3.0904431343078613\n",
            "[639 / 781], Loss: 3.2129218578338623\n",
            "[640 / 781], Loss: 3.3783276081085205\n",
            "[641 / 781], Loss: 3.030651569366455\n",
            "[642 / 781], Loss: 3.159332513809204\n",
            "[643 / 781], Loss: 2.990518569946289\n",
            "[644 / 781], Loss: 3.1963372230529785\n",
            "[645 / 781], Loss: 2.76837420463562\n",
            "[646 / 781], Loss: 3.039048671722412\n",
            "[647 / 781], Loss: 3.167958974838257\n",
            "[648 / 781], Loss: 3.0011849403381348\n",
            "[649 / 781], Loss: 3.139662504196167\n",
            "[650 / 781], Loss: 3.0973503589630127\n",
            "[651 / 781], Loss: 3.0474514961242676\n",
            "[652 / 781], Loss: 3.2160370349884033\n",
            "[653 / 781], Loss: 3.0847485065460205\n",
            "[654 / 781], Loss: 3.1404378414154053\n",
            "[655 / 781], Loss: 3.0141818523406982\n",
            "[656 / 781], Loss: 2.970083475112915\n",
            "[657 / 781], Loss: 3.1555676460266113\n",
            "[658 / 781], Loss: 3.025883674621582\n",
            "[659 / 781], Loss: 3.3242409229278564\n",
            "[660 / 781], Loss: 3.358288049697876\n",
            "[661 / 781], Loss: 3.0745022296905518\n",
            "[662 / 781], Loss: 3.1027746200561523\n",
            "[663 / 781], Loss: 3.168910264968872\n",
            "[664 / 781], Loss: 2.990450859069824\n",
            "[665 / 781], Loss: 3.0581233501434326\n",
            "[666 / 781], Loss: 3.063948631286621\n",
            "[667 / 781], Loss: 2.9101221561431885\n",
            "[668 / 781], Loss: 3.0905377864837646\n",
            "[669 / 781], Loss: 3.0365564823150635\n",
            "[670 / 781], Loss: 3.2696685791015625\n",
            "[671 / 781], Loss: 3.2576425075531006\n",
            "[672 / 781], Loss: 3.0307159423828125\n",
            "[673 / 781], Loss: 3.2265946865081787\n",
            "[674 / 781], Loss: 3.1653621196746826\n",
            "[675 / 781], Loss: 3.1683554649353027\n",
            "[676 / 781], Loss: 3.2308361530303955\n",
            "[677 / 781], Loss: 3.0579159259796143\n",
            "[678 / 781], Loss: 2.8751206398010254\n",
            "[679 / 781], Loss: 3.0134146213531494\n",
            "[680 / 781], Loss: 3.0788307189941406\n",
            "[681 / 781], Loss: 3.0691356658935547\n",
            "[682 / 781], Loss: 3.1482484340667725\n",
            "[683 / 781], Loss: 2.940701961517334\n",
            "[684 / 781], Loss: 3.191405773162842\n",
            "[685 / 781], Loss: 3.3046369552612305\n",
            "[686 / 781], Loss: 2.938873291015625\n",
            "[687 / 781], Loss: 3.0580034255981445\n",
            "[688 / 781], Loss: 3.217698097229004\n",
            "[689 / 781], Loss: 3.213423013687134\n",
            "[690 / 781], Loss: 3.020432710647583\n",
            "[691 / 781], Loss: 3.205655813217163\n",
            "[692 / 781], Loss: 3.0689353942871094\n",
            "[693 / 781], Loss: 2.929138422012329\n",
            "[694 / 781], Loss: 2.8847029209136963\n",
            "[695 / 781], Loss: 3.2316627502441406\n",
            "[696 / 781], Loss: 3.2043700218200684\n",
            "[697 / 781], Loss: 3.076108932495117\n",
            "[698 / 781], Loss: 3.0020391941070557\n",
            "[699 / 781], Loss: 3.001295804977417\n",
            "[700 / 781], Loss: 3.1743667125701904\n",
            "[701 / 781], Loss: 2.9455723762512207\n",
            "[702 / 781], Loss: 2.842620611190796\n",
            "[703 / 781], Loss: 3.104512929916382\n",
            "[704 / 781], Loss: 3.3007583618164062\n",
            "[705 / 781], Loss: 3.207761526107788\n",
            "[706 / 781], Loss: 3.170717477798462\n",
            "[707 / 781], Loss: 2.9692442417144775\n",
            "[708 / 781], Loss: 3.113630533218384\n",
            "[709 / 781], Loss: 3.135993480682373\n",
            "[710 / 781], Loss: 3.056565046310425\n",
            "[711 / 781], Loss: 3.0577268600463867\n",
            "[712 / 781], Loss: 3.022597312927246\n",
            "[713 / 781], Loss: 3.092224597930908\n",
            "[714 / 781], Loss: 2.803724527359009\n",
            "[715 / 781], Loss: 3.018862009048462\n",
            "[716 / 781], Loss: 3.2404065132141113\n",
            "[717 / 781], Loss: 3.0122241973876953\n",
            "[718 / 781], Loss: 3.150789260864258\n",
            "[719 / 781], Loss: 3.153069496154785\n",
            "[720 / 781], Loss: 2.9747893810272217\n",
            "[721 / 781], Loss: 3.040705919265747\n",
            "[722 / 781], Loss: 3.136953353881836\n",
            "[723 / 781], Loss: 3.2734105587005615\n",
            "[724 / 781], Loss: 3.070420265197754\n",
            "[725 / 781], Loss: 3.284694194793701\n",
            "[726 / 781], Loss: 3.1749320030212402\n",
            "[727 / 781], Loss: 2.941169023513794\n",
            "[728 / 781], Loss: 3.0487942695617676\n",
            "[729 / 781], Loss: 2.977813720703125\n",
            "[730 / 781], Loss: 3.097275733947754\n",
            "[731 / 781], Loss: 3.0043888092041016\n",
            "[732 / 781], Loss: 3.19767427444458\n",
            "[733 / 781], Loss: 3.0428271293640137\n",
            "[734 / 781], Loss: 2.9450583457946777\n",
            "[735 / 781], Loss: 3.0747320652008057\n",
            "[736 / 781], Loss: 2.9139559268951416\n",
            "[737 / 781], Loss: 2.8752071857452393\n",
            "[738 / 781], Loss: 3.1364729404449463\n",
            "[739 / 781], Loss: 3.1494524478912354\n",
            "[740 / 781], Loss: 2.872396945953369\n",
            "[741 / 781], Loss: 3.018005609512329\n",
            "[742 / 781], Loss: 2.9075825214385986\n",
            "[743 / 781], Loss: 3.0885541439056396\n",
            "[744 / 781], Loss: 3.126265525817871\n",
            "[745 / 781], Loss: 2.9945499897003174\n",
            "[746 / 781], Loss: 3.139970064163208\n",
            "[747 / 781], Loss: 3.1787831783294678\n",
            "[748 / 781], Loss: 2.85998797416687\n",
            "[749 / 781], Loss: 2.9973554611206055\n",
            "[750 / 781], Loss: 2.9045047760009766\n",
            "[751 / 781], Loss: 3.2721948623657227\n",
            "[752 / 781], Loss: 2.9818115234375\n",
            "[753 / 781], Loss: 2.89697003364563\n",
            "[754 / 781], Loss: 2.8806159496307373\n",
            "[755 / 781], Loss: 3.0694122314453125\n",
            "[756 / 781], Loss: 2.996934652328491\n",
            "[757 / 781], Loss: 3.1613242626190186\n",
            "[758 / 781], Loss: 3.193568229675293\n",
            "[759 / 781], Loss: 3.0896494388580322\n",
            "[760 / 781], Loss: 3.3051493167877197\n",
            "[761 / 781], Loss: 2.9546515941619873\n",
            "[762 / 781], Loss: 3.1693382263183594\n",
            "[763 / 781], Loss: 2.816129446029663\n",
            "[764 / 781], Loss: 3.083559036254883\n",
            "[765 / 781], Loss: 3.086324691772461\n",
            "[766 / 781], Loss: 3.0892016887664795\n",
            "[767 / 781], Loss: 3.1020867824554443\n",
            "[768 / 781], Loss: 3.124357223510742\n",
            "[769 / 781], Loss: 3.0555381774902344\n",
            "[770 / 781], Loss: 2.9721693992614746\n",
            "[771 / 781], Loss: 2.925626516342163\n",
            "[772 / 781], Loss: 3.118374824523926\n",
            "[773 / 781], Loss: 2.977003574371338\n",
            "[774 / 781], Loss: 2.9301204681396484\n",
            "[775 / 781], Loss: 3.1455206871032715\n",
            "[776 / 781], Loss: 3.2360692024230957\n",
            "[777 / 781], Loss: 3.1478073596954346\n",
            "[778 / 781], Loss: 3.283931016921997\n",
            "[779 / 781], Loss: 3.0621957778930664\n",
            "[780 / 781], Loss: 3.1985912322998047\n",
            "train Loss: 411.8913 Acc: 36.9949\n",
            "[0 / 781], Loss: 2.288182020187378\n",
            "[1 / 781], Loss: 2.3584988117218018\n",
            "[2 / 781], Loss: 2.3240854740142822\n",
            "[3 / 781], Loss: 2.4694366455078125\n",
            "[4 / 781], Loss: 2.4020276069641113\n",
            "[5 / 781], Loss: 2.633244276046753\n",
            "[6 / 781], Loss: 2.082552433013916\n",
            "[7 / 781], Loss: 2.323647975921631\n",
            "[8 / 781], Loss: 2.6351070404052734\n",
            "[9 / 781], Loss: 2.086014747619629\n",
            "[10 / 781], Loss: 2.187479257583618\n",
            "[11 / 781], Loss: 2.751394510269165\n",
            "[12 / 781], Loss: 2.7458505630493164\n",
            "[13 / 781], Loss: 2.5199356079101562\n",
            "[14 / 781], Loss: 2.374066114425659\n",
            "[15 / 781], Loss: 2.4416537284851074\n",
            "[16 / 781], Loss: 2.020963668823242\n",
            "[17 / 781], Loss: 2.5978944301605225\n",
            "[18 / 781], Loss: 2.541355609893799\n",
            "[19 / 781], Loss: 1.8837205171585083\n",
            "[20 / 781], Loss: 3.053865909576416\n",
            "[21 / 781], Loss: 2.2514610290527344\n",
            "[22 / 781], Loss: 2.471689224243164\n",
            "[23 / 781], Loss: 2.2651681900024414\n",
            "[24 / 781], Loss: 2.085825204849243\n",
            "[25 / 781], Loss: 2.992419958114624\n",
            "[26 / 781], Loss: 2.0022470951080322\n",
            "[27 / 781], Loss: 2.4777963161468506\n",
            "[28 / 781], Loss: 2.0186967849731445\n",
            "[29 / 781], Loss: 2.407489776611328\n",
            "[30 / 781], Loss: 2.175490140914917\n",
            "[31 / 781], Loss: 2.437927007675171\n",
            "[32 / 781], Loss: 1.9285194873809814\n",
            "[33 / 781], Loss: 1.977702021598816\n",
            "[34 / 781], Loss: 1.8368775844573975\n",
            "[35 / 781], Loss: 2.3768997192382812\n",
            "[36 / 781], Loss: 2.2866835594177246\n",
            "[37 / 781], Loss: 2.0499203205108643\n",
            "[38 / 781], Loss: 2.518441677093506\n",
            "[39 / 781], Loss: 2.445770502090454\n",
            "[40 / 781], Loss: 2.665954828262329\n",
            "[41 / 781], Loss: 2.2647805213928223\n",
            "[42 / 781], Loss: 1.4592292308807373\n",
            "[43 / 781], Loss: 2.1650326251983643\n",
            "[44 / 781], Loss: 2.8444125652313232\n",
            "[45 / 781], Loss: 2.168302059173584\n",
            "[46 / 781], Loss: 2.754573106765747\n",
            "[47 / 781], Loss: 2.3682973384857178\n",
            "[48 / 781], Loss: 2.254741907119751\n",
            "[49 / 781], Loss: 2.3026323318481445\n",
            "[50 / 781], Loss: 2.5554583072662354\n",
            "[51 / 781], Loss: 2.462160587310791\n",
            "[52 / 781], Loss: 2.275874376296997\n",
            "[53 / 781], Loss: 2.4172866344451904\n",
            "[54 / 781], Loss: 2.136463165283203\n",
            "[55 / 781], Loss: 2.541919231414795\n",
            "[56 / 781], Loss: 2.1319262981414795\n",
            "[57 / 781], Loss: 2.2407805919647217\n",
            "[58 / 781], Loss: 2.014763116836548\n",
            "[59 / 781], Loss: 2.5530452728271484\n",
            "[60 / 781], Loss: 2.061232328414917\n",
            "[61 / 781], Loss: 2.6771764755249023\n",
            "[62 / 781], Loss: 2.6923208236694336\n",
            "[63 / 781], Loss: 3.0031967163085938\n",
            "[64 / 781], Loss: 2.09019136428833\n",
            "[65 / 781], Loss: 2.318136692047119\n",
            "[66 / 781], Loss: 2.356625556945801\n",
            "[67 / 781], Loss: 2.3365254402160645\n",
            "[68 / 781], Loss: 1.907193899154663\n",
            "[69 / 781], Loss: 2.169487953186035\n",
            "[70 / 781], Loss: 2.2342240810394287\n",
            "[71 / 781], Loss: 1.665578842163086\n",
            "[72 / 781], Loss: 2.6478683948516846\n",
            "[73 / 781], Loss: 2.196674346923828\n",
            "[74 / 781], Loss: 2.768935203552246\n",
            "[75 / 781], Loss: 2.6721620559692383\n",
            "[76 / 781], Loss: 2.360069990158081\n",
            "[77 / 781], Loss: 2.72993803024292\n",
            "[78 / 781], Loss: 2.219670057296753\n",
            "[79 / 781], Loss: 2.565002202987671\n",
            "[80 / 781], Loss: 2.495612621307373\n",
            "[81 / 781], Loss: 2.2430739402770996\n",
            "[82 / 781], Loss: 2.438182830810547\n",
            "[83 / 781], Loss: 2.1647043228149414\n",
            "[84 / 781], Loss: 2.0484261512756348\n",
            "[85 / 781], Loss: 2.2913177013397217\n",
            "[86 / 781], Loss: 2.6154143810272217\n",
            "[87 / 781], Loss: 2.4271554946899414\n",
            "[88 / 781], Loss: 2.5005009174346924\n",
            "[89 / 781], Loss: 2.6746175289154053\n",
            "[90 / 781], Loss: 2.3009729385375977\n",
            "[91 / 781], Loss: 2.0232317447662354\n",
            "[92 / 781], Loss: 2.324753522872925\n",
            "[93 / 781], Loss: 2.5088398456573486\n",
            "[94 / 781], Loss: 2.193016290664673\n",
            "[95 / 781], Loss: 2.088474750518799\n",
            "[96 / 781], Loss: 2.144354820251465\n",
            "[97 / 781], Loss: 2.1233386993408203\n",
            "[98 / 781], Loss: 1.5270957946777344\n",
            "[99 / 781], Loss: 2.2738869190216064\n",
            "[100 / 781], Loss: 2.301771879196167\n",
            "[101 / 781], Loss: 2.4648265838623047\n",
            "[102 / 781], Loss: 2.0820679664611816\n",
            "[103 / 781], Loss: 2.200169563293457\n",
            "[104 / 781], Loss: 2.337358236312866\n",
            "[105 / 781], Loss: 1.849546194076538\n",
            "[106 / 781], Loss: 2.463764190673828\n",
            "[107 / 781], Loss: 2.724217414855957\n",
            "[108 / 781], Loss: 2.390850067138672\n",
            "[109 / 781], Loss: 2.107353448867798\n",
            "[110 / 781], Loss: 2.033700704574585\n",
            "[111 / 781], Loss: 2.173140525817871\n",
            "[112 / 781], Loss: 2.1518189907073975\n",
            "[113 / 781], Loss: 2.340200185775757\n",
            "[114 / 781], Loss: 2.8293204307556152\n",
            "[115 / 781], Loss: 1.9754775762557983\n",
            "[116 / 781], Loss: 2.670830726623535\n",
            "[117 / 781], Loss: 1.9351003170013428\n",
            "[118 / 781], Loss: 2.661886692047119\n",
            "[119 / 781], Loss: 2.0756516456604004\n",
            "[120 / 781], Loss: 2.740703821182251\n",
            "[121 / 781], Loss: 1.9606735706329346\n",
            "[122 / 781], Loss: 3.093341112136841\n",
            "[123 / 781], Loss: 2.2613015174865723\n",
            "[124 / 781], Loss: 2.582395076751709\n",
            "[125 / 781], Loss: 1.7084022760391235\n",
            "[126 / 781], Loss: 2.771711587905884\n",
            "[127 / 781], Loss: 2.148261785507202\n",
            "[128 / 781], Loss: 2.4670073986053467\n",
            "[129 / 781], Loss: 2.6227731704711914\n",
            "[130 / 781], Loss: 2.665766954421997\n",
            "[131 / 781], Loss: 2.4610025882720947\n",
            "[132 / 781], Loss: 2.284203290939331\n",
            "[133 / 781], Loss: 2.397808313369751\n",
            "[134 / 781], Loss: 2.3637285232543945\n",
            "[135 / 781], Loss: 2.383145570755005\n",
            "[136 / 781], Loss: 2.485205888748169\n",
            "[137 / 781], Loss: 2.534191370010376\n",
            "[138 / 781], Loss: 2.380247116088867\n",
            "[139 / 781], Loss: 2.023833990097046\n",
            "[140 / 781], Loss: 2.340618848800659\n",
            "[141 / 781], Loss: 2.3804807662963867\n",
            "[142 / 781], Loss: 1.889973759651184\n",
            "[143 / 781], Loss: 2.547524929046631\n",
            "[144 / 781], Loss: 1.993155837059021\n",
            "[145 / 781], Loss: 2.034640312194824\n",
            "[146 / 781], Loss: 3.0307233333587646\n",
            "[147 / 781], Loss: 2.1034951210021973\n",
            "[148 / 781], Loss: 1.838579773902893\n",
            "[149 / 781], Loss: 2.5046885013580322\n",
            "[150 / 781], Loss: 2.240471363067627\n",
            "[151 / 781], Loss: 2.610485315322876\n",
            "[152 / 781], Loss: 2.3059744834899902\n",
            "[153 / 781], Loss: 1.8451776504516602\n",
            "[154 / 781], Loss: 2.367023229598999\n",
            "[155 / 781], Loss: 2.62557053565979\n",
            "[156 / 781], Loss: 1.994577407836914\n",
            "[157 / 781], Loss: 1.967091679573059\n",
            "[158 / 781], Loss: 2.2997734546661377\n",
            "[159 / 781], Loss: 2.1994614601135254\n",
            "[160 / 781], Loss: 2.2244455814361572\n",
            "[161 / 781], Loss: 2.027916193008423\n",
            "[162 / 781], Loss: 2.91165828704834\n",
            "[163 / 781], Loss: 2.48051381111145\n",
            "[164 / 781], Loss: 2.7538516521453857\n",
            "[165 / 781], Loss: 2.3385462760925293\n",
            "[166 / 781], Loss: 2.6921920776367188\n",
            "[167 / 781], Loss: 2.15800404548645\n",
            "[168 / 781], Loss: 2.530313730239868\n",
            "[169 / 781], Loss: 1.830081820487976\n",
            "[170 / 781], Loss: 2.6748783588409424\n",
            "[171 / 781], Loss: 2.310445547103882\n",
            "[172 / 781], Loss: 2.1371049880981445\n",
            "[173 / 781], Loss: 2.241673469543457\n",
            "[174 / 781], Loss: 2.156860113143921\n",
            "[175 / 781], Loss: 2.183302879333496\n",
            "[176 / 781], Loss: 1.9739936590194702\n",
            "[177 / 781], Loss: 2.2388863563537598\n",
            "[178 / 781], Loss: 2.7151482105255127\n",
            "[179 / 781], Loss: 1.9250538349151611\n",
            "[180 / 781], Loss: 1.8746377229690552\n",
            "[181 / 781], Loss: 2.391112804412842\n",
            "[182 / 781], Loss: 2.3435888290405273\n",
            "[183 / 781], Loss: 1.868491291999817\n",
            "[184 / 781], Loss: 2.717059373855591\n",
            "[185 / 781], Loss: 2.0483036041259766\n",
            "[186 / 781], Loss: 1.690071940422058\n",
            "[187 / 781], Loss: 2.277172565460205\n",
            "[188 / 781], Loss: 1.9076390266418457\n",
            "[189 / 781], Loss: 2.409669876098633\n",
            "[190 / 781], Loss: 2.257843255996704\n",
            "[191 / 781], Loss: 2.634493350982666\n",
            "[192 / 781], Loss: 1.811132550239563\n",
            "[193 / 781], Loss: 2.116966962814331\n",
            "[194 / 781], Loss: 2.662445545196533\n",
            "[195 / 781], Loss: 2.305051803588867\n",
            "[196 / 781], Loss: 2.2755160331726074\n",
            "[197 / 781], Loss: 2.625368595123291\n",
            "[198 / 781], Loss: 2.446566581726074\n",
            "[199 / 781], Loss: 2.1354551315307617\n",
            "[200 / 781], Loss: 2.591357707977295\n",
            "[201 / 781], Loss: 2.201082468032837\n",
            "[202 / 781], Loss: 2.580872058868408\n",
            "[203 / 781], Loss: 2.5801260471343994\n",
            "[204 / 781], Loss: 2.195920705795288\n",
            "[205 / 781], Loss: 2.3762423992156982\n",
            "[206 / 781], Loss: 2.2908456325531006\n",
            "[207 / 781], Loss: 1.77068030834198\n",
            "[208 / 781], Loss: 2.1525075435638428\n",
            "[209 / 781], Loss: 2.0957987308502197\n",
            "[210 / 781], Loss: 1.970363974571228\n",
            "[211 / 781], Loss: 2.7288625240325928\n",
            "[212 / 781], Loss: 2.2221174240112305\n",
            "[213 / 781], Loss: 2.457287311553955\n",
            "[214 / 781], Loss: 2.5159547328948975\n",
            "[215 / 781], Loss: 2.460320234298706\n",
            "[216 / 781], Loss: 2.329289674758911\n",
            "[217 / 781], Loss: 2.6765480041503906\n",
            "[218 / 781], Loss: 2.6162497997283936\n",
            "[219 / 781], Loss: 2.411869764328003\n",
            "[220 / 781], Loss: 1.8749293088912964\n",
            "[221 / 781], Loss: 2.6657629013061523\n",
            "[222 / 781], Loss: 2.0917348861694336\n",
            "[223 / 781], Loss: 1.9963364601135254\n",
            "[224 / 781], Loss: 2.4538040161132812\n",
            "[225 / 781], Loss: 2.1256792545318604\n",
            "[226 / 781], Loss: 1.9562817811965942\n",
            "[227 / 781], Loss: 2.0994224548339844\n",
            "[228 / 781], Loss: 2.37610125541687\n",
            "[229 / 781], Loss: 2.2434065341949463\n",
            "[230 / 781], Loss: 2.297140121459961\n",
            "[231 / 781], Loss: 2.1057379245758057\n",
            "[232 / 781], Loss: 2.3671889305114746\n",
            "[233 / 781], Loss: 2.4789206981658936\n",
            "[234 / 781], Loss: 2.142838954925537\n",
            "[235 / 781], Loss: 2.300103187561035\n",
            "[236 / 781], Loss: 2.1838417053222656\n",
            "[237 / 781], Loss: 2.405668258666992\n",
            "[238 / 781], Loss: 1.758126139640808\n",
            "[239 / 781], Loss: 2.295703887939453\n",
            "[240 / 781], Loss: 2.2262651920318604\n",
            "[241 / 781], Loss: 2.406297445297241\n",
            "[242 / 781], Loss: 2.607815742492676\n",
            "[243 / 781], Loss: 2.0230600833892822\n",
            "[244 / 781], Loss: 2.2458550930023193\n",
            "[245 / 781], Loss: 1.576767086982727\n",
            "[246 / 781], Loss: 2.533046245574951\n",
            "[247 / 781], Loss: 2.6585376262664795\n",
            "[248 / 781], Loss: 2.4930708408355713\n",
            "[249 / 781], Loss: 2.0774013996124268\n",
            "[250 / 781], Loss: 1.9271509647369385\n",
            "[251 / 781], Loss: 2.174194812774658\n",
            "[252 / 781], Loss: 1.8855791091918945\n",
            "[253 / 781], Loss: 2.1238176822662354\n",
            "[254 / 781], Loss: 2.438011884689331\n",
            "[255 / 781], Loss: 2.473543882369995\n",
            "[256 / 781], Loss: 2.122431516647339\n",
            "[257 / 781], Loss: 2.45070743560791\n",
            "[258 / 781], Loss: 2.4975180625915527\n",
            "[259 / 781], Loss: 2.4760351181030273\n",
            "[260 / 781], Loss: 2.1628501415252686\n",
            "[261 / 781], Loss: 2.529949903488159\n",
            "[262 / 781], Loss: 2.906808376312256\n",
            "[263 / 781], Loss: 2.057508945465088\n",
            "[264 / 781], Loss: 2.539677619934082\n",
            "[265 / 781], Loss: 2.053767681121826\n",
            "[266 / 781], Loss: 2.1244702339172363\n",
            "[267 / 781], Loss: 2.7471768856048584\n",
            "[268 / 781], Loss: 2.1000261306762695\n",
            "[269 / 781], Loss: 2.2604987621307373\n",
            "[270 / 781], Loss: 2.7659964561462402\n",
            "[271 / 781], Loss: 2.0835037231445312\n",
            "[272 / 781], Loss: 2.246992826461792\n",
            "[273 / 781], Loss: 2.19431734085083\n",
            "[274 / 781], Loss: 1.842953085899353\n",
            "[275 / 781], Loss: 2.1163079738616943\n",
            "[276 / 781], Loss: 2.6271467208862305\n",
            "[277 / 781], Loss: 1.987557053565979\n",
            "[278 / 781], Loss: 1.9863358736038208\n",
            "[279 / 781], Loss: 1.6876957416534424\n",
            "[280 / 781], Loss: 2.336852788925171\n",
            "[281 / 781], Loss: 2.348426103591919\n",
            "[282 / 781], Loss: 1.8011703491210938\n",
            "[283 / 781], Loss: 2.507065773010254\n",
            "[284 / 781], Loss: 1.6329466104507446\n",
            "[285 / 781], Loss: 2.4484975337982178\n",
            "[286 / 781], Loss: 2.615473508834839\n",
            "[287 / 781], Loss: 2.7776448726654053\n",
            "[288 / 781], Loss: 2.200615882873535\n",
            "[289 / 781], Loss: 2.1737864017486572\n",
            "[290 / 781], Loss: 2.7827959060668945\n",
            "[291 / 781], Loss: 2.4818241596221924\n",
            "[292 / 781], Loss: 2.0262012481689453\n",
            "[293 / 781], Loss: 2.010695695877075\n",
            "[294 / 781], Loss: 2.458041191101074\n",
            "[295 / 781], Loss: 1.923132300376892\n",
            "[296 / 781], Loss: 3.0024709701538086\n",
            "[297 / 781], Loss: 2.8993959426879883\n",
            "[298 / 781], Loss: 2.630213975906372\n",
            "[299 / 781], Loss: 2.396129846572876\n",
            "[300 / 781], Loss: 1.8930981159210205\n",
            "[301 / 781], Loss: 1.928099274635315\n",
            "[302 / 781], Loss: 2.660545587539673\n",
            "[303 / 781], Loss: 2.5530693531036377\n",
            "[304 / 781], Loss: 2.570891857147217\n",
            "[305 / 781], Loss: 2.4909632205963135\n",
            "[306 / 781], Loss: 2.130615711212158\n",
            "[307 / 781], Loss: 2.5365548133850098\n",
            "[308 / 781], Loss: 2.3451054096221924\n",
            "[309 / 781], Loss: 2.3453118801116943\n",
            "[310 / 781], Loss: 2.967154026031494\n",
            "[311 / 781], Loss: 1.9627330303192139\n",
            "val Loss: 74.0135 Acc: 14.5801\n",
            "\n",
            "Training complete in 46m 50s\n",
            "Best val Acc: 14.580128\n"
          ]
        }
      ],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp3saD3cMRMr"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGMoI5WNiy2T"
      },
      "outputs": [],
      "source": [
        "# plot_weights(model_ft.cpu(), 0, single_channel=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2DYG-uDQva7"
      },
      "outputs": [],
      "source": [
        "# model_ft.conv1.weight.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "LJY3e-YCRUeY",
        "outputId": "c01d69ab-a4c4-4110-f0b8-654be9a4bdf0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x4608 with 64 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# #extracting the model features at the particular layer number\n",
        "# layer = model.features[layer_num]\n",
        "\n",
        "# #checking whether the layer is convolution layer or not \n",
        "# if isinstance(layer, nn.Conv2d):\n",
        "  #getting the weight tensor data\n",
        "weight_tensor = model_ft.conv1.weight.data\n",
        "\n",
        "if False:\n",
        "  if collated:\n",
        "    plot_filters_single_channel_big(weight_tensor)\n",
        "  else:\n",
        "    plot_filters_single_channel(weight_tensor)\n",
        "    \n",
        "else:\n",
        "  if weight_tensor.shape[1] == 3:\n",
        "    plot_filters_multi_channel(weight_tensor)\n",
        "  else:\n",
        "    print(\"Can only plot weights with three channels with single channel = False\")\n",
        "      \n",
        "# else:\n",
        "#   print(\"Can only visualize layers which are convolutional\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7-ziw5xSc7W"
      },
      "outputs": [],
      "source": [
        "torch.save(model_ft.state_dict(), \"model_resnet.pt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TinyImageNet (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
